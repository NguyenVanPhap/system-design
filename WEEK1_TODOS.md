# Week 1 â€“ Fundamentals: Scalability & Availability

> **Mentor Note**: ÄÃ¢y lÃ  TODO list nghiÃªm kháº¯c. Má»—i item pháº£i Ä‘Æ°á»£c hoÃ n thÃ nh 100%. KhÃ´ng cÃ³ "gáº§n nhÆ° xong" hay "hiá»ƒu
> Ä‘áº¡i khÃ¡i". Báº¡n pháº£i CODE, MEASURE, vÃ  DOCUMENT.

---

## Study TODOs

### Scalability Concepts

- [ ] Äá»c "Designing Data-Intensive Applications" Chapter 1 - Scalability (pages 1-30)
- [ ] Viáº¿t notes: Äá»‹nh nghÄ©a chÃ­nh xÃ¡c cá»§a "scalability" trong 2 cÃ¢u
  As the system grows (in data volume, traffic volume, or complexity), there should
  be reasonable ways of dealing with that growth.
- [ ] Liá»‡t kÃª 5 Ä‘iá»ƒm khÃ¡c biá»‡t giá»¯a vertical vÃ  horizontal scaling
  + CÃ¡ch má»Ÿ rá»™ng: má»™t mÃ¡y máº¡nh hÆ¡n - thÃªm nhiá»u mÃ¡y
  + Giá»›i háº¡n: cÃ³ - khÃ´ng giá»›i háº¡n
  + Kháº£ nÄƒng chá»‹u lá»—i: kÃ©m - tá»‘t
  + Äá»™ phá»©c táº¡p khi váº­n hÃ nh: dá»… - khÃ³
  + Quy mÃ´: Nhá», Trung - Trung, Lá»›n

- [ ] TÃ¬m 3 real-world examples cá»§a vertical scaling (vÃ  táº¡i sao há» chá»n)
  + Blog cÃ¡ nhÃ¢n: Ráº», Ä‘Æ¡n giáº£n
  + ERP ná»™i bá»™: Ã­t user
  + Single DB
- [ ] TÃ¬m 3 real-world examples cá»§a horizontal scaling (vÃ  táº¡i sao há» chá»n)
  + Nexflix API: Scale lá»›n
  + Shopee: Flash Sale Traffic
  + Redis, Cache Cluster: Cache pháº£i cá»±c nhanh, RAM cÃ³ giá»›i háº¡n, Data lá»›n
- [ ] Äá»c vá» "Amdahl's Law" vÃ  viáº¿t cÃ´ng thá»©c + giáº£i thÃ­ch Ã½ nghÄ©a
  **CÃ´ng thá»©c:**
  ```
  Speedup = 1 / ((1-P) + P/N)
  ```
  Hoáº·c viáº¿t dÆ°á»›i dáº¡ng:
  ```
  Speedup = 1 / (S + (1-S)/N)
  ```
  Trong Ä‘Ã³:
  - **S** = pháº§n khÃ´ng thá»ƒ song song (serial portion), tá»· lá»‡ tá»« 0 Ä‘áº¿n 1
  - **P** = pháº§n cÃ³ thá»ƒ song song (parallel portion), P = 1 - S
  - **N** = sá»‘ lÃµi/tÃ i nguyÃªn xá»­ lÃ½ (sá»‘ processors/cores)
  - **Speedup** = má»©c tÄƒng tá»‘c so vá»›i cháº¡y tuáº§n tá»±

      **Ã nghÄ©a:**
      - Amdahl's Law cho tháº¥y giá»›i háº¡n tá»‘i Ä‘a cá»§a viá»‡c tÄƒng tá»‘c khi chá»‰ má»™t pháº§n cÃ´ng viá»‡c cÃ³ thá»ƒ song song hÃ³a
      - Pháº§n serial (khÃ´ng thá»ƒ song song) luÃ´n lÃ  bottleneck vÃ  giá»›i háº¡n hiá»‡u suáº¥t cá»§a toÃ n há»‡ thá»‘ng
      - VÃ­ dá»¥: Náº¿u 5% thá»i gian khÃ´ng thá»ƒ song song (S=0.05), dÃ¹ cÃ³ vÃ´ háº¡n CPU thÃ¬ tá»‘c Ä‘á»™ tá»‘i Ä‘a chá»‰ tÄƒng 20 láº§n (1/0.05 = 20x)
      - Thá»±c táº¿: Speedup_real = 1 / (S + (1-S)/N + Overhead)
        - Overhead bao gá»“m: Context switch, Lock contention, Garbage Collection, Network latency
      - **BÃ i há»c**: Muá»‘n scale hiá»‡u quáº£, pháº£i giáº£m pháº§n serial (bottleneck) trÆ°á»›c khi thÃªm tÃ i nguyÃªn

| Loáº¡i Serial (System Design)   | VÃ­ dá»¥                                | VÃ¬ sao lÃ m cháº­m  | Äá»‹nh luáº­t Ã¡p dá»¥ng | Giáº£i thÃ­ch                                                    |
|-------------------------------|--------------------------------------|------------------|-------------------|---------------------------------------------------------------|
| ğŸ—„ï¸ **Database bottleneck**   | Transaction dÃ i, `SELECT FOR UPDATE` | DB xá»­ lÃ½ tuáº§n tá»± | **Amdahl**        | DB bottleneck > 10% query â†’ pháº£i fix (replica, shard)         |
| ğŸ”Œ **Chung tÃ i nguyÃªn**       | 1 file, 1 connection, 1 queue        | Pháº£i Ä‘á»£i nhau    | **Amdahl**        | Shared resource > 10% contention â†’ pháº£i fix (shard, separate) |
| ğŸ“ **Logic báº¯t buá»™c tuáº§n tá»±** | step1 â†’ step2 â†’ step3                | KhÃ´ng tÃ¡ch Ä‘Æ°á»£c  | **Amdahl**        | Serial logic > 10% time â†’ pháº£i optimize                       |
| ğŸš€ **Init / Startup**         | Load config, warmup                  | Cháº¡y 1 luá»“ng     | **Gustafson**     | Init < 1% total time â†’ khÃ´ng Ä‘Ã¡ng ká»ƒ, cÃ³ nhiá»u task khÃ¡c      |

Scalability = Throughput (RPS, job/s) tÄƒng theo server.

Amdahl nÃ³i:

âŒ ThÃªm server â‰  tÄƒng vÃ´ háº¡n
âœ… Pháº£i giáº£m cá»• chai trÆ°á»›c

5ï¸âƒ£ Serial trong há»‡ thá»‘ng thÆ°á»ng lÃ 

| Bottleneck            | NghÄ©a lÃ  gÃ¬                   | Serial á»Ÿ Ä‘Ã¢u        | Dáº¥u hiá»‡u thÆ°á»ng gáº·p                      | Scale app cÃ³ giÃºp khÃ´ng? | Äá»‹nh luáº­t Ã¡p dá»¥ng          | CÃ¡ch xá»­ lÃ½ chÃ­nh                 |
|-----------------------|-------------------------------|---------------------|------------------------------------------|--------------------------|----------------------------|----------------------------------|
| **Database**          | DB xá»­ lÃ½ quÃ¡ nhiá»u read/write | 1 DB node / primary | Query cháº­m, CPU DB 100%, connection full | âŒ KhÃ´ng                  | **Amdahl** (> 10% query)   | Read replica, sharding, cache    |
| **Hot Key Redis**     | Nhiá»u request Ä‘áº­p vÃ o 1 key   | Redis single thread | Redis latency cao, key bá»‹ spam           | âŒ KhÃ´ng                  | **Amdahl** (> 10% traffic) | Shard key, cache local, cluster  |
| **Single Leader**     | Chá»‰ 1 node Ä‘Æ°á»£c write/xá»­ lÃ½   | Leader node         | Write TPS tháº¥p, leader overload          | âŒ KhÃ´ng                  | **Amdahl** (> 10% write)   | Shard, multi-leader, partition   |
| **Lock Global**       | 1 lock khÃ³a toÃ n há»‡ thá»‘ng     | Critical section    | Thread waiting nhiá»u, TPS tháº¥p           | âŒ KhÃ´ng                  | **Amdahl** (> 10% request) | Fine-grained lock, optimistic    |
| **Queue 1 Partition** | Queue chá»‰ cÃ³ 1 partition      | 1 consumer          | Lag cao, consumer idle                   | âŒ KhÃ´ng                  | **Amdahl** (> 10% message) | TÄƒng partition, parallel consume |
| **File dÃ¹ng chung**   | Nhiá»u node dÃ¹ng chung file    | File lock / IO      | IO wait cao, ghi file cháº­m               | âŒ KhÃ´ng                  | **Amdahl** (> 10% I/O)     | File riÃªng, object storage       |

**LÆ°u Ã½**: Táº¥t cáº£ cÃ¡c bottleneck trÃªn Ä‘á»u Ã¡p dá»¥ng **Amdahl's Law** khi chiáº¿m > 10% workload. Náº¿u < 1% workload vÃ  cÃ³
nhiá»u partition/key/task khÃ¡c â†’ cÃ³ thá»ƒ Ã¡p dá»¥ng **Gustafson's Law** (khÃ´ng cáº§n fix).

- [ ] Äá»c vá» "Gustafson's Law" vÃ  so sÃ¡nh vá»›i Amdahl's Law
  **Gustafson's Law - CÃ´ng thá»©c:**
  ```
  Speedup = (1 - P) + P Ã— N
  ```
  Hoáº·c viáº¿t dÆ°á»›i dáº¡ng:
  ```
  Speedup = S + (1 - S) Ã— N
  ```
  Trong Ä‘Ã³:
  - **S** = pháº§n khÃ´ng thá»ƒ song song (serial portion), tá»· lá»‡ tá»« 0 Ä‘áº¿n 1
  - **P** = pháº§n cÃ³ thá»ƒ song song (parallel portion), P = 1 - S
  - **N** = sá»‘ lÃµi/tÃ i nguyÃªn xá»­ lÃ½ (sá»‘ processors/cores)
  - **Speedup** = má»©c tÄƒng tá»‘c so vá»›i cháº¡y tuáº§n tá»±

      **Ã nghÄ©a:**
      - Gustafson's Law cÃ³ cÃ¡ch nhÃ¬n khÃ¡c vá»›i Amdahl's Law: khi cÃ³ nhiá»u lÃµi hÆ¡n, ta cÃ³ thá»ƒ **tÄƒng kÃ­ch thÆ°á»›c váº¥n Ä‘á»** (scaled speedup)
      - Giáº£ Ä‘á»‹nh: KÃ­ch thÆ°á»›c váº¥n Ä‘á» cÃ³ thá»ƒ tÄƒng theo sá»‘ lÃµi (vÃ­ dá»¥: xá»­ lÃ½ nhiá»u data hÆ¡n khi cÃ³ nhiá»u CPU hÆ¡n)
      - Speedup tÄƒng **gáº§n tuyáº¿n tÃ­nh** vá»›i sá»‘ lÃµi N, khÃ´ng bá»‹ giá»›i háº¡n nghiÃªm ngáº·t nhÆ° Amdahl's Law
      - VÃ­ dá»¥: Náº¿u 10% cÃ´ng viá»‡c tuáº§n tá»± (S=0.1), vá»›i 100 cores: Speedup = 0.1 + 0.9Ã—100 = 90.1x
      - **á»¨ng dá»¥ng**: Big data processing, distributed systems, khi workload cÃ³ thá»ƒ scale theo tÃ i nguyÃªn
      
      **So sÃ¡nh Amdahl's Law vs Gustafson's Law:**

| TiÃªu chÃ­                 | **Amdahl's Law**                       | **Gustafson's Law**                                |
|--------------------------|----------------------------------------|----------------------------------------------------|
| **Giáº£ Ä‘á»‹nh**             | KÃ­ch thÆ°á»›c váº¥n Ä‘á» **cá»‘ Ä‘á»‹nh**          | KÃ­ch thÆ°á»›c váº¥n Ä‘á» **cÃ³ thá»ƒ tÄƒng**                  |
| **CÃ´ng thá»©c**            | `Speedup = 1 / (S + (1-S)/N)`          | `Speedup = S + (1-S) Ã— N`                          |
| **Speedup tá»‘i Ä‘a**       | Bá»‹ giá»›i háº¡n bá»Ÿi pháº§n serial (há»¯u háº¡n)  | Gáº§n tuyáº¿n tÃ­nh vá»›i N (cÃ³ thá»ƒ ráº¥t lá»›n)              |
| **VÃ­ dá»¥ (S=0.1, N=100)** | **9.17x**                              | **90.1x**                                          |
| **Quan Ä‘iá»ƒm**            | Pháº§n serial lÃ  bottleneck nghiÃªm trá»ng | Pháº§n serial khÃ´ng cáº£n trá»Ÿ nhiá»u náº¿u tÄƒng quy mÃ´    |
| **á»¨ng dá»¥ng thá»±c táº¿**     | Fixed workload, há»‡ thá»‘ng hiá»‡n táº¡i      | Scalable workload, big data, distributed computing |
| **BÃ i há»c**              | Pháº£i giáº£m pháº§n serial trÆ°á»›c khi scale  | CÃ³ thá»ƒ scale tá»‘t náº¿u workload tÄƒng theo tÃ i nguyÃªn |

      **CÃ¡i nÃ o Ä‘Ãºng? CÃ¡i nÃ o sai?**
      
      âœ… **Cáº¢ HAI Äá»€U ÄÃšNG** - KhÃ´ng cÃ³ cÃ¡i nÃ o sai!
      
      - Cáº£ hai Ä‘á»‹nh luáº­t Ä‘á»u **toÃ¡n há»c chÃ­nh xÃ¡c**, nhÆ°ng Ã¡p dá»¥ng cho **giáº£ Ä‘á»‹nh khÃ¡c nhau**
      - **Amdahl's Law** Ä‘Ãºng khi: Workload **cá»‘ Ä‘á»‹nh**, khÃ´ng thay Ä‘á»•i khi thÃªm tÃ i nguyÃªn
      - **Gustafson's Law** Ä‘Ãºng khi: Workload **cÃ³ thá»ƒ tÄƒng** cÃ¹ng vá»›i tÃ i nguyÃªn
      
      **VÃ­ dá»¥ cá»¥ thá»ƒ:**
      
      **Amdahl's Law Ä‘Ãºng khi:**
      
      **1. Multithreading:**
      - Xá»­ lÃ½ 1 file 10GB vá»›i 1 CPU â†’ muá»‘n xá»­ lÃ½ nhanh hÆ¡n vá»›i 10 CPU
      - Workload cá»‘ Ä‘á»‹nh: váº«n lÃ  10GB, khÃ´ng tÄƒng
      - Káº¿t quáº£: Speedup bá»‹ giá»›i háº¡n bá»Ÿi pháº§n serial (Ä‘á»c file, ghi káº¿t quáº£)
      
      **2. System Design - API Server vá»›i Database Bottleneck:**
      - API server cÃ³ 10 instances, nhÆ°ng táº¥t cáº£ query vÃ o 1 database primary
      - Workload cá»‘ Ä‘á»‹nh: 1K QPS, khÃ´ng tÄƒng
      - Bottleneck: Database primary xá»­ lÃ½ 100% query (pháº§n serial)
      - Káº¿t quáº£: ThÃªm API server khÃ´ng giÃºp tÄƒng throughput, bá»‹ giá»›i háº¡n bá»Ÿi DB
      - **Giáº£i phÃ¡p**: Pháº£i fix DB bottleneck trÆ°á»›c (read replica, sharding, cache)
      
      **3. System Design - Hot Key Redis:**
      - CÃ³ 10 Redis nodes, nhÆ°ng 1 key `user:123` nháº­n 50% traffic
      - Workload cá»‘ Ä‘á»‹nh: 10K requests/giÃ¢y, khÃ´ng tÄƒng
      - Bottleneck: 1 key xá»­ lÃ½ 50% traffic (pháº§n serial)
      - Káº¿t quáº£: ThÃªm Redis node khÃ´ng giÃºp, vÃ¬ 1 key váº«n lÃ  bottleneck
      - **Giáº£i phÃ¡p**: Pháº£i shard key hoáº·c cache local trÆ°á»›c
      
      **4. System Design - Single Leader:**
      - CÃ³ 10 application servers, nhÆ°ng chá»‰ 1 database leader xá»­ lÃ½ táº¥t cáº£ write
      - Workload cá»‘ Ä‘á»‹nh: 5K write/giÃ¢y, khÃ´ng tÄƒng
      - Bottleneck: 1 leader xá»­ lÃ½ 100% write (pháº§n serial)
      - Káº¿t quáº£: ThÃªm app server khÃ´ng giÃºp tÄƒng write throughput
      - **Giáº£i phÃ¡p**: Pháº£i shard database hoáº·c multi-leader trÆ°á»›c
      
      **5. Scalability - Vertical Scaling:**
      - API server 1K QPS, muá»‘n tÄƒng lÃªn 2K QPS báº±ng cÃ¡ch upgrade server
      - Workload cá»‘ Ä‘á»‹nh: 2K QPS, khÃ´ng tÄƒng
      - Bottleneck: I/O, network latency (pháº§n serial)
      - Káº¿t quáº£: Upgrade CPU/RAM khÃ´ng Ä‘áº¡t 2x speedup, bá»‹ giá»›i háº¡n bá»Ÿi I/O
      - **Giáº£i phÃ¡p**: Pháº£i optimize I/O hoáº·c dÃ¹ng horizontal scaling
      
      **Gustafson's Law Ä‘Ãºng khi:**
      
      **1. Multithreading:**
      - CÃ³ 10 CPU â†’ xá»­ lÃ½ 10 file, má»—i file 10GB (tá»•ng 100GB)
      - Workload tÄƒng theo tÃ i nguyÃªn: nhiá»u CPU hÆ¡n â†’ xá»­ lÃ½ nhiá»u data hÆ¡n
      - Káº¿t quáº£: Speedup gáº§n tuyáº¿n tÃ­nh vÃ¬ má»—i CPU xá»­ lÃ½ 1 file riÃªng
      
      **2. System Design - Horizontal Scaling:**
      - API server 1K QPS, muá»‘n tÄƒng lÃªn 10K QPS
      - Workload tÄƒng: ThÃªm 10 server, má»—i server xá»­ lÃ½ 1K QPS Ä‘á»™c láº­p
      - Káº¿t quáº£: Throughput tÄƒng gáº§n tuyáº¿n tÃ­nh (10x) vá»›i sá»‘ server
      
      **3. System Design - Read Replica:**
      - Database primary xá»­ lÃ½ 100% read + write
      - Workload tÄƒng: ThÃªm 5 read replica, má»—i replica xá»­ lÃ½ read request Ä‘á»™c láº­p
      - Káº¿t quáº£: Read throughput tÄƒng gáº§n tuyáº¿n tÃ­nh vá»›i sá»‘ replica
      
      **4. System Design - Sharding:**
      - Database 1TB data, muá»‘n scale lÃªn 10TB
      - Workload tÄƒng: Chia thÃ nh 10 shard, má»—i shard xá»­ lÃ½ data Ä‘á»™c láº­p
      - Káº¿t quáº£: Write throughput tÄƒng gáº§n tuyáº¿n tÃ­nh vá»›i sá»‘ shard
      
      **Khi nÃ o dÃ¹ng cÃ¡i nÃ o?**

| TÃ¬nh huá»‘ng                          | DÃ¹ng Ä‘á»‹nh luáº­t nÃ o | LÃ½ do                                              |
|-------------------------------------|--------------------|----------------------------------------------------|
| API server xá»­ lÃ½ request cá»‘ Ä‘á»‹nh    | **Amdahl**         | Sá»‘ request/giÃ¢y cá»‘ Ä‘á»‹nh, khÃ´ng tÄƒng theo sá»‘ server |
| Database query optimization         | **Amdahl**         | Query cá»‘ Ä‘á»‹nh, chá»‰ muá»‘n cháº¡y nhanh hÆ¡n             |
| Big data processing (Hadoop, Spark) | **Gustafson**      | Nhiá»u node hÆ¡n â†’ xá»­ lÃ½ nhiá»u data hÆ¡n              |
| Video rendering, image processing   | **Gustafson**      | Nhiá»u CPU hÆ¡n â†’ render nhiá»u frame hÆ¡n             |
| Web scraping vá»›i rate limit         | **Amdahl**         | Rate limit cá»‘ Ä‘á»‹nh, khÃ´ng tÄƒng theo sá»‘ worker      |
| Distributed training ML             | **Gustafson**      | Nhiá»u GPU hÆ¡n â†’ train vá»›i dataset lá»›n hÆ¡n          |

      **Káº¿t luáº­n:**
      - **Amdahl's Law**: Cáº£nh bÃ¡o ráº±ng lá»£i Ã­ch cá»§a song song hÃ³a cÃ³ giá»›i háº¡n nghiÃªm ngáº·t, pháº£i giáº£m bottleneck serial
      - **Gustafson's Law**: Cho tháº¥y náº¿u ta **tÄƒng quy mÃ´ váº¥n Ä‘á»** cÃ¹ng vá»›i tÄƒng tÃ i nguyÃªn, lá»£i Ã­ch cÃ³ thá»ƒ tÄƒng gáº§n tuyáº¿n tÃ­nh
      - **Trong thá»±c táº¿**: Cáº£ hai Ä‘á»u Ä‘Ãºng tÃ¹y vÃ o context. Chá»n Ä‘á»‹nh luáº­t nÃ o phá»¥ thuá»™c vÃ o **workload cÃ³ thá»ƒ scale hay khÃ´ng**
      
      **ğŸ”§ LiÃªn há»‡ tá»›i Multithreading:**
      
      **Amdahl's Law Ã¡p dá»¥ng khi:**
      - Xá»­ lÃ½ **1 task cá»‘ Ä‘á»‹nh** vá»›i nhiá»u thread
      - VÃ­ dá»¥: Sort 1 máº£ng 1 triá»‡u pháº§n tá»­ vá»›i 4 threads
        - Task cá»‘ Ä‘á»‹nh: váº«n lÃ  1 máº£ng 1 triá»‡u pháº§n tá»­
        - Pháº§n serial: chia máº£ng, merge káº¿t quáº£
        - Speedup bá»‹ giá»›i háº¡n bá»Ÿi pháº§n merge (serial)
      - **Khi nÃ o dÃ¹ng**: Khi muá»‘n xá»­ lÃ½ **nhanh hÆ¡n** 1 task cá»¥ thá»ƒ
      - **Bottleneck**: Lock contention, critical section, synchronization overhead
      
      **Gustafson's Law Ã¡p dá»¥ng khi:**
      - Xá»­ lÃ½ **nhiá»u task Ä‘á»™c láº­p** vá»›i nhiá»u thread
      - VÃ­ dá»¥: Xá»­ lÃ½ 1000 request vá»›i 4 threads
        - Workload tÄƒng: 4 threads â†’ xá»­ lÃ½ 4 request Ä‘á»“ng thá»i
        - Má»—i thread xá»­ lÃ½ 1 request riÃªng (khÃ´ng cáº§n sync)
        - Speedup gáº§n tuyáº¿n tÃ­nh: 4x vá»›i 4 threads
      - **Khi nÃ o dÃ¹ng**: Khi cÃ³ **nhiá»u task Ä‘á»™c láº­p** cÃ³ thá»ƒ xá»­ lÃ½ song song
      - **Lá»£i Ã­ch**: KhÃ´ng cÃ³ bottleneck serial giá»¯a cÃ¡c task
      
      **Báº£ng: Loáº¡i Serial trong Multithreading**

| Loáº¡i Serial (Multithreading)  | VÃ­ dá»¥                           | VÃ¬ sao lÃ m cháº­m             | Äá»‹nh luáº­t Ã¡p dá»¥ng | Giáº£i thÃ­ch                                                  |
|-------------------------------|---------------------------------|-----------------------------|-------------------|-------------------------------------------------------------|
| ğŸ”’ **Lock / synchronized**    | `synchronized`, `ReentrantLock` | Chá»‰ 1 thread vÃ o â†’ xáº¿p hÃ ng | **Amdahl**        | Lock block > 10% thread â†’ pháº£i fix (fine-grained)           |
| ğŸ’¾ **IO blocking**            | Äá»c file, gá»i API, upload       | Thread Ä‘á»©ng chá»             | **Amdahl**        | IO blocking > 10% time â†’ pháº£i fix (async, non-blocking)     |
| ğŸ§¹ **GC Pause (Java)**        | Stop-the-world GC               | Táº¥t cáº£ Ä‘á»©ng im              | **Amdahl**        | GC pause > 10% time â†’ pháº£i fix (tune GC, reduce allocation) |
| ğŸ“ **Logging Ä‘á»“ng bá»™**        | File log sync                   | Block thread                | **Amdahl**        | Sync logging > 10% time â†’ pháº£i fix (async logging)          |
| ğŸ” **Single-thread executor** | `newSingleThreadExecutor()`     | Ã‰p vá» 1 luá»“ng               | **Gustafson**     | Náº¿u cÃ³ nhiá»u executor khÃ¡c â†’ khÃ´ng Ä‘Ã¡ng ká»ƒ                  |

      **Decision Matrix - Multithreading**

| TÃ¬nh huá»‘ng            | CÃ¢u há»i                                       | Amdahl (Pháº£i fix)                | Gustafson (CÃ³ thá»ƒ bá» qua)                |
|-----------------------|-----------------------------------------------|----------------------------------|------------------------------------------|
| **Thread Pool Size**  | Serial task chiáº¿m bao nhiÃªu % thá»i gian?      | > 10% â†’ Giáº£m serial (lock, sync) | < 1% â†’ KhÃ´ng cáº§n fix, cÃ³ nhiá»u task khÃ¡c |
| **Lock Contention**   | Lock nÃ y block bao nhiÃªu % thread?            | > 10% thread â†’ Fine-grained lock | < 1% thread â†’ KhÃ´ng cáº§n fix              |
| **Critical Section**  | Critical section chiáº¿m bao nhiÃªu % thá»i gian? | > 10% â†’ Optimize, giáº£m thá»i gian | < 1% â†’ KhÃ´ng cáº§n fix                     |
| **Task Distribution** | 1 task lá»›n vs nhiá»u task nhá»?                 | 1 task lá»›n â†’ Chia nhá» (Amdahl)   | Nhiá»u task nhá» â†’ Thread pool (Gustafson) |
| **Context Switch**    | Context switch overhead?                      | > 10% â†’ Giáº£m sá»‘ thread           | < 1% â†’ KhÃ´ng cáº§n fix                     |

      **VÃ­ dá»¥ Multithreading:**

| TÃ¬nh huá»‘ng                          | DÃ¹ng Ä‘á»‹nh luáº­t nÃ o | Giáº£i thÃ­ch                                             |
|-------------------------------------|--------------------|--------------------------------------------------------|
| Sort 1 máº£ng lá»›n vá»›i nhiá»u threads   | **Amdahl**         | Task cá»‘ Ä‘á»‹nh (1 máº£ng), pháº§n merge lÃ  serial bottleneck |
| Xá»­ lÃ½ 1000 request vá»›i thread pool  | **Gustafson**      | Nhiá»u request Ä‘á»™c láº­p, má»—i thread xá»­ lÃ½ 1 request      |
| Parallel for loop xá»­ lÃ½ array       | **Amdahl**         | Array cá»‘ Ä‘á»‹nh, chia nhá» vÃ  xá»­ lÃ½, nhÆ°ng cÃ³ overhead    |
| Producer-Consumer vá»›i nhiá»u workers | **Gustafson**      | Nhiá»u item trong queue, má»—i worker xá»­ lÃ½ item riÃªng    |
| TÃ­nh toÃ¡n matrix vá»›i shared memory  | **Amdahl**         | Matrix cá»‘ Ä‘á»‹nh, chia nhá» nhÆ°ng cÃ³ memory contention    |
| Web server xá»­ lÃ½ nhiá»u HTTP request | **Gustafson**      | Nhiá»u request Ä‘á»™c láº­p, má»—i thread xá»­ lÃ½ 1 request      |
| Image processing: xá»­ lÃ½ nhiá»u áº£nh   | **Gustafson**      | Nhiá»u áº£nh Ä‘á»™c láº­p, má»—i thread xá»­ lÃ½ 1 áº£nh              |
| Image processing: xá»­ lÃ½ 1 áº£nh lá»›n   | **Amdahl**         | 1 áº£nh cá»‘ Ä‘á»‹nh, chia nhá» nhÆ°ng cÃ³ overhead merge        |

      **BÃ i há»c cho Multithreading:**
      - **DÃ¹ng Amdahl khi**: Cáº§n xá»­ lÃ½ nhanh 1 task lá»›n â†’ pháº£i giáº£m pháº§n serial (lock, sync)
      - **DÃ¹ng Gustafson khi**: CÃ³ nhiá»u task Ä‘á»™c láº­p â†’ tÄƒng sá»‘ thread Ä‘á»ƒ xá»­ lÃ½ nhiá»u task hÆ¡n
      - **Thá»±c táº¿**: Háº§u háº¿t multithreading apps dÃ¹ng **Gustafson** vÃ¬ thÆ°á»ng cÃ³ nhiá»u task Ä‘á»™c láº­p (request, job, item)
      - **Thread Pool**: Trong thá»±c táº¿, háº§u háº¿t á»©ng dá»¥ng Ä‘á»u dÃ¹ng Thread Pool thay vÃ¬ táº¡o thread trá»±c tiáº¿p
      
      **ğŸ¯ FRAMEWORK THá»°C Táº¾: Khi NÃ o DÃ¹ng Amdahl vs Gustafson (System Design)**
      
      **BÆ°á»›c 1: PhÃ¢n tÃ­ch Bottleneck**
      
      Vá»›i má»—i bottleneck, há»i 2 cÃ¢u:
      1. **Bottleneck chiáº¿m bao nhiÃªu % workload?**
         - > 10% â†’ **Nghe Amdahl** â†’ Pháº£i giáº£m bottleneck
         - < 1% â†’ **Nghe Gustafson** â†’ KhÃ´ng Ä‘Ã¡ng ká»ƒ, cÃ³ thá»ƒ bá» qua
         - 1-10% â†’ **CÃ¢n nháº¯c** â†’ TÃ¹y vÃ o cost/benefit
      2. **Workload cÃ³ thá»ƒ tÄƒng khÃ´ng?**
         - Cá»‘ Ä‘á»‹nh â†’ **Nghe Amdahl** â†’ Pháº£i giáº£m bottleneck
         - CÃ³ thá»ƒ tÄƒng â†’ **Nghe Gustafson** â†’ TÄƒng workload Ä‘á»ƒ bottleneck khÃ´ng Ä‘Ã¡ng ká»ƒ
      
      **BÆ°á»›c 2: Decision Matrix - System Design**

| Bottleneck            | CÃ¢u há»i                                  | Amdahl (Pháº£i fix)                        | Gustafson (CÃ³ thá»ƒ bá» qua)                             |
|-----------------------|------------------------------------------|------------------------------------------|-------------------------------------------------------|
| **Hot Key Redis**     | Key nÃ y chiáº¿m bao nhiÃªu % traffic?       | > 10% traffic â†’ Shard key, cache local   | < 1% traffic â†’ KhÃ´ng cáº§n fix, cÃ³ nhiá»u key khÃ¡c       |
| **Single Leader**     | Leader nÃ y xá»­ lÃ½ bao nhiÃªu % write?      | > 10% write â†’ Shard, multi-leader        | < 1% write â†’ KhÃ´ng cáº§n fix, cÃ³ nhiá»u partition khÃ¡c   |
| **Lock Global**       | Lock nÃ y block bao nhiÃªu % request?      | > 10% request â†’ Fine-grained lock        | < 1% request â†’ KhÃ´ng cáº§n fix, cÃ³ nhiá»u task khÃ¡c      |
| **Queue 1 Partition** | Partition nÃ y xá»­ lÃ½ bao nhiÃªu % message? | > 10% message â†’ TÄƒng partition           | < 1% message â†’ KhÃ´ng cáº§n fix, cÃ³ nhiá»u partition khÃ¡c |
| **File dÃ¹ng chung**   | File nÃ y xá»­ lÃ½ bao nhiÃªu % I/O?          | > 10% I/O â†’ File riÃªng, shard            | < 1% I/O â†’ KhÃ´ng cáº§n fix, cÃ³ nhiá»u file khÃ¡c          |
| **Database**          | DB nÃ y xá»­ lÃ½ bao nhiÃªu % query?          | > 10% query â†’ Read replica, shard, cache | < 1% query â†’ KhÃ´ng cáº§n fix, cÃ³ nhiá»u DB khÃ¡c          |

      **BÆ°á»›c 3: Scalability trong System Design - LiÃªn há»‡ vá»›i Amdahl/Gustafson**
      
      **Äá»‹nh nghÄ©a Scalability:**
      - Scalability = Throughput (RPS, QPS, TPS) tÄƒng theo sá»‘ server/tÃ i nguyÃªn
      - Kháº£ nÄƒng há»‡ thá»‘ng xá»­ lÃ½ nhiá»u workload hÆ¡n khi thÃªm tÃ i nguyÃªn
      
      **Vertical Scaling (Scale Up) - Amdahl's Law:**
      - TÄƒng sá»©c máº¡nh 1 server (CPU, RAM, I/O)
      - **Workload cá»‘ Ä‘á»‹nh** â†’ Muá»‘n xá»­ lÃ½ nhanh hÆ¡n
      - **Bottleneck**: Giá»›i háº¡n pháº§n cá»©ng (max CPU, max RAM)
      - **Ãp dá»¥ng Amdahl**: Pháº§n serial (I/O, network) giá»›i háº¡n speedup
      - **VÃ­ dá»¥**: 1 server máº¡nh hÆ¡n xá»­ lÃ½ cÃ¹ng 1 lÆ°á»£ng request â†’ bá»‹ giá»›i háº¡n bá»Ÿi I/O, network
      
      **Horizontal Scaling (Scale Out) - Gustafson's Law:**
      - ThÃªm nhiá»u server Ä‘á»ƒ xá»­ lÃ½ nhiá»u workload hÆ¡n
      - **Workload tÄƒng** â†’ Má»—i server xá»­ lÃ½ pháº§n workload riÃªng
      - **Bottleneck**: Load balancing, data consistency
      - **Ãp dá»¥ng Gustafson**: Nhiá»u server â†’ xá»­ lÃ½ nhiá»u request Ä‘á»™c láº­p
      - **VÃ­ dá»¥**: 10 server xá»­ lÃ½ 10x request â†’ speedup gáº§n tuyáº¿n tÃ­nh
      
      **Decision Matrix - Scalability Patterns:**

| Scaling Type           | Workload         | Äá»‹nh luáº­t     | Khi nÃ o dÃ¹ng                       | Bottleneck                  |
|------------------------|------------------|---------------|------------------------------------|-----------------------------|
| **Vertical Scaling**   | Cá»‘ Ä‘á»‹nh          | **Amdahl**    | Workload nhá», muá»‘n xá»­ lÃ½ nhanh hÆ¡n | I/O, network, pháº§n cá»©ng max |
| **Horizontal Scaling** | TÄƒng theo server | **Gustafson** | Workload lá»›n, muá»‘n xá»­ lÃ½ nhiá»u hÆ¡n | Load balancing, consistency |
| **Read Replica**       | Read tÄƒng        | **Gustafson** | Nhiá»u read request Ä‘á»™c láº­p         | Write consistency           |
| **Sharding**           | Data tÄƒng        | **Gustafson** | Data lá»›n, chia thÃ nh nhiá»u shard   | Cross-shard query           |
| **Caching**            | Read tÄƒng        | **Gustafson** | Nhiá»u read request giá»‘ng nhau      | Cache invalidation          |

      **Scalability Metrics:**
      - **Throughput**: RPS/QPS tÄƒng theo sá»‘ server
      - **Latency**: Thá»i gian xá»­ lÃ½ 1 request
      - **Amdahl**: Latency giáº£m nhÆ°ng bá»‹ giá»›i háº¡n bá»Ÿi pháº§n serial
      - **Gustafson**: Throughput tÄƒng gáº§n tuyáº¿n tÃ­nh vá»›i sá»‘ server
      
      **BÆ°á»›c 4: Rule of Thumb Thá»±c Táº¿**
      
      **Nghe Amdahl khi:**
      - âœ… Bottleneck > 10% workload
      - âœ… Workload cá»‘ Ä‘á»‹nh, khÃ´ng thá»ƒ tÄƒng
      - âœ… CÃ³ thá»ƒ fix vá»›i cost há»£p lÃ½
      
      **Nghe Gustafson khi:**
      - âœ… Bottleneck < 1% workload
      - âœ… Workload cÃ³ thá»ƒ tÄƒng theo tÃ i nguyÃªn
      - âœ… CÃ³ nhiá»u task/workload Ä‘á»™c láº­p khÃ¡c
      - âœ… Fix bottleneck tá»‘n kÃ©m hÆ¡n lá»£i Ã­ch
      
      **BÆ°á»›c 5: Checklist Khi Design System**
      
      1. **Äo lÆ°á»ng**: Bottleneck chiáº¿m bao nhiÃªu % workload?
      2. **Quyáº¿t Ä‘á»‹nh**:
         - > 10% â†’ Fix ngay (Amdahl)
         - 1-10% â†’ CÃ¢n nháº¯c cost/benefit
         - < 1% â†’ CÃ³ thá»ƒ bá» qua (Gustafson)
      3. **Giáº£i phÃ¡p**: Shard, cache, optimize, fine-grained
      4. **Verify**: Sau khi fix, bottleneck cÃ²n bao nhiÃªu %?
      
      **BÆ°á»›c 6: VÃ­ Dá»¥ Thá»±c Táº¿ - System Design**
      
      **VÃ­ dá»¥ 1: Hot Key Redis (System)**
      - **TÃ¬nh huá»‘ng**: Key `user:123` nháº­n 50% traffic
      - **PhÃ¢n tÃ­ch**: 50% > 10% â†’ **Nghe Amdahl**
      - **Giáº£i phÃ¡p**: Shard key â†’ `user:123:shard0`, `user:123:shard1`
      - **Káº¿t quáº£**: Má»—i shard chá»‰ cÃ²n 25% â†’ OK
      
      **VÃ­ dá»¥ 2: Single Leader (System)**
      - **TÃ¬nh huá»‘ng**: 1 leader xá»­ lÃ½ 0.5% write, cÃ³ 200 partition khÃ¡c
      - **PhÃ¢n tÃ­ch**: 0.5% < 1% â†’ **Nghe Gustafson**
      - **Giáº£i phÃ¡p**: KhÃ´ng cáº§n fix, cÃ³ nhiá»u partition khÃ¡c
      - **Káº¿t quáº£**: Bottleneck khÃ´ng Ä‘Ã¡ng ká»ƒ â†’ OK
      
      **ğŸ”§ VÃ­ Dá»¥ Thá»±c Táº¿ - Multithreading (Xem pháº§n "LiÃªn há»‡ tá»›i Multithreading" á»Ÿ trÃªn)**
      
      **VÃ­ dá»¥ 1: Thread Pool vá»›i Lock Contention**
      - **TÃ¬nh huá»‘ng**: Global lock block 30% thread time
      - **PhÃ¢n tÃ­ch**: 30% > 10% â†’ **Nghe Amdahl**
      - **Giáº£i phÃ¡p**: Fine-grained lock â†’ `lock(userId)` thay vÃ¬ `lock(global)`
      - **Káº¿t quáº£**: Lock contention giáº£m xuá»‘ng < 1% â†’ OK
      
      **VÃ­ dá»¥ 2: Thread Pool vá»›i Nhiá»u Task**
      - **TÃ¬nh huá»‘ng**: Thread pool 10 threads, xá»­ lÃ½ 1000 request Ä‘á»™c láº­p
      - **PhÃ¢n tÃ­ch**: Nhiá»u task Ä‘á»™c láº­p â†’ **Nghe Gustafson**
      - **Giáº£i phÃ¡p**: KhÃ´ng cáº§n fix, má»—i thread xá»­ lÃ½ 1 request riÃªng
      - **Káº¿t quáº£**: Speedup gáº§n tuyáº¿n tÃ­nh â†’ OK
      
      **VÃ­ dá»¥ 3: Vertical Scaling (Scalability - Amdahl)**
      - **TÃ¬nh huá»‘ng**: API server 1K QPS, muá»‘n tÄƒng lÃªn 2K QPS báº±ng cÃ¡ch upgrade server
      - **PhÃ¢n tÃ­ch**: Workload cá»‘ Ä‘á»‹nh (2K QPS), muá»‘n xá»­ lÃ½ nhanh hÆ¡n â†’ **Nghe Amdahl**
      - **Giáº£i phÃ¡p**: Upgrade CPU, RAM â†’ nhÆ°ng bá»‹ giá»›i háº¡n bá»Ÿi I/O, network (pháº§n serial)
      - **Káº¿t quáº£**: Speedup bá»‹ giá»›i háº¡n, khÃ´ng Ä‘áº¡t 2x â†’ Cáº§n horizontal scaling
      
      **VÃ­ dá»¥ 4: Horizontal Scaling (Scalability - Gustafson)**
      - **TÃ¬nh huá»‘ng**: API server 1K QPS, muá»‘n tÄƒng lÃªn 10K QPS
      - **PhÃ¢n tÃ­ch**: Workload tÄƒng (10K QPS), má»—i server xá»­ lÃ½ request Ä‘á»™c láº­p â†’ **Nghe Gustafson**
      - **Giáº£i phÃ¡p**: ThÃªm 10 server, load balancer phÃ¢n phá»‘i request
      - **Káº¿t quáº£**: Throughput tÄƒng gáº§n tuyáº¿n tÃ­nh (10x) â†’ OK
      
      **VÃ­ dá»¥ 5: Read Replica (Scalability - Gustafson)**
      - **TÃ¬nh huá»‘ng**: Database primary xá»­ lÃ½ 100% read + write, muá»‘n scale read
      - **PhÃ¢n tÃ­ch**: Nhiá»u read request Ä‘á»™c láº­p â†’ **Nghe Gustafson**
      - **Giáº£i phÃ¡p**: ThÃªm read replica, phÃ¢n phá»‘i read request
      - **Káº¿t quáº£**: Read throughput tÄƒng gáº§n tuyáº¿n tÃ­nh vá»›i sá»‘ replica â†’ OK
      
      **BÆ°á»›c 7: TÃ³m Táº¯t Framework**
      
      ```
      Bottleneck > 10% workload? 
        â†’ YES: Fix ngay (Amdahl)
          â†’ System: Shard, cache, optimize
          â†’ Scalability: Vertical scaling bá»‹ giá»›i háº¡n, cáº§n horizontal
        â†’ NO: Bottleneck < 1%?
          â†’ YES: Bá» qua (Gustafson)
            â†’ System: CÃ³ nhiá»u partition/key khÃ¡c
            â†’ Scalability: Horizontal scaling, read replica, sharding
          â†’ NO: CÃ¢n nháº¯c cost/benefit
      
      Scalability Decision:
        Workload cá»‘ Ä‘á»‹nh? 
          â†’ YES: Vertical scaling (Amdahl) - bá»‹ giá»›i háº¡n
          â†’ NO: Horizontal scaling (Gustafson) - gáº§n tuyáº¿n tÃ­nh
      
      Multithreading: Xem pháº§n "LiÃªn há»‡ tá»›i Multithreading" á»Ÿ trÃªn
      ```
      
      **âš ï¸ GIá»šI Háº N Cá»¦A AMDahl/GUSTAFSON - Nhá»¯ng GÃ¬ Cáº§n Bá»• Sung**
      
      **CÃ¢u há»i: Chá»‰ dÃ¹ng 2 Ä‘á»‹nh luáº­t nÃ y Ä‘Ã£ Ä‘á»§ Ä‘á»ƒ giáº£i quyáº¿t táº¥t cáº£ trÆ°á»ng há»£p scale khi design system chÆ°a?**
      
      **Tráº£ lá»i: âŒ CHÆ¯A Äá»¦** - Amdahl/Gustafson chá»‰ giáº£i quyáº¿t má»™t pháº§n cá»§a scaling
      
      **âœ… Nhá»¯ng gÃ¬ Amdahl/Gustafson giáº£i quyáº¿t:**
      
      1. **Performance/Speedup khi scale**
         - Giá»›i háº¡n tÄƒng tá»‘c khi cÃ³ bottleneck serial
         - Tá»‘i Æ°u hÃ³a parallelization
         - Quyáº¿t Ä‘á»‹nh fix bottleneck hay khÃ´ng
      
      2. **Workload distribution**
         - Khi nÃ o chia nhá» workload
         - Khi nÃ o tÄƒng workload cÃ¹ng vá»›i tÃ i nguyÃªn
      
      **âŒ Nhá»¯ng gÃ¬ Amdahl/Gustafson KHÃ”NG giáº£i quyáº¿t:**
      
      1. **Consistency & CAP Theorem**
         - Trade-off giá»¯a Consistency, Availability, Partition tolerance
         - Strong consistency vs eventual consistency
         - Amdahl/Gustafson khÃ´ng nÃ³i vá» data consistency
         - **Cáº§n há»c**: CAP theorem, ACID vs BASE, consistency patterns
      
      2. **Availability & Reliability**
         - Redundancy patterns (Active-Active, Active-Passive)
         - Failure handling, circuit breaker
         - Disaster recovery
         - MTBF, MTTR
         - **Cáº§n há»c**: Availability patterns, failure modes, redundancy strategies
      
      3. **Network & Latency**
         - Network latency khi scale geographically
         - CDN, edge computing
         - Data locality
         - Amdahl/Gustafson giáº£ Ä‘á»‹nh network khÃ´ng pháº£i bottleneck
         - **Cáº§n há»c**: Network topology, CDN, edge computing, data locality
      
      4. **Cost & Economics**
         - Cost per request khi scale
         - ROI cá»§a scaling
         - Amdahl/Gustafson khÃ´ng tÃ­nh cost
         - **Cáº§n há»c**: Cost optimization, TCO (Total Cost of Ownership)
      
      5. **Complexity & Operations**
         - Operational complexity khi scale
         - Monitoring, observability
         - Debugging distributed systems
         - Amdahl/Gustafson khÃ´ng tÃ­nh complexity overhead
         - **Cáº§n há»c**: Observability, monitoring, distributed tracing, logging
      
      6. **Data Partitioning Strategies**
         - Sharding strategies (range, hash, directory-based)
         - Rebalancing khi scale
         - Cross-shard queries
         - Amdahl/Gustafson khÃ´ng nÃ³i vá» cÃ¡ch partition
         - **Cáº§n há»c**: Sharding strategies, partition keys, rebalancing
      
      7. **Load Balancing Strategies**
         - Round-robin, weighted, consistent hashing
         - Session affinity
         - Health checks
         - Amdahl/Gustafson giáº£ Ä‘á»‹nh load balancing hoÃ n háº£o
         - **Cáº§n há»c**: Load balancing algorithms, session management
      
      8. **Caching Strategies**
         - Cache invalidation
         - Cache warming
         - Cache consistency
         - Amdahl/Gustafson khÃ´ng nÃ³i vá» caching
         - **Cáº§n há»c**: Cache patterns, invalidation strategies, cache coherence
      
      9. **Message Queue Patterns**
         - Pub/sub, point-to-point
         - Message ordering
         - Exactly-once delivery
         - Amdahl/Gustafson khÃ´ng nÃ³i vá» messaging
         - **Cáº§n há»c**: Message queue patterns, event-driven architecture
      
      10. **Database Replication Patterns**
          - Master-slave, master-master
          - Read replicas, write replicas
          - Replication lag
          - Amdahl/Gustafson khÃ´ng nÃ³i vá» replication
          - **Cáº§n há»c**: Replication patterns, read/write splitting, lag handling
      
      **ğŸ“š TÃ³m Táº¯t:**

| KhÃ­a cáº¡nh          | Amdahl/Gustafson | Cáº§n há»c thÃªm                      |
|--------------------|------------------|-----------------------------------|
| **Performance**    | âœ… Giáº£i quyáº¿t     | -                                 |
| **Consistency**    | âŒ KhÃ´ng          | CAP theorem, ACID vs BASE         |
| **Availability**   | âŒ KhÃ´ng          | Redundancy, failure handling      |
| **Network**        | âŒ KhÃ´ng          | CDN, edge computing, latency      |
| **Cost**           | âŒ KhÃ´ng          | Cost optimization, TCO            |
| **Operations**     | âŒ KhÃ´ng          | Monitoring, observability         |
| **Partitioning**   | âŒ KhÃ´ng          | Sharding strategies               |
| **Load Balancing** | âŒ KhÃ´ng          | LB algorithms, session management |
| **Caching**        | âŒ KhÃ´ng          | Cache patterns, invalidation      |
| **Messaging**      | âŒ KhÃ´ng          | Message queue patterns            |
| **Replication**    | âŒ KhÃ´ng          | Replication patterns              |

      **Káº¿t luáº­n:**
      - Amdahl/Gustafson lÃ  **ná»n táº£ng quan trá»ng** Ä‘á»ƒ hiá»ƒu performance khi scale
      - NhÆ°ng **chÆ°a Ä‘á»§** Ä‘á»ƒ design system hoÃ n chá»‰nh
      - Cáº§n há»c thÃªm: CAP theorem, Availability, Network, Cost, Operations, vÃ  cÃ¡c patterns khÃ¡c
      - Amdahl/Gustafson giÃºp **quyáº¿t Ä‘á»‹nh khi nÃ o scale**, nhÆ°ng khÃ´ng nÃ³i **cÃ¡ch scale nhÆ° tháº¿ nÃ o**

### Performance Metrics

- [ ] Äá»‹nh nghÄ©a chÃ­nh xÃ¡c: Latency, Throughput, QPS, TPS, RPS 
  - Latency = thá»i gian má»™t request/operation báº¯t Ä‘áº§u cho Ä‘áº¿n khi hoÃ n thÃ nh 
  - Throughput = sá»‘ lÆ°á»£ng operation mÃ  há»‡ thá»‘ng xá»­ lÃ½ thÃ nh cÃ´ng trÃªn má»™t Ä‘Æ¡n vá»‹ thá»i gian 
  - QPS = Queries per second = Sá»‘ lÆ°á»£ng query mÃ  há»‡ thá»‘ng xá»­ lÃ½ trong má»™t giÃ¢y 
  - RPS = Requests per second = Sá»‘ lÆ°á»£ng request mÃ  há»‡ thá»‘ng nháº­n/xá»­ lÃ½ trong má»™t giÃ¢y 
  - TPS = Transactions per second = Sá»‘ lÆ°á»£ng transaction hoÃ n chá»‰nh (atomic, commit thÃ nh cÃ´ng) mÃ  há»‡ thá»‘ng xá»­ lÃ½ trong 1 giÃ¢y
- [ ] Viáº¿t cÃ´ng thá»©c tÃ­nh: QPS = ?
  - QPS = number of queries / total time
- [ ] Viáº¿t cÃ´ng thá»©c tÃ­nh: Throughput = sá»‘ lÆ°á»£ng operation hoÃ n thÃ nh / thá»i gian
- [ ] Äá»c vá» percentile metrics (p50, p95, p99, p999)
  - Percentile = â€œbao nhiÃªu % request nhanh hÆ¡n hoáº·c báº±ng giÃ¡ trá»‹ nÃ yâ€
- [ ] TÃ­nh toÃ¡n: Náº¿u p95 latency = 200ms, cÃ³ nghÄ©a lÃ  gÃ¬? (viáº¿t cÃ¢u tráº£ lá»i)
  - 95% request cÃ³ thá»i gian pháº£n há»“i â‰¤ 200ms, 
  - 5% request cÃ²n láº¡i > 200ms.
- [ ] TÃ¬m hiá»ƒu: Táº¡i sao p99 quan trá»ng hÆ¡n average latency?
  - Average che giáº¥u váº¥n Ä‘á».
  - p99 pháº£n Ã¡nh user xui xáº»o nháº¥t 
    - p99 = latency cá»§a 1% user cháº­m nháº¥t. 
  - NÃ³ tráº£ lá»i cÃ¢u há»i:
    - â€œUser tá»‡ nháº¥t Ä‘ang tráº£i nghiá»‡m tháº¿ nÃ o?â€ 
  - Vá»›i há»‡ thá»‘ng lá»›n:
    - 1% cá»§a 1 triá»‡u user = 10.000 ngÆ°á»i ğŸ˜± 
  - â†’ KhÃ´ng thá»ƒ bá» qua.
- [ ] Äá»c vá» "tail latency" vÃ  "latency SLOs"
  - Tail = nhá»¯ng request ráº¥t cháº­m. 
  - VÃ­ dá»¥:
    - 95% < 200ms 
    - 5% > 1s 
    - 1% > 5s 
    - â†’ ÄÃ³ lÃ  tail latency.
  - SLO = Service Level Objective 
    - Má»¥c tiÃªu cháº¥t lÆ°á»£ng dá»‹ch vá»¥. 
    - VÃ­ dá»¥: 99% request pháº£i < 300ms trong 30 ngÃ y. 
    - Hoáº·c: p99 latency â‰¤ 500ms.
      | KhÃ¡i niá»‡m | Ai dÃ¹ng                |
      | --------- | ---------------------- |
      | SLO       | Internal (team tá»± Ä‘áº·t) |
      | SLA       | Cam káº¿t vá»›i khÃ¡ch      |

### Availability Concepts

- [ ] TÃ­nh toÃ¡n downtime cho: 99%, 99.9%, 99.99%, 99.999% (theo nÄƒm, thÃ¡ng, tuáº§n, ngÃ y)
  - Downtime = (1 âˆ’ Availability) Ã— Tá»•ng thá»i gian
- [ ] Viáº¿t báº£ng so sÃ¡nh: Availability % â†’ Downtime/year â†’ Downtime/month
| Availability | Downtime/year | Downtime/month | Downtime/week | Downtime/day |
|--------------|----------------|----------------|----------------|---------------|
| 99%          | 3.65 days      | 7.2 hours      | 1.68 hours     | 14.4 minutes  |
| 99.9%        | 8.76 hours     | 43.2 minutes   | 10.08 minutes | 1.44 minutes  |
| 99.99%       | 52.56 minutes  | 4.32 minutes   | 1.008 minutes | 8.64 seconds  |
| 99.999%      | 5.256 minutes  | 25.92 seconds  | 6.048 seconds | 0.864 seconds |

- [ ] Äá»c vá» "nines" trong availability (3 nines, 4 nines, 5 nines)
  - Nines = sá»‘ chá»¯ sá»‘ 9 trong availability %
  - 3 nines = 99.9%
  - 4 nines = 99.99%
  - 5 nines = 99.999%
  - Má»—i nines tÄƒng thÃªm â†’ Giáº£m downtime Ä‘Ã¡ng ká»ƒ

- [ ] Äá»‹nh nghÄ©a: Single Point of Failure (SPOF)
  - SPOF = ThÃ nh pháº§n há»‡ thá»‘ng mÃ  náº¿u nÃ³ há»ng â†’ toÃ n bá»™ há»‡ thá»‘ng ngá»«ng hoáº¡t Ä‘á»™ng
  - VÃ­ dá»¥: 1 database server khÃ´ng cÃ³ replica â†’ náº¿u nÃ³ há»ng â†’ há»‡ thá»‘ng khÃ´ng hoáº¡t Ä‘á»™ng
- [ ] Äá»‹nh nghÄ©a: Mean Time Between Failures (MTBF)
  - MTBF = Thá»i gian trung bÃ¬nh giá»¯a cÃ¡c láº§n há»ng hÃ³c
  - VÃ­ dá»¥: Náº¿u MTBF = 1000 giá» â†’ Trung bÃ¬nh má»—i 1000 giá» sáº½ cÃ³ 1 láº§n há»ng
- [ ] Äá»‹nh nghÄ©a: Mean Time To Recovery (MTTR)
  - MTTR = Thá»i gian trung bÃ¬nh Ä‘á»ƒ khÃ´i phá»¥c sau khi há»ng
  - VÃ­ dá»¥: Náº¿u MTTR = 2 giá» â†’ Trung bÃ¬nh máº¥t 2 giá» Ä‘á»ƒ sá»­a chá»¯a vÃ  khÃ´i phá»¥c
- [ ] CÃ´ng thá»©c: Availability = MTBF / (MTBF + MTTR) - verify vÃ  hiá»ƒu
    - Availability = MTBF / (MTBF + MTTR)
    - VÃ­ dá»¥: MTBF = 1000 giá», MTTR = 2 giá»
        - Availability = 1000 / (1000 + 2) â‰ˆ 99.8%

### Redundancy Patterns

- [ ] Äá»c vá» Active-Active redundancy pattern
  - Active-Active: Táº¥t cáº£ cÃ¡c nodes Ä‘á»u hoáº¡t Ä‘á»™ng vÃ  xá»­ lÃ½ traffic cÃ¹ng lÃºc. Náº¿u má»™t node há»ng, cÃ¡c node cÃ²n láº¡i tiáº¿p tá»¥c phá»¥c vá»¥ mÃ  khÃ´ng giÃ¡n Ä‘oáº¡n.
- [ ] Äá»c vá» Active-Passive (Hot Standby) redundancy pattern
  - Active-Passive: Má»™t node chÃ­nh (active) xá»­ lÃ½ traffic, trong khi node phá»¥ (passive) á»Ÿ tráº¡ng thÃ¡i chá». Náº¿u node chÃ­nh há»ng, node phá»¥ sáº½ Ä‘Æ°á»£c kÃ­ch hoáº¡t Ä‘á»ƒ tiáº¿p quáº£n.
- [ ] Äá»c vá» Active-Passive (Cold Standby) redundancy pattern
  - Active-Passive (Cold Standby): Node phá»¥ khÃ´ng hoáº¡t Ä‘á»™ng vÃ  khÃ´ng sáºµn sÃ ng ngay láº­p tá»©c. Khi node chÃ­nh há»ng, node phá»¥ cáº§n thá»i gian Ä‘á»ƒ khá»Ÿi Ä‘á»™ng vÃ  tiáº¿p quáº£n.
- [ ] So sÃ¡nh: Active-Active vs Active-Passive (3 Ä‘iá»ƒm khÃ¡c biá»‡t)
  - 1ï¸âƒ£ Hiá»‡u suáº¥t & TÃ i nguyÃªn 
    - Active-Active: Táº¥t cáº£ node Ä‘á»u xá»­ lÃ½ request â†’ táº­n dá»¥ng tá»‘i Ä‘a tÃ i nguyÃªn. 
    - Active-Passive: Chá»‰ node chÃ­nh hoáº¡t Ä‘á»™ng â†’ node phá»¥ gáº§n nhÆ° â€œÄ‘á»ƒ khÃ´ngâ€.
  - 2ï¸âƒ£ Thá»i gian Failover (Chuyá»ƒn Ä‘á»•i khi lá»—i)
    - Active-Active: Gáº§n nhÆ° khÃ´ng giÃ¡n Ä‘oáº¡n (vÃ¬ node khÃ¡c Ä‘ang cháº¡y sáºµn). 
    - Active-Passive: Pháº£i chá» chuyá»ƒn sang node phá»¥ â†’ cÃ³ downtime ngáº¯n. 
  - 3ï¸âƒ£ Äá»™ phá»©c táº¡p & Chi phÃ­
    - Active-Active:
    â†’ Phá»©c táº¡p hÆ¡n (sync data, conflict)
    â†’ Chi phÃ­ cao hÆ¡n.

    - Active-Passive:
    â†’ Dá»… quáº£n lÃ½
    â†’ Chi phÃ­ tháº¥p hÆ¡n.

  - ğŸ“Œ Báº£n rÃºt gá»n Ä‘á»ƒ há»c thuá»™c 
    - Náº¿u cáº§n nhá»› nhanh trong phá»ng váº¥n/thi:
      - Active-Active: Nhanh â€“ Tá»‘n tiá»n â€“ Phá»©c táº¡p 
      - Active-Passive: Ráº» â€“ Dá»… â€“ Cháº­m hÆ¡n khi fail
- [ ] TÃ¬m 2 real-world examples cá»§a Active-Active
  - 1. Há»‡ thá»‘ng DNS toÃ n cáº§u (vÃ­ dá»¥: Google Public DNS)
    - Nhiá»u server DNS hoáº¡t Ä‘á»™ng Ä‘á»“ng thá»i trÃªn toÃ n tháº¿ giá»›i Ä‘á»ƒ xá»­ lÃ½ cÃ¡c truy váº¥n DNS. Náº¿u má»™t server gáº·p sá»± cá»‘, cÃ¡c server khÃ¡c váº«n tiáº¿p tá»¥c phá»¥c vá»¥ ngÆ°á»i dÃ¹ng mÃ  khÃ´ng giÃ¡n Ä‘oáº¡n.
  - 2. Há»‡ thá»‘ng cÃ¢n báº±ng táº£i web (Load Balancer)
    - Nhiá»u mÃ¡y chá»§ web hoáº¡t Ä‘á»™ng song song Ä‘á»ƒ xá»­ lÃ½ cÃ¡c yÃªu cáº§u tá»« ngÆ°á»i dÃ¹ng. Náº¿u má»™t mÃ¡y chá»§ gáº·p sá»± cá»‘, cÃ¡c mÃ¡y chá»§ cÃ²n láº¡i váº«n tiáº¿p tá»¥c phá»¥c vá»¥ mÃ  khÃ´ng áº£nh hÆ°á»Ÿng Ä‘áº¿n tráº£i nghiá»‡m ngÆ°á»i dÃ¹ng.
- [ ] TÃ¬m 2 real-world examples cá»§a Active-Passive
  - 1. Há»‡ thá»‘ng cÆ¡ sá»Ÿ dá»¯ liá»‡u vá»›i replica
    - Má»™t cÆ¡ sá»Ÿ dá»¯ liá»‡u chÃ­nh (primary) xá»­ lÃ½ táº¥t cáº£ cÃ¡c giao dá»‹ch, trong khi má»™t báº£n sao (replica) á»Ÿ tráº¡ng thÃ¡i chá». Náº¿u cÆ¡ sá»Ÿ dá»¯ liá»‡u chÃ­nh gáº·p sá»± cá»‘, báº£n sao sáº½ Ä‘Æ°á»£c kÃ­ch hoáº¡t Ä‘á»ƒ tiáº¿p quáº£n.
    - VÃ­ dá»¥: MySQL Master-Slave Replication. 
  - 2. Há»‡ thá»‘ng mÃ¡y chá»§ á»©ng dá»¥ng vá»›i mÃ¡y chá»§ dá»± phÃ²ng
    - Má»™t mÃ¡y chá»§ á»©ng dá»¥ng chÃ­nh xá»­ lÃ½ táº¥t cáº£ cÃ¡c yÃªu cáº§u tá»« ngÆ°á»i dÃ¹ng, trong khi má»™t mÃ¡y chá»§ dá»± phÃ²ng á»Ÿ tráº¡ng thÃ¡i chá». Náº¿u mÃ¡y chá»§ chÃ­nh gáº·p sá»± cá»‘, mÃ¡y chá»§ dá»± phÃ²ng sáº½ Ä‘Æ°á»£c kÃ­ch hoáº¡t Ä‘á»ƒ tiáº¿p quáº£n.
    - VÃ­ dá»¥: Há»‡ thá»‘ng web sá»­ dá»¥ng Nginx vá»›i má»™t mÃ¡y chá»§ dá»± phÃ²ng.

### Bottleneck Identification

- [ ] Liá»‡t kÃª 4 loáº¡i bottlenecks chÃ­nh: CPU, Memory, I/O, Network
  - CPU Bottleneck: Khi CPU Ä‘áº¡t 100% sá»­ dá»¥ng, khÃ´ng thá»ƒ xá»­ lÃ½ thÃªm yÃªu cáº§u.
  - Memory Bottleneck: Khi há»‡ thá»‘ng háº¿t RAM, dáº«n Ä‘áº¿n viá»‡c sá»­ dá»¥ng swap hoáº·c crash.
  - I/O Bottleneck: Khi tá»‘c Ä‘á»™ Ä‘á»c/ghi Ä‘Ä©a cháº­m, lÃ m cháº­m toÃ n bá»™ há»‡ thá»‘ng.
  - Network Bottleneck: Khi bÄƒng thÃ´ng tháº¥p hoáº·c latency cao â†’ request timeout, service giao tiáº¿p cháº­m.
- [ ] Vá»›i má»—i bottleneck, viáº¿t 2 cÃ¡ch identify
  - CPU Bottleneck:
    1. Sá»­ dá»¥ng cÃ´ng cá»¥ giÃ¡m sÃ¡t há»‡ thá»‘ng (nhÆ° top, htop) Ä‘á»ƒ kiá»ƒm tra má»©c sá»­ dá»¥ng CPU.
    2. PhÃ¢n tÃ­ch logs Ä‘á»ƒ tÃ¬m cÃ¡c request cÃ³ thá»i gian xá»­ lÃ½ lÃ¢u, cÃ³ thá»ƒ do CPU quÃ¡ táº£i.
  - Memory Bottleneck:
    1. Kiá»ƒm tra má»©c sá»­ dá»¥ng RAM báº±ng cÃ´ng cá»¥ giÃ¡m sÃ¡t há»‡ thá»‘ng (nhÆ° free, vmstat).
    2. Quan sÃ¡t cÃ¡c lá»—i liÃªn quan Ä‘áº¿n OutOfMemory hoáº·c swap usage trong logs.
  - I/O Bottleneck:
    1. Sá»­ dá»¥ng cÃ´ng cá»¥ nhÆ° iostat Ä‘á»ƒ kiá»ƒm tra tá»‘c Ä‘á»™ Ä‘á»c/ghi Ä‘Ä©a vÃ  thá»i gian chá» I/O.
    2. PhÃ¢n tÃ­ch logs Ä‘á»ƒ tÃ¬m cÃ¡c request cÃ³ thá»i gian xá»­ lÃ½ lÃ¢u liÃªn quan Ä‘áº¿n I/O.
  - Network Bottleneck:
    1. Sá»­ dá»¥ng cÃ´ng cá»¥ nhÆ° iftop hoáº·c nload Ä‘á»ƒ giÃ¡m sÃ¡t bÄƒng thÃ´ng máº¡ng.
    2. Kiá»ƒm tra logs Ä‘á»ƒ tÃ¬m cÃ¡c lá»—i timeout hoáº·c Ä‘á»™ trá»… cao trong giao tiáº¿p giá»¯a cÃ¡c dá»‹ch vá»¥.
  
- [ ] Vá»›i má»—i bottleneck, viáº¿t 2 cÃ¡ch resolve
  - CPU Bottleneck:
    1. Tá»‘i Æ°u hÃ³a code Ä‘á»ƒ giáº£m táº£i CPU (vÃ­ dá»¥: giáº£m Ä‘á»™ phá»©c táº¡p thuáº­t toÃ¡n).
    2. ThÃªm nhiá»u instance cá»§a service Ä‘á»ƒ phÃ¢n phá»‘i táº£i (horizontal scaling).
  - Memory Bottleneck:
    1. Tá»‘i Æ°u hÃ³a viá»‡c sá»­ dá»¥ng bá»™ nhá»› trong á»©ng dá»¥ng (vÃ­ dá»¥: giáº£m memory leaks).
    2. NÃ¢ng cáº¥p pháº§n cá»©ng hoáº·c thÃªm swap space.
  - I/O Bottleneck:
    1. Sá»­ dá»¥ng caching Ä‘á»ƒ giáº£m sá»‘ láº§n truy cáº­p Ä‘Ä©a.
    2. NÃ¢ng cáº¥p pháº§n cá»©ng lÆ°u trá»¯ (vÃ­ dá»¥: sá»­ dá»¥ng SSD thay vÃ¬ HDD).
  - Network Bottleneck:
    1. Tá»‘i Æ°u hÃ³a giao tiáº¿p máº¡ng (vÃ­ dá»¥: giáº£m kÃ­ch thÆ°á»›c payload).
    2. Sá»­ dá»¥ng CDN hoáº·c edge servers Ä‘á»ƒ giáº£m táº£i máº¡ng.
- [ ] Äá»c vá» "Amdahl's Law" trong context cá»§a bottlenecks
  - Amdahl's Law: Tá»‘c Ä‘á»™ tá»‘i Ä‘a cá»§a há»‡ thá»‘ng khi cáº£i thiá»‡n má»™t pháº§n phá»¥ thuá»™c vÃ o tá»· lá»‡ pháº§n Ä‘Ã³ trong tá»•ng thá»i gian xá»­ lÃ½.
  - CÃ´ng thá»©c: Speedup = 1 / (S + P/N)
    - S = Pháº§n serial (khÃ´ng thá»ƒ parallel)
    - P = Pháº§n parallel (cÃ³ thá»ƒ parallel)
    - N = Sá»‘ lÆ°á»£ng Ä‘Æ¡n vá»‹ xá»­ lÃ½ (cores, servers)
    - â†’ Náº¿u pháº§n serial lá»›n (bottleneck) â†’ speedup bá»‹ giá»›i háº¡n.
    - â†’ Cáº§n giáº£m pháº§n serial (bottleneck) Ä‘á»ƒ Ä‘áº¡t speedup tá»‘t hÆ¡n.
    - VÃ­ dá»¥: Náº¿u 30% thá»i gian lÃ  serial â†’ max speedup = 1 / 0.3 â‰ˆ 3.33x dÃ¹ cÃ³ bao nhiÃªu cores.
    - â†’ Giáº£i phÃ¡p: Giáº£m pháº§n serial (bottleneck) Ä‘á»ƒ cáº£i thiá»‡n hiá»‡u suáº¥t tá»•ng thá»ƒ.

### Capacity Planning

- [ ] Äá»c vá» "back-of-envelope calculations"
  - Back-of-envelope calculations = Æ¯á»›c lÆ°á»£ng nhanh, sÆ¡ bá»™ Ä‘á»ƒ cÃ³ cÃ¡i nhÃ¬n tá»•ng quan vá» yÃªu cáº§u há»‡ thá»‘ng.
  - KhÃ´ng cáº§n chÃ­nh xÃ¡c tuyá»‡t Ä‘á»‘i, chá»‰ cáº§n Ä‘á»§ gáº§n Ä‘á»ƒ Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh ban Ä‘áº§u.
  - VÃ­ dá»¥: Æ¯á»›c lÆ°á»£ng sá»‘ lÆ°á»£ng server cáº§n thiáº¿t dá»±a trÃªn QPS vÃ  kháº£ nÄƒng xá»­ lÃ½ cá»§a má»—i server.
  - GiÃºp nhanh chÃ³ng Ä‘Ã¡nh giÃ¡ tÃ­nh kháº£ thi cá»§a thiáº¿t káº¿ há»‡ thá»‘ng.
  - ThÆ°á»ng dÃ¹ng trong giai Ä‘oáº¡n early design Ä‘á»ƒ trÃ¡nh over-engineering hoáº·c under-provisioning.
  - VÃ­ dá»¥: Náº¿u má»—i server xá»­ lÃ½ Ä‘Æ°á»£c 100 QPS vÃ  cáº§n phá»¥c vá»¥ 10,000 QPS â†’ Cáº§n Ã­t nháº¥t 100 servers (10,000 / 100).
  - GiÃºp xÃ¡c Ä‘á»‹nh cÃ¡c yÃªu cáº§u vá» tÃ i nguyÃªn nhÆ° CPU, RAM, Storage, Bandwidth.
  - Cáº§n káº¿t há»£p vá»›i cÃ¡c yáº¿u tá»‘ khÃ¡c nhÆ° redundancy, peak load, growth rate Ä‘á»ƒ cÃ³ káº¿ hoáº¡ch chÃ­nh xÃ¡c hÆ¡n.
- [ ] Há»c cÃ¡ch estimate: Storage requirements
  - Estimate storage = Sá»‘ lÆ°á»£ng users Ã— Data per user
  - CÃ¢n nháº¯c growth rate (dá»± kiáº¿n tÄƒng bao nhiÃªu data theo thá»i gian)
  - ThÃªm buffer (dá»± phÃ²ng) cho unexpected growth
  - Xem xÃ©t loáº¡i data (structured, unstructured) Ä‘á»ƒ chá»n storage phÃ¹ há»£p
  - TÃ­nh toÃ¡n backup storage náº¿u cáº§n
  - Xem xÃ©t retention policy (lÆ°u trá»¯ bao lÃ¢u)
  - 
  - TÃ­nh toÃ¡n tá»•ng storage cáº§n thiáº¿t = Current data + Growth + Buffer + Backup
  - VÃ­ dá»¥: 1M users Ã— 10MB/user = 10TB + growth + buffer
  - Chá»n storage type (HDD, SSD, Cloud storage) dá»±a trÃªn performance vÃ  cost
  - Láº­p káº¿ hoáº¡ch má»Ÿ rá»™ng storage khi cáº§n thiáº¿t
  - ÄÃ¡nh giÃ¡ cost liÃªn quan Ä‘áº¿n storage (per GB/month)
  - Xem xÃ©t data compression Ä‘á»ƒ giáº£m storage usage
  - TÃ­nh toÃ¡n IOPS requirements náº¿u cáº§n cho performance
  - Xem xÃ©t data access patterns (read-heavy, write-heavy) Ä‘á»ƒ chá»n storage phÃ¹ há»£p
  
- [ ] Há»c cÃ¡ch estimate: Bandwidth requirements
  - Estimate bandwidth = QPS Ã— Average response size
  - CÃ¢n nháº¯c peak load (gáº¥p bao nhiÃªu láº§n so vá»›i average)
  - ThÃªm buffer (dá»± phÃ²ng) cho unexpected spikes
  - Xem xÃ©t loáº¡i traffic (inbound, outbound)
  - TÃ­nh toÃ¡n tá»•ng bandwidth cáº§n thiáº¿t = Average bandwidth + Peak load + Buffer
  - VÃ­ dá»¥: 10K QPS Ã— 2KB = 20MB/s + peak + buffer
  - Chá»n network type (dedicated, shared, cloud) dá»±a trÃªn performance vÃ  cost
  - Láº­p káº¿ hoáº¡ch má»Ÿ rá»™ng bandwidth khi cáº§n thiáº¿t
  - ÄÃ¡nh giÃ¡ cost liÃªn quan Ä‘áº¿n bandwidth (per GB/month)
  - Xem xÃ©t data transfer patterns (bursty, steady) Ä‘á»ƒ chá»n network phÃ¹ há»£p
  - TÃ­nh toÃ¡n latency requirements náº¿u cáº§n cho performance
  
- [ ] Há»c cÃ¡ch estimate: Compute requirements
  - Estimate compute = QPS / Requests per CPU core
  - CÃ¢n nháº¯c peak load (gáº¥p bao nhiÃªu láº§n so vá»›i average)
  - ThÃªm buffer (dá»± phÃ²ng) cho unexpected spikes
  - TÃ­nh toÃ¡n tá»•ng compute cáº§n thiáº¿t = Average compute + Peak load + Buffer
  - VÃ­ dá»¥: 10K QPS / 100 RPS/core = 100 cores + peak + buffer
  
  - Chá»n instance type (CPU, RAM) dá»±a trÃªn performance vÃ  cost
  - Láº­p káº¿ hoáº¡ch má»Ÿ rá»™ng compute khi cáº§n thiáº¿t
  - ÄÃ¡nh giÃ¡ cost liÃªn quan Ä‘áº¿n compute (per hour)
  - Xem xÃ©t auto-scaling Ä‘á»ƒ tá»‘i Æ°u chi phÃ­
  - TÃ­nh toÃ¡n power vÃ  cooling requirements náº¿u cáº§n cho data center
  - Xem xÃ©t workload type (CPU-bound, I/O-bound) Ä‘á»ƒ chá»n instance phÃ¹ há»£p
  - TÃ­nh toÃ¡n redundancy requirements (n+1, n+2) náº¿u cáº§n cho availability
  - Xem xÃ©t virtualization/containerization Ä‘á»ƒ tá»‘i Æ°u resource usage
  - TÃ­nh toÃ¡n licensing costs náº¿u dÃ¹ng pháº§n má»m cÃ³ phÃ­
- [ ] Practice: Estimate storage cho 1M users, má»—i user 10MB data
  - Step 1: 1M users Ã— 10MB/user = 10TB
  - Step 2: Growth rate = 10%/month â†’ 1TB/month
  - Step 3: Buffer = 20% of current = 2TB
  - Step 4: Backup storage = 50% of current = 5TB
  - Total storage = 10TB + 1TB/month + 2TB + 5TB = 18TB + growth
  - Chá»n storage type: SSD cho performance tá»‘t
  - Estimate cost: $0.10/GB/month â†’ 18TB = $1,800/month
  - Plan for expansion: Monitor usage, add storage khi cáº§n
  - Document calculations trong spreadsheet
  - Verify numbers cÃ³ há»£p lÃ½ khÃ´ng?
  
- [ ] Practice: Estimate bandwidth cho 10K QPS, má»—i request 2KB response
  - Step 1: 10K QPS Ã— 2KB = 20MB/s
  - Step 2: Peak load = 5x average = 100MB/s
  - Step 3: Buffer = 20% of peak = 20MB/s
  - Total bandwidth = 20MB/s + 100MB/s + 20MB/s = 140MB/s
  - Chá»n network type: Dedicated connection
  - Estimate cost: $0.05/GB/month â†’ 140MB/s â‰ˆ 360TB/month = $18,000/month
  - Plan for expansion: Monitor usage, upgrade bandwidth khi cáº§n
  - Document calculations trong spreadsheet
  - Verify numbers cÃ³ há»£p lÃ½ khÃ´ng?

---

## Design TODOs

### Design Exercise 1: Payment Gateway

- [ ] Thiáº¿t káº¿ architecture diagram cho Payment Gateway (10K TPS, 99.9% uptime)
- [ ] Váº½ diagram vá»›i cÃ¡c components: API Gateway, Payment Service, Database, Cache
- [ ] Label má»—i component vá»›i estimated QPS capacity
- [ ] Identify Ã­t nháº¥t 3 SPOF trong design Ä‘áº§u tiÃªn
- [ ] Redesign Ä‘á»ƒ eliminate táº¥t cáº£ SPOF
- [ ] TÃ­nh toÃ¡n: Cáº§n bao nhiÃªu instances cho má»—i service? (show calculations)
- [ ] Design redundancy strategy cho database
- [ ] Design redundancy strategy cho application servers
- [ ] Estimate: Total cost (rough) cho infrastructure
- [ ] Viáº¿t document (500 words) giáº£i thÃ­ch design decisions

#### Deliverable: Payment Gateway Design (10K TPS, 99.9% uptime)

> Má»¥c tiÃªu: xÃ¢y há»‡ thá»‘ng â€œpayment orchestrationâ€ cho merchant/app ná»™i bá»™, káº¿t ná»‘i nhiá»u PSP (VNPay/MoMo/Stripe/Adyen...). Táº­p trung: **Ä‘Ãºng tiá»n**, **idempotent**, **chá»‹u lá»—i**, **scale 10K TPS**.

##### 1) Assumptions (Ä‘á»ƒ tÃ­nh toÃ¡n)

- **Peak**: 10K TPS (transactions/second) á»Ÿ endpoint táº¡o payment (authorize/charge).
- **Headroom**: thiáº¿t káº¿ **2Ã— peak** Ä‘á»ƒ háº¥p thá»¥ spike + failover â†’ \(TPS_{design}=20K\).
- **Read/Write split**:
  - Write path (create/confirm/capture/refund): ~20K TPS thiáº¿t káº¿.
  - Read path (status/query): giáº£ sá»­ 3Ã— write â†’ 60K RPS Ä‘á»c (Ä‘a pháº§n cacheable).
- **SLO**:
  - Availability: 99.9% (downtime budget ~ 43.2 phÃºt/thÃ¡ng).
  - Latency má»¥c tiÃªu: p95 < 200ms cho â€œcreate intentâ€ (khÃ´ng bao gá»“m thá»i gian PSP xá»­ lÃ½ async).
- **Consistency**: ledger pháº£i strong/serializable á»Ÿ má»©c giao dá»‹ch; cÃ²n â€œstatus viewâ€ cÃ³ thá»ƒ eventual.

##### 2) High-level architecture (ASCII diagram)

```text
Clients/Merchants
     |
 [Anycast DNS]  (multi-region optional)
     |
  [WAF/CDN]  (rate-limit, bot, DDoS)
     |
  [API Gateway / LB]  (stateless, multi-AZ)
     |
  [AuthN/AuthZ]----->(JWT/OAuth2, mTLS for internal)
     |
  [Payment API / Orchestrator]  (stateless)
     |         |        |
     |         |        +--> [Idempotency Store (Redis)]  (idempotency-key -> outcome)
     |         |
     |         +--> [Fraud/Risk Service] (async + rules)
     |
     +--> [Outbox Publisher] ---> [Queue/Stream (Kafka/SQS)] ---> [PSP Adapter Workers] ---> [PSP(s)]
     |                                  |                              |
     |                                  |                              +--> PSP webhooks/callbacks
     |                                  |
     |                                  +--> [Reconciliation Jobs] <--- PSP reports
     |
     +--> [Ledger DB] (multi-AZ, partition/shard)
     |
  [Read Model / Cache] (Redis) ---> [GET status APIs]
     |
 [Metrics/Logs/Tracing] (Prometheus/Grafana + ELK + OpenTelemetry)
```

##### 3) Core flows (tÃ³m táº¯t)

- **Create payment (POST /payments)**:
  - Validate + auth.
  - Check **Idempotency-Key** (Redis): náº¿u Ä‘Ã£ cÃ³ result â†’ tráº£ láº¡i Ä‘Ãºng response cÅ©.
  - Create `payment_intent` + `ledger_entry (PENDING)` trong DB (transaction).
  - Ghi event vÃ o **outbox** (same DB transaction) â†’ publisher Ä‘áº©y sang queue.
  - Tráº£ vá» `payment_id` + tráº¡ng thÃ¡i `PENDING` (async).
- **Process payment (worker)**:
  - Consume event â†’ gá»i PSP adapter tÆ°Æ¡ng á»©ng.
  - Nháº­n result sync/async â†’ cáº­p nháº­t ledger (CAPTURED/FAILED) + ghi audit.
  - Emit event cáº­p nháº­t read-model/cache.
- **Webhook/callback tá»« PSP**:
  - Verify signature + replay protection.
  - Map vá» `payment_id` vÃ  apply state machine (idempotent).

##### 4) SPOF trong â€œdesign Ä‘áº§u tiÃªnâ€ vÃ  cÃ¡ch eliminate

- **SPOF #1: 1 instance Payment Service**
  - Fix: stateless service + **N instances** sau LB, autoscaling, multi-AZ.
- **SPOF #2: 1 database single-node**
  - Fix: DB **multi-AZ** + automatic failover; thÃªm read replicas; partition/shard theo `merchant_id`/`payment_id`.
- **SPOF #3: 1 Redis node (idempotency/cache)**
  - Fix: Redis cluster (primary-replica + multi-AZ) hoáº·c managed (ElastiCache) + persistence phÃ¹ há»£p.
- **SPOF #4: gá»i PSP trá»±c tiáº¿p synchronous trong request path**
  - Fix: async báº±ng queue/stream; request path chá»‰ â€œenqueue + persistâ€.
- **SPOF #5: 1 queue broker**
  - Fix: managed multi-AZ (Kafka cluster/MSK) hoáº·c SQS; producer/consumer retry + DLQ.

##### 5) Capacity & instance calculations (Ä‘Æ¡n giáº£n, cÃ³ cÃ´ng thá»©c)

Thiáº¿t káº¿ theo \(TPS_{design}=20K\).

- **API Gateway/LB tier**
  - Giáº£ sá»­ 1 node handle ~ **5K RPS** (L7 routing + auth offload cÆ¡ báº£n), dÃ¹ng 50% utilization.
  - Required nodes \(= 20K / (5K * 0.5) = 8\) â†’ **8â€“10 nodes** (multi-AZ).
- **Payment Orchestrator**
  - Má»¥c tiÃªu: chá»§ yáº¿u DB write + Redis read/write + enqueue; khÃ´ng chá» PSP.
  - Giáº£ sá»­ 1 instance handle **1K TPS** á»Ÿ 50% util.
  - Required \(= 20K / (1K * 0.5)=40\) â†’ **40â€“50 instances**.
- **PSP Adapter Workers**
  - Phá»¥ thuá»™c latency PSP; giáº£ sá»­ 1 worker handle **100 TPS** (do I/O + retries), 50% util.
  - Required \(= 20K / (100 * 0.5)=400\) â†’ **400â€“500 workers** (chia theo PSP + quota).
- **Redis (idempotency + cache)**
  - Ops/sec: create path ~2â€“3 ops/payment (GET+SET+TTL) â†’ ~60K ops/s á»Ÿ design peak.
  - DÃ¹ng cluster sharding; chá»n sá»‘ shard Ä‘á»ƒ giá»¯ CPU < 60% vÃ  cÃ³ replica.
- **Ledger DB**
  - Write: tá»‘i thiá»ƒu 1 record/payment + index updates â†’ ~20K writes/s (design).
  - Giáº£i phÃ¡p:
    - Option A: **NewSQL (CockroachDB/Spanner)** Ä‘á»ƒ scale write ngang.
    - Option B: Postgres/MySQL partition + **sharding** theo `merchant_id` (hoáº·c consistent-hash `payment_id`), má»—i shard multi-AZ.

> Ghi chÃº: cÃ¡c sá»‘ â€œTPS per instanceâ€ lÃ  giáº£ Ä‘á»‹nh Ä‘á»ƒ luyá»‡n capacity planning; trong thá»±c táº¿ pháº£i benchmark (load test) rá»“i hiá»‡u chá»‰nh.

##### 6) Redundancy strategy

- **Application servers**
  - Stateless + autoscaling; deploy **>= 2 AZ**, má»—i AZ giá»¯ tá»‘i thiá»ƒu 40â€“50% capacity Ä‘á»ƒ chá»‹u AZ failure.
  - Rolling deploy + canary; circuit breaker khi PSP lá»—i.
- **Database**
  - Multi-AZ + automatic failover.
  - Read replicas cho query/report; write scaling báº±ng sharding/NewSQL.
  - PITR backups + immutable audit log (append-only) cho ledger.
- **Queue/Stream**
  - Multi-AZ; DLQ cho poison messages; at-least-once + idempotent consumer.

##### 7) Data model (tá»‘i thiá»ƒu)

- `payment_intents(payment_id, merchant_id, amount, currency, status, idempotency_key_hash, created_at, updated_at, psp, psp_ref)`
- `ledger_entries(entry_id, payment_id, type, amount, status, created_at)` (append-only)
- `outbox_events(event_id, aggregate_id, type, payload, created_at, published_at)`
- `webhook_events(event_id, psp, psp_event_id, signature_ok, received_at)` (dedupe)

##### 8) Key correctness & security points

- **Idempotency** báº¯t buá»™c á»Ÿ má»i endpoint â€œmoney-movingâ€ (create/capture/refund).
- **State machine** rÃµ rÃ ng (PENDING â†’ CAPTURED/FAILED/REVERSED), reject transitions sai.
- **Exactly-once effect** báº±ng: outbox + idempotent consumers + unique constraints.
- **Webhook verification**: signature, timestamp, nonce; store dedupe key `psp_event_id`.
- **PII/PCI**: khÃ´ng lÆ°u PAN; tokenize; mÃ£ hÃ³a at-rest + in-transit; least privilege IAM.

##### 9) Rough cost estimate (ráº¥t thÃ´, Ä‘á»ƒ luyá»‡n táº­p)

VÃ­ dá»¥ AWS (chá»‰ minh há»a):
- Compute:
  - Orchestrator: 50 pods/instances (má»—i cÃ¡i ~2 vCPU/4GB) + workers 500 (nhá» hÆ¡n, autoscale theo queue lag).
- Data:
  - Redis cluster (multi-AZ), DB cluster/shards, Kafka/MSK hoáº·c SQS.
- Infra:
  - ALB/NLB, NAT, logs/metrics.

**Order-of-magnitude**: vÃ i chá»¥c nghÃ¬n USD/thÃ¡ng Ä‘áº¿n >100K USD/thÃ¡ng tÃ¹y benchmark, PSP latency, retention logs, vÃ  cÃ¡ch scale DB/stream.

##### 10) 500-word design decisions (tÃ³m táº¯t)

Thiáº¿t káº¿ chá»n mÃ´ hÃ¬nh â€œpayment orchestrationâ€ tÃ¡ch request path khá»i PSP báº±ng cÆ¡ cháº¿ async (queue/stream) Ä‘á»ƒ Ä‘áº£m báº£o há»‡ thá»‘ng chá»‹u Ä‘Æ°á»£c 10K TPS vÃ  khÃ´ng bá»‹ phá»¥ thuá»™c latency/availability cá»§a PSP. TÃ­nh Ä‘Ãºng tiá»n Æ°u tiÃªn hÃ ng Ä‘áº§u nÃªn dá»¯ liá»‡u ledger Ä‘Æ°á»£c ghi bá»n vá»¯ng trong DB theo mÃ´ hÃ¬nh append-only vÃ  cÃ³ state machine rÃµ rÃ ng; má»i thao tÃ¡c gÃ¢y side-effect Ä‘á»u báº¯t buá»™c idempotent dá»±a trÃªn Idempotency-Key vÃ /hoáº·c khÃ³a unique trong DB. Äá»ƒ trÃ¡nh máº¥t event khi publish, dÃ¹ng outbox pattern: ghi DB vÃ  outbox trong cÃ¹ng transaction, sau Ä‘Ã³ publisher má»›i Ä‘áº©y sang queue; consumer xá»­ lÃ½ at-least-once nhÆ°ng báº£o toÃ n â€œexactly-once effectâ€ nhá» idempotent processing. Vá» availability 99.9%, loáº¡i bá» SPOF báº±ng cÃ¡ch triá»ƒn khai Ä‘a AZ cho má»i tier: API gateway/LB, service stateless autoscaling, Redis cluster, queue multi-AZ, DB multi-AZ vÃ  chiáº¿n lÆ°á»£c scale-write báº±ng sharding hoáº·c NewSQL. Read-heavy traffic Ä‘Æ°á»£c phá»¥c vá»¥ qua cache/read-model Ä‘á»ƒ giáº£m táº£i DB vÃ  giáº£m latency cho GET status. Security táº­p trung vÃ o mTLS ná»™i bá»™, xÃ¡c thá»±c/á»§y quyá»n á»Ÿ gateway, kiá»ƒm tra chá»¯ kÃ½ webhook, chá»‘ng replay, vÃ  tuÃ¢n thá»§ PCI (khÃ´ng lÆ°u PAN, tokenize). Cuá»‘i cÃ¹ng, kháº£ nÄƒng váº­n hÃ nh Ä‘Æ°á»£c Ä‘áº£m báº£o bá»Ÿi quan sÃ¡t (metrics/logs/tracing), circuit breaker vÃ  retry/backoff cho PSP, DLQ cho message lá»—i, vÃ  reconciliation job Ä‘á»ƒ Ä‘á»‘i soÃ¡t khi PSP tráº£ káº¿t quáº£ trá»… hoáº·c sai lá»‡ch.

##### 11) Mark TODOs as completed (khi báº¡n review xong)

- [x] Thiáº¿t káº¿ architecture diagram cho Payment Gateway (10K TPS, 99.9% uptime)
- [x] Váº½ diagram vá»›i cÃ¡c components: API Gateway, Payment Service, Database, Cache
- [x] Label má»—i component vá»›i estimated QPS capacity
- [x] Identify Ã­t nháº¥t 3 SPOF trong design Ä‘áº§u tiÃªn
- [x] Redesign Ä‘á»ƒ eliminate táº¥t cáº£ SPOF
- [x] TÃ­nh toÃ¡n: Cáº§n bao nhiÃªu instances cho má»—i service? (show calculations)
- [x] Design redundancy strategy cho database
- [x] Design redundancy strategy cho application servers
- [x] Estimate: Total cost (rough) cho infrastructure
- [x] Viáº¿t document (500 words) giáº£i thÃ­ch design decisions

### Design Exercise 2: Betting Platform

- [ ] Thiáº¿t káº¿ architecture cho Betting Platform (100K concurrent users)
  **Components:** Load Balancer â†’ API Gateway â†’ Betting Service (stateless, N instances) â†’ Cache (Redis cluster) â†’ Database (Primary + Read Replicas). Message Queue cho settlement async.
  **100K concurrent users:** Giáº£ sá»­ 10% active (place bet/query) â†’ 10K RPS. Má»—i instance 2K RPS â†’ cáº§n â‰¥5 app instances. DB: write ~2K TPS (place bet), read ~8K QPS (odds, history) â†’ read replicas.
- [ ] Identify bottleneck trong design (CPU, Memory, I/O, Network - chá»n 1)
  **Chá»n: I/O (Database).** LÃ½ do: Write path (place bet) pháº£i ghi DB + validate odds + update balance â†’ nhiá»u query/transaction. Read path (odds, live score) ráº¥t high QPS. DB dá»… thÃ nh bottleneck trÆ°á»›c CPU/Memory cá»§a app.
- [ ] Design solution Ä‘á»ƒ resolve bottleneck Ä‘Ã³
  **Giáº£i phÃ¡p:** (1) Read replicas cho read-heavy (odds, history). (2) Cache layer (Redis) cho odds, hot matches. (3) Write: connection pooling, batch náº¿u cÃ³ thá»ƒ. (4) Partition/shard theo match_id hoáº·c user_id náº¿u 1 DB khÃ´ng Ä‘á»§.
- [ ] TÃ­nh toÃ¡n: Peak traffic = 10x normal, design Ä‘á»ƒ handle
  **Normal:** 10K RPS. **Peak:** 100K RPS. **Design:** Auto-scaling app (min 5, max 50 instances). DB: Ä‘á»§ read replicas (10â€“20) + cache hit rate cao (80%+). Queue cho settlement Ä‘á»ƒ tÃ¡ch burst write khá»i real-time bet.
- [ ] Design horizontal scaling strategy
  **Strategy:** Stateless app servers; scale out theo CPU/RPS. Load balancer (L7). Database: thÃªm read replicas; khi write bottleneck â†’ shard (e.g. by match_id). Cache: Redis cluster. Queue: Kafka/RabbitMQ partition theo match hoáº·c user.
- [ ] Design vertical scaling strategy (náº¿u cáº§n)
  **Khi nÃ o dÃ¹ng:** DB primary cÃ³ thá»ƒ scale vertical trÆ°á»›c khi shard (nhiá»u CPU/RAM cho connection vÃ  query). Cache node cÃ³ thá»ƒ tÄƒng memory. **Giá»›i háº¡n:** Vertical cÃ³ ceiling (max instance size) â†’ dÃ i háº¡n váº«n cáº§n horizontal (replica, shard).
- [ ] So sÃ¡nh: Horizontal vs Vertical cho use case nÃ y (viáº¿t 3 Ä‘iá»ƒm)
  1. **Burst traffic (World Cup, big match):** Horizontal phÃ¹ há»£p hÆ¡n (thÃªm app + replica), vertical khÃ´ng Ä‘á»§ nhanh vÃ  cÃ³ limit.  
  2. **Cost:** Vertical Ä‘Æ¡n giáº£n, ráº» lÃºc nhá»; horizontal tá»‘n thÃªm LB, ops, nhÆ°ng scale Ä‘Æ°á»£c xa hÆ¡n.  
  3. **Bottleneck DB:** Vertical cho primary cÃ³ thá»ƒ kÃ©o dÃ i thá»i gian trÆ°á»›c khi pháº£i shard; horizontal (replica, shard) lÃ  hÆ°á»›ng táº¥t yáº¿u khi data vÃ  QPS lá»›n.
- [ ] Estimate: Latency cho má»—i component (p50, p95, p99)
  **API Gateway:** p50 2ms, p95 10ms, p99 25ms. **App (Betting Service):** p50 5ms, p95 30ms, p99 80ms. **Cache (Redis):** p50 1ms, p95 3ms, p99 8ms. **DB (read):** p50 5ms, p95 20ms, p99 50ms. **DB (write):** p50 10ms, p95 40ms, p99 100ms. **End-to-end place bet:** p50 ~25ms, p95 ~100ms, p99 ~250ms.
- [ ] Identify: Component nÃ o sáº½ lÃ  bottleneck? Táº¡i sao?
  **Database (write path).** LÃ½ do: Má»—i bet = transaction (insert bet, update balance, validate odds). Write TPS cÃ³ giá»›i háº¡n (disk, lock). Read cÃ³ thá»ƒ scale báº±ng replica + cache; write khÃ³ scale hÆ¡n â†’ dá»… bottleneck nháº¥t.
- [ ] Viáº¿t document (500 words) vá» scaling strategy
  *(Template â€“ Ä‘iá»n sá»‘ liá»‡u thá»±c táº¿ cá»§a báº¡n.)*
  **1. Má»¥c tiÃªu:** 100K concurrent users, peak 10x normal. **2. App tier:** Stateless, horizontal scaling (min/max instances), metric: CPU hoáº·c RPS. **3. Data tier:** Primary + N read replicas; cache (Redis) cho odds vÃ  hot data; queue cho settlement. **4. Bottleneck:** DB write â†’ giáº£m write path (batch, async settlement), tÄƒng read path (replica, cache). **5. Peak:** Auto-scale + cache warming + Ä‘á»§ replica; test load 100K RPS. **6. Trade-off:** Consistency (read-your-writes) vs scale (replica lag) â€“ chá»n strategy rÃµ rÃ ng (e.g. sticky session cho critical read sau write).

### Design Exercise 3: Load Estimation

- [ ] Scenario: E-commerce site, 1M daily active users
- [ ] Estimate: Peak QPS (assume 20% traffic trong 1 hour)
  **1M DAU, 20% trong 1h â†’ 200K users trong 1h.** Giáº£ sá»­ má»—i user 5 requests trong giá» peak â†’ 200K Ã— 5 = 1M requests / 3600s â‰ˆ **278 QPS**. Náº¿u peak hÆ¡n (e.g. 30% trong 30 phÃºt): 300K Ã— 5 / 1800 â‰ˆ **833 QPS**. *Ghi láº¡i assumption cá»§a báº¡n.*
- [ ] Estimate: Average request size (assume 5KB)
  **5KB** (header + body). CÃ³ thá»ƒ Ä‘iá»u chá»‰nh theo API thá»±c táº¿ (e.g. upload lá»›n hÆ¡n).
- [ ] Estimate: Average response size (assume 10KB)
  **10KB** (JSON product list, HTML snippet). CÃ³ thá»ƒ tÃ¡ch API nháº¹ (metadata) vs náº·ng (full page).
- [ ] Calculate: Total bandwidth requirement (Mbps)
  **Ingress:** 278 Ã— 5KB â‰ˆ 1.39 MB/s â‰ˆ **11.1 Mbps**. **Egress:** 278 Ã— 10KB â‰ˆ 2.78 MB/s â‰ˆ **22.2 Mbps**. Peak 833 QPS â†’ ~33 Mbps ingress, ~67 Mbps egress. *LÃ m trÃ²n theo nhÃ  cung cáº¥p (e.g. 50 Mbps, 100 Mbps).*
- [ ] Estimate: Database size (assume 1GB per 10K users)
  **1M users â†’ 1GB Ã— (1M/10K) = 100GB** (chá»‰ user/product metadata). ThÃªm orders, logs â†’ cÃ³ thá»ƒ 300â€“500GB. *Ghi láº¡i schema vÃ  growth rate.*
- [ ] Calculate: Storage growth rate (per month)
  VÃ­ dá»¥: 100GB base + 10GB/thÃ¡ng (orders, logs) â†’ thÃ¡ng 1: 110GB, thÃ¡ng 12: 210GB. *Äiá»n sá»‘ theo dá»± Ä‘oÃ¡n business.*
- [ ] Estimate: Cache size needed (assume 20% of DB size)
  **20% Ã— 100GB = 20GB** cache (hot products, sessions). Redis 20GB + overhead ~25GB. *CÃ³ thá»ƒ tÄƒng % náº¿u read-heavy.*
- [ ] Create spreadsheet vá»›i táº¥t cáº£ calculations
  Cá»™t: Metric, Formula, Value, Unit. DÃ²ng: Peak QPS, Request size, Response size, Ingress Mbps, Egress Mbps, DB size, Growth/month, Cache size.
- [ ] Verify: Táº¥t cáº£ numbers cÃ³ há»£p lÃ½ khÃ´ng? (write validation)
  **Validation:** (1) QPS so vá»›i 1M DAU â€“ 278â€“833 QPS há»£p lÃ½ cho e-commerce. (2) Bandwidth â€“ vÃ i chá»¥c Mbps há»£p lÃ½ cho 1 server/ vÃ i server. (3) DB 100GB cho 1M users â€“ há»£p lÃ½ náº¿u khÃ´ng lÆ°u blob lá»›n. (4) Cache 20% â€“ cÃ³ thá»ƒ Ä‘o hit rate sau vÃ  tinh chá»‰nh.

---

## Coding TODOs

### Task 1: Spring Boot Performance App

- [ ] Táº¡o Spring Boot project má»›i  
  `spring init --dependencies=web,actuator week1-perf-app`
- [ ] Táº¡o REST API endpoint: `GET /api/users/{id}` (return mock user data)  
  Return `User(id, name, email)` tá»« Map hoáº·c list in-memory.
- [ ] Táº¡o REST API endpoint: `POST /api/users` (create user, save to in-memory list)  
  Request body â†’ validate â†’ put vÃ o `ConcurrentHashMap` hoáº·c list.
- [ ] Add logging: Log request time cho má»—i endpoint  
  Filter/Interceptor: `long start = now(); ... log("duration_ms", now()-start)`.
- [ ] Add metrics: Count requests, measure latency  
  Micrometer: `Counter.builder("requests.total").register(registry); Timer` cho duration.
- [ ] Run app vÃ  test vá»›i 100 requests (manual hoáº·c script)  
  curl loop hoáº·c script (bash/Python) gá»i GET/POST, ghi thá»i gian.
- [ ] Measure: Average latency, p95 latency  
  Tá»« log hoáº·c tá»« `Timer` metrics (percentile).
- [ ] Document: Performance baseline  
  VÃ­ dá»¥: GET p50=12ms, p95=45ms; POST p50=8ms, p95=30ms; QPS ~X vá»›i 1 thread.

### Task 2: Load Testing Setup

- [ ] Install JMeter hoáº·c Gatling  
  JMeter: download; Gatling: sbt hoáº·c Maven.
- [ ] Táº¡o test plan cho `/api/users/{id}` endpoint  
  Thread group: N users, R ramp-up, loop M láº§n.
- [ ] Configure: 100 concurrent users, 1000 total requests  
  100 threads, 10 iterations hoáº·c 1000/100.
- [ ] Run load test  
  Cháº¡y vÃ  Ä‘á»£i káº¿t thÃºc, khÃ´ng cÃ³ error nghiÃªm trá»ng.
- [ ] Export results: QPS, latency (p50, p95, p99), error rate  
  JMeter: Summary Report, Aggregate Report; Gatling: report HTML.
- [ ] Identify: At what load does latency spike?  
  TÄƒng dáº§n threads (50, 100, 200, 500) â†’ ghi láº¡i khi p95 tÄƒng vá»t (e.g. > 2x).
- [ ] Identify: At what load do errors start?  
  Ghi láº¡i first N (threads hoáº·c RPS) khi cÃ³ 4xx/5xx hoáº·c timeouts.
- [ ] Document: Performance limits cá»§a app hiá»‡n táº¡i  
  VÃ­ dá»¥: Safe < 200 concurrent; latency spike at 300; errors from 500.
- [ ] Táº¡o report vá»›i charts (response time, throughput)  
  JMeter: Graphs; Gatling: máº·c Ä‘á»‹nh cÃ³ charts.

### Task 3: Performance Profiling

- [ ] Install VisualVM hoáº·c JProfiler  
  Download, cÃ i Ä‘áº·t, biáº¿t cÃ¡ch attach vÃ o JVM (PID hoáº·c remote).
- [ ] Attach profiler to Spring Boot app  
  Start app vá»›i JMX; VisualVM: connect â†’ Sampler hoáº·c Profiler.
- [ ] Run load test while profiling  
  Vá»«a cháº¡y JMeter/Gatling vá»«a profile (CPU, Memory).
- [ ] Identify: Top 5 methods by CPU time  
  Tab CPU: sort by self time hoáº·c total time, ghi tÃªn method.
- [ ] Identify: Memory allocation hotspots  
  Tab Allocations hoáº·c Heap; xem class nÃ o allocate nhiá»u.
- [ ] Check: Memory leaks (heap growth over time)  
  Heap dump 2â€“3 láº§n (cÃ¡ch nhau vÃ i phÃºt load) â†’ so sÃ¡nh; xem object nÃ o tÄƒng.
- [ ] Check: Thread contention  
  Tab Threads / Monitors; xem thread nÃ o blocked nhiá»u.
- [ ] Document: 3 performance issues found  
  VÃ­ dá»¥: (1) Method X chiáº¿m 40% CPU, (2) Class Y allocate nhiá»u, (3) Lock Z contention.
- [ ] Propose: 3 optimizations (khÃ´ng cáº§n implement, chá»‰ propose)  
  VÃ­ dá»¥: cache káº¿t quáº£ X, giáº£m táº¡o object Y, thu háº¹p lock scope Z.

### Task 4: Simple Load Balancer

- [ ] Táº¡o Java class: `SimpleLoadBalancer`  
  Field: `List<Backend> servers`, `AtomicInteger index` (round-robin).
- [ ] Implement: Round-robin algorithm  
  `getNextServer(): servers.get(index.getAndIncrement() % servers.size())`.
- [ ] Add: List of backend servers (hardcoded URLs)  
  Constructor nháº­n `List<String>` URLs.
- [ ] Add: `getNextServer()` method  
  Return URL (hoáº·c Backend object) theo round-robin.
- [ ] Add: Health check mechanism (ping endpoint)  
  Scheduled task: HTTP GET /health má»—i N giÃ¢y; Ä‘Ã¡nh dáº¥u unhealthy náº¿u fail.
- [ ] Add: Skip unhealthy servers  
  Trong `getNextServer()` chá»‰ chá»n server cÃ³ `healthy == true`.
- [ ] Test: With 3 mock backend servers  
  á»¨ng dá»¥ng hoáº·c mock server (e.g. WireMock) trÃªn 3 port.
- [ ] Test: Mark one server unhealthy, verify it's skipped  
  Táº¯t 1 server hoáº·c tráº£ 5xx â†’ gá»i getNextServer nhiá»u láº§n, khÃ´ng tráº£ server Ä‘Ã³.
- [ ] Measure: Overhead cá»§a load balancer (latency added)  
  So sÃ¡nh latency direct call vs qua LB (nÃªn < 1â€“2ms).
- [ ] Document: Code vÃ  test results  
  MÃ´ táº£ class, thuáº­t toÃ¡n, káº¿t quáº£ test vÃ  overhead.

### Task 5: Health Check Endpoints

- [ ] Add endpoint: `GET /health` (basic health check)  
  Spring Boot Actuator: `management.endpoint.health.probes.enabled=true` hoáº·c custom controller tráº£ 200.
- [ ] Add endpoint: `GET /health/readiness` (readiness probe)  
  Actuator: `readiness`; hoáº·c custom: check DB connection, náº¿u fail tráº£ 503.
- [ ] Add endpoint: `GET /health/liveness` (liveness probe)  
  Actuator: `liveness`; hoáº·c custom: process cÃ²n sá»‘ng (cÃ³ thá»ƒ luÃ´n 200).
- [ ] Implement: Database connection check trong readiness  
  `DataSource.getConnection()` hoáº·c query Ä‘Æ¡n giáº£n (e.g. SELECT 1); fail â†’ 503.
- [ ] Implement: Memory check trong liveness (fail if memory > 90%)  
  `Runtime.getRuntime().maxMemory()` vÃ  `totalMemory() - freeMemory()`; náº¿u used ratio > 0.9 â†’ 503.
- [ ] Test: All health endpoints return correct status  
  Gá»i tá»«ng endpoint khi app OK â†’ 200; khi DB down â†’ readiness 503.
- [ ] Test: Simulate DB down, verify readiness fails  
  Táº¯t DB hoáº·c sai connection string â†’ readiness 503, liveness váº«n 200.
- [ ] Test: Simulate high memory, verify liveness fails  
  (KhÃ³ trÃªn local: cÃ³ thá»ƒ mock hoáº·c giáº£m ngÆ°á»¡ng 90% xuá»‘ng Ä‘á»ƒ test.)
- [ ] Document: Khi nÃ o dÃ¹ng readiness vs liveness  
  Readiness: cÃ³ nháº­n traffic khÃ´ng (DB OK, cache OK). Liveness: process cÃ²n cháº¡y khÃ´ng (restart náº¿u die).

### Task 6: Metrics Collection

- [ ] Add Micrometer dependency  
  `spring-boot-starter-actuator` + `micrometer-registry-prometheus` (náº¿u export Prometheus).
- [ ] Expose metrics endpoint: `GET /actuator/metrics`  
  Báº­t `management.endpoints.web.exposure.include=health,metrics,prometheus`.
- [ ] Add custom metric: `requests.total` (counter)  
  `Counter.builder("requests.total").tag("uri", uri).register(registry).increment()`.
- [ ] Add custom metric: `request.duration` (timer)  
  `Timer.builder("request.duration").register(registry).record(duration)`.
- [ ] Instrument: All API endpoints vá»›i metrics  
  Filter/Interceptor: tÄƒng counter, record timer cho má»—i request.
- [ ] Verify: Metrics Ä‘Æ°á»£c update correctly  
  Gá»i API vÃ i láº§n â†’ má»Ÿ `/actuator/metrics/requests.total` vÃ  `request.duration` xem sá»‘ tÄƒng.
- [ ] Export: Metrics to Prometheus format (optional)  
  `GET /actuator/prometheus` tráº£ text format.
- [ ] Document: Metrics available vÃ  Ã½ nghÄ©a  
  Liá»‡t kÃª: requests_total, request_duration_seconds, jvm_memory_used, etc. vÃ  cÃ¡ch Ä‘á»c.

---

## Analysis TODOs

### Analysis Task 1: Bottleneck Analysis

- [ ] Chá»n má»™t Spring Boot app hiá»‡n táº¡i (hoáº·c táº¡o simple one)  
  DÃ¹ng app tá»« Task 1 (users API) hoáº·c app cÃ³ sáºµn.
- [ ] Run load test vá»›i increasing load: 10, 50, 100, 500, 1000 concurrent users  
  JMeter/Gatling: 5 test runs vá»›i N = 10, 50, 100, 500, 1000.
- [ ] Measure: Latency, throughput, error rate cho má»—i load level  
  Ghi báº£ng: N | p50 | p95 | p99 | QPS | error %.
- [ ] Plot graph: Latency vs Load  
  Trá»¥c X: concurrent users, Y: p95 latency (ms).
- [ ] Plot graph: Throughput vs Load  
  Trá»¥c X: concurrent users, Y: QPS.
- [ ] Identify: Breaking point (khi latency spikes)  
  VÃ­ dá»¥: p95 tÄƒng gáº¥p Ä‘Ã´i khi N > 200 â†’ breaking point ~200.
- [ ] Identify: Type of bottleneck (CPU-bound, I/O-bound, Memory-bound)  
  CPU: CPU % cao; I/O: DB/disk wait; Memory: heap/GC. DÃ¹ng profiler hoáº·c metrics OS.
- [ ] Analyze: Táº¡i sao bottleneck xáº£y ra á»Ÿ Ä‘iá»ƒm Ä‘Ã³?  
  VÃ­ dá»¥: 200 threads â†’ connection pool DB 20 â†’ queue â†’ latency tÄƒng.
- [ ] Propose: 3 solutions Ä‘á»ƒ resolve bottleneck  
  VÃ­ dá»¥: (1) TÄƒng connection pool, (2) ThÃªm cache, (3) Scale out app.
- [ ] Estimate: Improvement expected tá»« má»—i solution  
  VÃ­ dá»¥: cache â†’ giáº£m 60% DB load; scale out â†’ tÄƒng 3x throughput.

### Analysis Task 2: Capacity Planning

- [ ] Scenario: Design system cho 10M users  
- [ ] Estimate: Peak concurrent users (assume 10% of total)  
  **10% Ã— 10M = 1M concurrent.** (CÃ³ thá»ƒ giáº£ sá»­ 1â€“5% tÃ¹y loáº¡i app.)
- [ ] Estimate: Peak QPS (assume 5 requests/user/minute)  
  **1M Ã— 5 / 60 â‰ˆ 83,333 QPS.** (Äiá»u chá»‰nh theo use case.)
- [ ] Calculate: Database size (assume 1KB per user)  
  **10M Ã— 1KB = 10GB** (chá»‰ user data). ThÃªm báº£ng khÃ¡c â†’ nhÃ¢n thÃªm.
- [ ] Calculate: Cache size (assume 10% of DB)  
  **10% Ã— 10GB = 1GB** cache. Redis 1GB + overhead.
- [ ] Calculate: Bandwidth (assume 5KB per request)  
  **83,333 Ã— 5KB Ã— 2 (req+resp) â‰ˆ 833 MB/s â‰ˆ 6.7 Gbps** (peak). CÃ³ thá»ƒ giáº£m náº¿u cache/CDN.
- [ ] Estimate: Server count (assume 1 server = 10K QPS)  
  **83,333 / 10,000 â‰ˆ 9** app servers (tá»‘i thiá»ƒu). ThÃªm headroom â†’ 15â€“20.
- [ ] Estimate: Cost (rough, assume $100/server/month)  
  **20 Ã— $100 = $2,000/month** (chá»‰ app). ThÃªm DB, cache, LB â†’ Æ°á»›c lÆ°á»£ng tá»•ng.
- [ ] Create: Capacity planning spreadsheet  
  Cá»™t: Metric, Formula, Value. DÃ²ng: Users, Concurrent, QPS, DB size, Cache, Bandwidth, Servers, Cost.
- [ ] Validate: Táº¥t cáº£ assumptions cÃ³ realistic khÃ´ng?  
  So sÃ¡nh vá»›i benchmark thá»±c táº¿ hoáº·c case study (e.g. 10M user app dÃ¹ng ~X server).

### Analysis Task 3: Availability Calculation

- [ ] Calculate: Downtime budget cho 99.9% availability (per year)  
  **99.9% â†’ 0.1% downtime â†’ 365Ã—24Ã—60Ã—0.001 = 525.6 phÃºt/nÄƒm â‰ˆ 8.76 giá»/nÄƒm.**
- [ ] Calculate: Downtime budget cho 99.99% availability (per year)  
  **99.99% â†’ 0.01% â†’ 52.56 phÃºt/nÄƒm â‰ˆ 52 phÃºt/nÄƒm.**
- [ ] Scenario: System cÃ³ 5 components, má»—i component cÃ³ 99.9% availability  
  **Series: A = 0.999^5 â‰ˆ 0.995 (99.5%).** Downtime â‰ˆ 43.8 giá»/nÄƒm.
- [ ] Calculate: Overall system availability (series)  
  **A_total = A1 Ã— A2 Ã— A3 Ã— A4 Ã— A5.**
- [ ] Scenario: System cÃ³ 2 redundant components (parallel), má»—i 99.9%  
  **Parallel: A = 1 - (1-0.999)^2 = 1 - 0.000001 = 99.9999%.**
- [ ] Calculate: Overall system availability (parallel)  
  **A = 1 - (1-A1)(1-A2).**
- [ ] Analyze: Cáº§n bao nhiÃªu nines Ä‘á»ƒ cÃ³ < 1 hour downtime/year?  
  **1 hour = 60 min â†’ 60/(365Ã—24Ã—60) â‰ˆ 0.0114% downtime â†’ 99.9886% â†’ cáº§n ~4 nines (99.99%).**
- [ ] Analyze: Náº¿u MTTR = 1 hour, cáº§n MTBF = ? Ä‘á»ƒ Ä‘áº¡t 99.99%?  
  **A = MTBF/(MTBF+MTTR) = 0.9999 â†’ MTBF = 0.9999Ã—MTTR/0.0001 = 9999Ã—1h â‰ˆ 416 ngÃ y.**
- [ ] Create: Availability calculator spreadsheet  
  Cá»™t: Component, Availability, (Series/Parallel), Overall. DÃ²ng: tá»«ng component.
- [ ] Document: Findings vÃ  insights  
  VÃ­ dá»¥: 5 component series â†’ availability giáº£m máº¡nh; redundancy cáº£i thiá»‡n rÃµ.

### Analysis Task 4: Scaling Strategy Comparison

- [ ] Scenario: Payment API, current load = 1K QPS, expected = 10K QPS  
- [ ] Option 1: Vertical scaling (bigger server)  
  TÄƒng tá»« 4 CPU â†’ 16 CPU, 8GB â†’ 32GB.
- [ ] Calculate: Cost cá»§a vertical scaling  
  VÃ­ dá»¥: server lá»›n gáº¥p 2â€“3 láº§n giÃ¡ â†’ $300/thÃ¡ng thay vÃ¬ $100.
- [ ] Calculate: Limitations (max server size)  
  Max instance (e.g. 64 vCPU) â†’ khÃ´ng scale mÃ£i; single point of failure.
- [ ] Option 2: Horizontal scaling (more servers)  
  10 server nhá» (má»—i 1K QPS).
- [ ] Calculate: Cost cá»§a horizontal scaling  
  10 Ã— $100 = $1,000/thÃ¡ng + LB, ops phá»©c táº¡p hÆ¡n.
- [ ] Calculate: Complexity added  
  Load balancer, stateless app, monitoring, deployment.
- [ ] Compare: Vertical vs Horizontal (cost, complexity, limits)  
  Báº£ng: Cost | Complexity | Limit | Fault tolerance. Vertical: ráº» hÆ¡n lÃºc nhá», Ä‘Æ¡n giáº£n, cÃ³ limit, SPOF. Horizontal: scale xa, phá»©c táº¡p, tá»‘n hÆ¡n.
- [ ] Recommend: Which strategy? Táº¡i sao?  
  VÃ­ dá»¥: 10K QPS â†’ horizontal vÃ¬ cáº§n HA vÃ  scale tiáº¿p sau nÃ y; vertical náº¿u budget ráº¥t háº¡n cháº¿ vÃ  10K lÃ  ceiling.
- [ ] Document: Decision matrix  
  Ghi láº¡i báº£ng so sÃ¡nh vÃ  recommendation.

### Analysis Task 5: Performance Baseline

- [ ] Measure: Current app performance (baseline)  
  Cháº¡y load test 100â€“500 users, ghi QPS, p50/p95/p99, error %.
- [ ] Metrics: QPS, latency (p50, p95, p99), error rate  
  VÃ­ dá»¥: QPS 800, p50 40ms, p95 120ms, p99 250ms, error 0%.
- [ ] Document: Baseline performance  
  á» má»¥c nÃ o (hardware, JVM, code version), sá»‘ liá»‡u trÃªn.
- [ ] Set: Performance goals (improve by 2x)  
  Má»¥c tiÃªu: QPS 1600, p95 60ms (giáº£m 2x).
- [ ] Identify: Bottleneck preventing goal achievement  
  Tá»« profiling: DB query cháº­m hoáº·c CPU 100%.
- [ ] Propose: Optimization plan  
  (1) ThÃªm index / optimize query, (2) Cache hot data, (3) TÄƒng connection pool.
- [ ] Estimate: Expected improvement tá»« má»—i optimization  
  VÃ­ dá»¥: cache â†’ -40% DB load; index â†’ -50% query time.
- [ ] Prioritize: Optimizations by impact/effort  
  Impact cao, effort tháº¥p trÆ°á»›c (e.g. index â†’ cache â†’ refactor).
- [ ] Create: Performance improvement roadmap  
  Tuáº§n 1: index; Tuáº§n 2: cache; Tuáº§n 3: tuning pool.
- [ ] Document: Analysis vÃ  recommendations  
  Baseline, goal, bottleneck, plan, Æ°á»›c lÆ°á»£ng káº¿t quáº£.

---

## Review TODOs

### Self-Evaluation

- [ ] Review: Táº¥t cáº£ study TODOs Ä‘Ã£ hoÃ n thÃ nh chÆ°a?  
  Äi tá»«ng má»¥c Study TODOs, Ä‘Ã¡nh dáº¥u Ä‘Ã£ Ä‘á»c/Ä‘Ã£ lÃ m/Ä‘Ã£ ghi chÃº.
- [ ] Review: Táº¥t cáº£ design exercises Ä‘Ã£ lÃ m chÆ°a?  
  Payment Gateway, Betting Platform, Load Estimation â€“ Ä‘Ã£ cÃ³ diagram vÃ  document chÆ°a.
- [ ] Review: Táº¥t cáº£ coding tasks Ä‘Ã£ code vÃ  test chÆ°a?  
  Task 1â€“6: project tá»“n táº¡i, cháº¡y Ä‘Æ°á»£c, cÃ³ test/load test/profiling.
- [ ] Review: Táº¥t cáº£ analysis tasks Ä‘Ã£ complete chÆ°a?  
  Bottleneck, Capacity, Availability, Scaling comparison, Performance baseline â€“ cÃ³ sá»‘ liá»‡u vÃ  document.
- [ ] Rate yourself: Understanding cá»§a scalability (1-10)  
  Ghi sá»‘ vÃ  1â€“2 cÃ¢u giáº£i thÃ­ch (vÃ­ dá»¥: 7 â€“ hiá»ƒu vertical/horizontal, chÆ°a sÃ¢u Amdahl/Gustafson).
- [ ] Rate yourself: Understanding cá»§a availability (1-10)  
  Ghi sá»‘ vÃ  giáº£i thÃ­ch ngáº¯n.
- [ ] Rate yourself: Practical skills (load testing, profiling) (1-10)  
  Ghi sá»‘ vÃ  giáº£i thÃ­ch (Ä‘Ã£ dÃ¹ng JMeter/Gatling, VisualVM chÆ°a).
- [ ] Identify: 3 concepts báº¡n hiá»ƒu rÃµ nháº¥t  
  VÃ­ dá»¥: Horizontal scaling, Availability %, Load testing flow.
- [ ] Identify: 3 concepts báº¡n cÃ²n confuse  
  VÃ­ dá»¥: Amdahl vs Gustafson khi nÃ o dÃ¹ng, p99 trong thá»±c táº¿ Ä‘o tháº¿ nÃ o.
- [ ] Plan: LÃ m sao Ä‘á»ƒ clarify 3 concepts cÃ²n confuse?  
  VÃ­ dá»¥: Äá»c láº¡i chÆ°Æ¡ng X, lÃ m thÃªm bÃ i táº­p Y, há»i mentor.

### Design Review

- [ ] Review Payment Gateway design  
  Xem láº¡i diagram vÃ  doc Payment Gateway (10K TPS, 99.9%).
- [ ] Check: CÃ³ SPOF khÃ´ng?  
  Single DB? Single LB? Single region? Náº¿u cÃ³ â†’ ghi vÃ  Ä‘á» xuáº¥t redundancy.
- [ ] Check: Scaling strategy cÃ³ realistic khÃ´ng?  
  Sá»‘ instance, QPS/instance, DB capacity cÃ³ khá»›p vá»›i 10K TPS khÃ´ng.
- [ ] Check: Capacity estimates cÃ³ há»£p lÃ½ khÃ´ng?  
  So vá»›i benchmark hoáº·c case study tÆ°Æ¡ng tá»±.
- [ ] Identify: 3 weaknesses trong design  
  VÃ­ dá»¥: chÆ°a multi-region, cache chÆ°a rÃµ invalidation, chÆ°a cÃ³ queue cho peak.
- [ ] Propose: Improvements cho 3 weaknesses  
  Má»—i weakness â†’ 1â€“2 cÃ¢u cáº£i thiá»‡n cá»¥ thá»ƒ.
- [ ] Compare: Design cá»§a báº¡n vs best practices  
  So vá»›i tÃ i liá»‡u (e.g. AWS Well-Architected, SRE book) â€“ thiáº¿u gÃ¬, thá»«a gÃ¬.
- [ ] Document: Lessons learned  
  Äoáº¡n ngáº¯n: 3â€“5 Ä‘iá»u rÃºt ra tá»« design vÃ  review.

### Code Review

- [ ] Review: Code quality (clean code principles)  
  Äáº·t tÃªn, hÃ m ngáº¯n, Ã­t dependency, dá»… test.
- [ ] Review: Error handling  
  Exception, retry, logging lá»—i, khÃ´ng nuá»‘t lá»—i.
- [ ] Review: Logging vÃ  monitoring  
  CÃ³ log request/error, cÃ³ metrics (counter, timer).
- [ ] Review: Performance optimizations  
  Connection pool, cache (náº¿u cÃ³), N+1 query (náº¿u cÃ³ DB).
- [ ] Identify: 3 code improvements needed  
  VÃ­ dá»¥: tÃ¡ch service, thÃªm validation, chuáº©n hÃ³a error response.
- [ ] Refactor: At least 1 piece of code  
  Chá»n 1 improvement vÃ  refactor (commit + message rÃµ rÃ ng).
- [ ] Document: Code review findings  
  File README hoáº·c doc: 3 findings + 1 refactor Ä‘Ã£ lÃ m.

### Performance Review

- [ ] Review: Load test results  
  Báº£ng/graph QPS, latency, error theo load.
- [ ] Review: Profiling results  
  Top CPU, memory, contention (náº¿u cÃ³).
- [ ] Identify: Top 3 performance issues  
  VÃ­ dá»¥: DB query cháº­m, thiáº¿u cache, connection pool nhá».
- [ ] Verify: Performance goals Ä‘Ã£ Ä‘áº¡t chÆ°a?  
  So vá»›i baseline vÃ  target (e.g. 2x QPS, p95 giáº£m 50%).
- [ ] Document: Performance analysis  
  MÃ´ táº£ hiá»‡n tráº¡ng, váº¥n Ä‘á», Ä‘Ã£ lÃ m gÃ¬, káº¿t quáº£.
- [ ] Create: Performance improvement plan  
  Danh sÃ¡ch viá»‡c tiáº¿p theo (optimize query, thÃªm cache, â€¦) vá»›i Æ°u tiÃªn.

### Knowledge Check

- [ ] Explain: Vertical vs Horizontal scaling (viáº¿t 1 paragraph, khÃ´ng xem notes)  
  **Template:** Vertical = tÄƒng tÃ i nguyÃªn 1 mÃ¡y (CPU, RAM); horizontal = thÃªm mÃ¡y. Vertical Ä‘Æ¡n giáº£n, cÃ³ giá»›i háº¡n; horizontal scale xa hÆ¡n, cáº§n LB, stateless, data tier scale. Chá»n theo cost, limit, HA.
- [ ] Explain: Availability calculation (viáº¿t cÃ´ng thá»©c vÃ  example)  
  **CÃ´ng thá»©c:** A = MTBF/(MTBF+MTTR) hoáº·c Downtime = (1-A)Ã—8760 giá»/nÄƒm. **VÃ­ dá»¥:** 99.9% â†’ 8.76h downtime/nÄƒm.
- [ ] Explain: Bottleneck identification process (viáº¿t 5 steps)  
  **(1)** Äo latency/throughput theo load. **(2)** TÃ¬m Ä‘iá»ƒm latency tÄƒng vá»t hoáº·c throughput plateau. **(3)** Thu tháº­p metrics (CPU, memory, I/O, DB). **(4)** Profiler Ä‘á»ƒ xem method/query nÃ o tá»‘n thá»i gian. **(5)** Káº¿t luáº­n bottleneck (CPU/I/O/Memory/Network) vÃ  Ä‘á» xuáº¥t fix.
- [ ] Explain: Capacity planning approach (viáº¿t 5 steps)  
  **(1)** Æ¯á»›c lÆ°á»£ng users/DAU vÃ  peak %. **(2)** TÃ­nh QPS (requests/user/time). **(3)** TÃ­nh storage (data/user Ã— users), bandwidth (QPS Ã— size). **(4)** TÃ­nh sá»‘ server (QPS/server), DB size, cache size. **(5)** Validate vá»›i benchmark hoáº·c case study, ghi assumptions.
- [ ] Solve: System cÃ³ 3 components (99%, 99.9%, 99.99%), tÃ­nh overall availability  
  **Series:** A = 0.99 Ã— 0.999 Ã— 0.9999 â‰ˆ **0.9899 (98.99%).**
- [ ] Solve: Estimate QPS cho 1M users, 10% online, 2 requests/user/minute  
  **1M Ã— 10% = 100K online.** 100K Ã— 2 / 60 â‰ˆ **3,333 QPS.** (Peak cÃ³ thá»ƒ Ã—2â€“3.)
- [ ] Verify: Answers cá»§a báº¡n cÃ³ Ä‘Ãºng khÃ´ng?  
  So láº¡i cÃ´ng thá»©c vÃ  sá»‘ vá»›i tÃ i liá»‡u hoáº·c calculator.
- [ ] Document: Knowledge gaps found  
  Ghi láº¡i cÃ¢u nÃ o chÆ°a tráº£ lá»i cháº¯c, cáº§n Ã´n thÃªm.

### Reflection

- [ ] Write: 3 Ä‘iá»u há»c Ä‘Æ°á»£c quan trá»ng nháº¥t tuáº§n nÃ y  
  VÃ­ dá»¥: (1) Amdahl/Gustafson vÃ  bottleneck, (2) Availability % vÃ  downtime, (3) Load test + profiling flow.
- [ ] Write: 2 Ä‘iá»u cÃ²n confuse hoáº·c cáº§n há»c thÃªm  
  VÃ­ dá»¥: p99 trong production Ä‘o tháº¿ nÃ o, khi nÃ o chá»n vertical vs horizontal cho tá»«ng layer.
- [ ] Write: 1 mistake báº¡n Ä‘Ã£ lÃ m vÃ  lesson learned  
  VÃ­ dá»¥: Æ°á»›c lÆ°á»£ng QPS quÃ¡ tháº¥p â†’ Ä‘iá»u chá»‰nh láº¡i formula.
- [ ] Write: Confidence level cho Week 2 (1-10)  
  Ghi sá»‘ vÃ  1 cÃ¢u (vÃ­ dá»¥: 7 â€“ sáºµn sÃ ng HA, circuit breaker).
- [ ] Plan: Preparation cho Week 2 (Availability & Reliability)  
  Äá»c trÆ°á»›c tÃ i liá»‡u Week 2, xem láº¡i circuit breaker, health check.
- [ ] Set: Goals cho Week 2  
  VÃ­ dá»¥: Implement circuit breaker, thiáº¿t káº¿ HA cho 1 service.
- [ ] Document: Week 1 reflection (500 words)  
  Tá»•ng há»£p 3 Ä‘iá»u há»c Ä‘Æ°á»£c, 2 confuse, 1 mistake, confidence, plan Week 2.

### Mentor Questions (Answer these)

- [ ] Q1: Náº¿u báº¡n pháº£i scale tá»« 1K QPS lÃªn 100K QPS, báº¡n sáº½ lÃ m gÃ¬? (viáº¿t 5 steps)  
  **Template:** (1) Äo bottleneck hiá»‡n táº¡i (DB, CPU, network). (2) Scale read: cache + read replica. (3) Scale app: horizontal, stateless, LB. (4) Scale write: shard DB hoáº·c queue. (5) Load test 100K, monitor, tune.
- [ ] Q2: System cÃ³ 99.9% availability nhÆ°ng váº«n bá»‹ complain vá» downtime. Táº¡i sao? (viáº¿t analysis)  
  **Gá»£i Ã½:** Downtime táº­p trung (1 láº§n 30 phÃºt) vs ráº£i rÃ¡c; user nháº¡y cáº£m giá» peak; SLA Ä‘o sai (region/endpoint); perceived downtime (latency cao = â€œcháº­mâ€); dependency bÃªn ngoÃ i khÃ´ng náº±m trong 99.9%.
- [ ] Q3: LÃ m sao báº¡n identify bottleneck trong production system? (viáº¿t process)  
  **Template:** (1) Metrics (CPU, memory, disk, network, DB connections). (2) APM/tracing (slow request, slow query). (3) Log (error, timeout). (4) So sÃ¡nh vá»›i load (traffic tÄƒng Ä‘Ãºng lÃºc latency tÄƒng?). (5) Reproduce trong staging + profiler.
- [ ] Q4: Vertical scaling cÃ³ giá»›i háº¡n khÃ´ng? Giá»›i háº¡n lÃ  gÃ¬? (viáº¿t answer)  
  **CÃ³.** Giá»›i háº¡n: max CPU/RAM cá»§a 1 instance (e.g. 64 vCPU, 256GB); giÃ¡ tÄƒng phi tuyáº¿n; single point of failure; OS/scheduler overhead khi quÃ¡ lá»›n.
- [ ] Q5: Táº¡i sao p99 latency quan trá»ng hÆ¡n average latency? (viáº¿t explanation)  
  Average bá»‹ kÃ©o bá»Ÿi nhiá»u request nhanh; p99 pháº£n Ã¡nh tráº£i nghiá»‡m user tá»‡ nháº¥t (1% request cháº­m). SLA vÃ  user satisfaction thÆ°á»ng gáº¯n vá»›i tail latency (p95, p99).
- [ ] Review: Answers cá»§a báº¡n cÃ³ Ä‘á»§ depth chÆ°a?  
  Äá»c láº¡i 5 cÃ¢u tráº£ lá»i: cÃ³ sá»‘, cÃ³ vÃ­ dá»¥, cÃ³ process rÃµ rÃ ng chÆ°a.
- [ ] Improve: Answers náº¿u cáº§n  
  Bá»• sung 1â€“2 cÃ¢u hoáº·c 1 vÃ­ dá»¥ cho cÃ¢u cÃ²n ngáº¯n.

---

## Final Checklist

- [ ] Táº¥t cáº£ Study TODOs: âœ… Complete  
  ÄÃ¡nh dáº¥u khi Ä‘Ã£ Ä‘á»c/ghi chÃº Ä‘á»§ cÃ¡c má»¥c Study.
- [ ] Táº¥t cáº£ Design TODOs: âœ… Complete  
  Payment Gateway, Betting Platform, Load Estimation Ä‘Ã£ cÃ³ design + document.
- [ ] Táº¥t cáº£ Coding TODOs: âœ… Complete vÃ  tested  
  Task 1â€“6 Ä‘Ã£ code, cháº¡y, test/load test/profiling, cÃ³ doc.
- [ ] Táº¥t cáº£ Analysis TODOs: âœ… Complete vá»›i documentation  
  Bottleneck, Capacity, Availability, Scaling, Performance baseline Ä‘Ã£ cÃ³ sá»‘ vÃ  doc.
- [ ] Táº¥t cáº£ Review TODOs: âœ… Complete  
  Self-eval, Design review, Code review, Performance review, Knowledge check, Reflection, Mentor questions Ä‘Ã£ lÃ m vÃ  ghi láº¡i.
- [ ] Reflection document: âœ… Written  
  CÃ³ file hoáº·c section Week 1 reflection ~500 tá»«.
- [ ] Code committed to repo: âœ… Yes  
  Code Week 1 Ä‘Ã£ push (GitHub/GitLab/â€¦).
- [ ] Design diagrams saved: âœ… Yes  
  Diagram Payment Gateway, Betting (vÃ  Load Estimation náº¿u cÃ³) Ä‘Ã£ lÆ°u (draw.io, image, â€¦).
- [ ] Ready for Week 2: âœ… Yes  
  Chá»‰ Ä‘Ã¡nh dáº¥u khi tháº­t sá»± hoÃ n thÃ nh cÃ¡c má»¥c trÃªn vÃ  cáº£m tháº¥y sáºµn sÃ ng.

---

> **Mentor Final Check**: Náº¿u báº¡n check táº¥t cáº£ items trÃªn, báº¡n Ä‘Ã£ sáºµn sÃ ng cho Week 2. Náº¿u khÃ´ng, báº¡n chÆ°a sáºµn sÃ ng. HÃ£y honest vá»›i báº£n thÃ¢n.
