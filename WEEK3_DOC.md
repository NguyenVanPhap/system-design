# Week 3 ‚Äì Database Design & SQL Scaling

> **Mentor Note**: Database l√† backbone c·ªßa m·ªçi h·ªá th·ªëng. N·∫øu database ch·∫≠m, to√†n b·ªô system ch·∫≠m. Tu·∫ßn n√†y b·∫°n ph·∫£i
> MASTER database performance. Kh√¥ng c√≥ "query ch·∫°y ƒë∆∞·ª£c l√† OK". M·ªói query ph·∫£i ƒë∆∞·ª£c optimize, measure, v√† verify.
> Production systems kh√¥ng ch·∫•p nh·∫≠n slow queries.

---

## Study TODOs

### Database Schema Design Fundamentals

- [x] ƒê·ªçc "Designing Data-Intensive Applications" Chapter 2 - Data Models (pages 30-80)
    - **Key takeaways (DDIA Ch2 ‚Äì Data Models):**
        - **Relational model**: m·∫°nh v·ªÅ ad-hoc queries, JOIN, consistency; h·ª£p cho OLTP/transactional.
        - **Document model**: schema linh ho·∫°t, ph√π h·ª£p d·ªØ li·ªáu d·∫°ng *aggregate* (vd: user + settings + addresses), gi·∫£m
          JOIN; trade-off l√† kh√≥ JOIN/constraint nh∆∞ relational.
        - **Graph model**: t·ªëi ∆∞u cho quan h·ªá ph·ª©c t·∫°p, nhi·ªÅu hops (social graph, recommendation).
        - **Insight**: ch·ªçn data model theo **access patterns**; kh√¥ng c√≥ model ‚Äút·ªët nh·∫•t‚Äù, ch·ªâ c√≥ ‚Äúph√π h·ª£p nh·∫•t‚Äù.
- [x] ƒê·ªçc v·ªÅ "Normalization" - 1NF, 2NF, 3NF, BCNF
    - **1NF**: gi√° tr·ªã **nguy√™n t·ª≠** (kh√¥ng list/array trong 1 √¥), kh√¥ng l·∫∑p group c·ªôt.
    - **2NF**: ƒë√£ 1NF v√† m·ªçi non-key column **ph·ª• thu·ªôc to√†n b·ªô** v√†o kh√≥a ch√≠nh (ƒë·∫∑c bi·ªát v·ªõi composite key).
    - **3NF**: ƒë√£ 2NF v√† kh√¥ng c√≥ **transitive dependency** (A ‚Üí B ‚Üí C).
    - **BCNF**: m·ªçi determinant ph·∫£i l√† **candidate key**; ch·∫∑t h∆°n 3NF, d√πng khi integrity c·ª±c quan tr·ªçng.
    - **Th·ª±c t·∫ø**: ƒëa s·ªë OLTP d·ª´ng ·ªü **3NF**; BCNF ch·ªâ khi th·∫•y anomaly r√µ r√†ng.
- [x] Vi·∫øt notes: Khi n√†o normalize? Khi n√†o denormalize?
    - **Normalize khi:**
        - ‚úÖ C·∫ßn consistency/integrity (tr√°nh duplicate data)
        - ‚úÖ Write-heavy (update 1 ch·ªó, tr√°nh update nhi·ªÅu b·∫£ng/record tr√πng)
        - ‚úÖ Compliance/financial/healthcare c·∫ßn r√†ng bu·ªôc ch·∫∑t
    - **Denormalize khi:**
        - ‚úÖ Read-heavy, c·∫ßn latency th·∫•p
        - ‚úÖ Mu·ªën gi·∫£m JOINs cho hot paths
        - ‚úÖ Analytics/reporting c·∫ßn query nhanh (pre-aggregations, summary)
- [x] ƒê·ªçc v·ªÅ "denormalization" - trade-offs v·ªõi normalization
    - **Normalization**: consistency cao, schema s·∫°ch; trade-off l√† query c√≥ th·ªÉ ch·∫≠m v√¨ nhi·ªÅu JOIN.
    - **Denormalization**: query nhanh, √≠t JOIN; trade-off l√† **dup data**, risk **inconsistency**, write/update ph·ª©c
      t·∫°p h∆°n, c·∫ßn strategy sync.
- [x] Li·ªát k√™ 5 use cases c·∫ßn normalization
    1. **User management**: users/roles/permissions c·∫ßn consistency
    2. **E-commerce catalog**: products/categories/attributes tr√°nh tr√πng l·∫∑p
    3. **Financial accounting**: transactions/ledgers integrity critical
    4. **Healthcare records**: compliance, auditability
    5. **CMS**: articles/authors/categories, schema linh ho·∫°t
- [x] Li·ªát k√™ 5 use cases c·∫ßn denormalization
    1. **Analytics dashboard**: pre-aggregated metrics
    2. **Real-time reporting**: fact tables ph·ª•c v·ª• query nhanh
    3. **Caching/profile read model**: g·ªôp user + related data ƒë·ªÉ ƒë·ªçc 1 hit
    4. **Time-series**: summary theo window/time bucket
    5. **Search index**: denormalized docs ƒë·ªÉ search nhanh (ho·∫∑c sync sang search engine)
- [x] ƒê·ªçc v·ªÅ "star schema" vs "snowflake schema"
    - **Star schema**:
        - 1 **fact** table l·ªõn (events/transactions) + nhi·ªÅu **dimension** tables ‚Äúd√†y‚Äù th√¥ng tin.
        - Query ƒë∆°n gi·∫£n, √≠t JOIN s√¢u ‚Üí ph·ªï bi·∫øn trong BI/warehouse.
    - **Snowflake schema**:
        - Dimension ƒë∆∞·ª£c **normalize ti·∫øp** (dimension t√°ch nh·ªè nhi·ªÅu b·∫£ng).
        - Gi·∫£m tr√πng l·∫∑p dimension nh∆∞ng JOIN nhi·ªÅu h∆°n, query ph·ª©c t·∫°p h∆°n.
    - **Rule of thumb**: b·∫Øt ƒë·∫ßu **star**, ch·ªâ snowflake khi c√≥ l√Ω do r√µ r√†ng (data quality, dimension qu√° l·ªõn/chu·∫©n
      h√≥a).
- [x] ƒê·ªçc v·ªÅ "entity-relationship modeling" best practices
    - **Model theo business**, kh√¥ng theo UI/screen.
    - **ƒê·∫∑t t√™n nh·∫•t qu√°n** (users/orders/order_items), tr√°nh vi·∫øt t·∫Øt m∆° h·ªì.
    - **X√°c ƒë·ªãnh cardinality** r√µ r√†ng (1-1, 1-n, n-n); n-n lu√¥n c√≥ **junction table**.
    - ∆Øu ti√™n **surrogate key** (INT/BIGINT/UUID) cho b·∫£ng core; natural key ƒë·ªÉ UNIQUE constraint.
    - **T√°ch entity theo lifecycle/t·∫ßn su·∫•t update** (profile/settings/logs/history).
    - Thi·∫øt k·∫ø d·ª±a tr√™n **access patterns** (li·ªát k√™ query quan tr·ªçng tr∆∞·ªõc khi ch·ªët ERD).
- [x] ƒê·ªçc v·ªÅ "foreign key constraints" - performance impact
    - **INSERT/UPDATE/DELETE**: FK check t·∫°o overhead + c·∫ßn index tr√™n FK columns ƒë·ªÉ tr√°nh scan.
    - **DELETE parent**: c√≥ th·ªÉ tƒÉng lock contention/cascade cost, d·ªÖ ngh·∫Ωn n·∫øu workload write cao.
    - **Operational**: bulk import/ETL ƒë√¥i khi ph·∫£i disable t·∫°m ƒë·ªÉ nhanh, r·ªìi validate/sync l·∫°i.
- [x] Research: Foreign keys trong production - enable hay disable? T·∫°i sao?
    - **Enable FK khi:**
        - Integrity l√† ∆∞u ti√™n (financial/healthcare), schema trong 1 DB, write rate v·ª´a ph·∫£i
    - **Disable/avoid FK khi:**
        - H·ªá th·ªëng c·ª±c high-write, latency critical (gaming/betting), ho·∫∑c microservices (FK cross-service kh√¥ng kh·∫£
          thi)
    - **Best practice th·ª±c d·ª•ng**:
        - N·∫øu disable FK: b·∫Øt bu·ªôc c√≥ **application-level validation + background consistency checks** (job reconcile),
          v√† design ƒë·ªÉ tr√°nh orphan records.

### Indexing Deep Dive

- [x] ƒê·ªçc v·ªÅ "B-tree index" - how it works internally
    - C·∫•u tr√∫c **c√¢y c√¢n b·∫±ng nhi·ªÅu nh√°nh**, keys ƒë∆∞·ª£c sort trong nodes; lookup/insert/delete ƒë·ªÅu ~O(log n) v√¨ chi·ªÅu cao
      c√¢y th·∫•p v√† ƒë∆∞·ª£c t·ª± re-balance.
- [x] ƒê·ªçc v·ªÅ "Hash index" - use cases v√† limitations
    - D√πng **hash(key) ‚Üí bucket** n√™n r·∫•t t·ªët cho **equality lookup** (=), nh∆∞ng kh√¥ng h·ªó tr·ª£ range scan, ORDER BY hay
      prefix search; ph√π h·ª£p key-value exact match.
- [x] ƒê·ªçc v·ªÅ "Composite index" - column order matters
    - Index `(A,B,C)` h·ªØu d·ª•ng cho ƒëi·ªÅu ki·ªán b·∫Øt ƒë·∫ßu t·ª´ tr√°i: `A`, `A,B`, `A,B,C`; n·∫øu ch·ªâ filter b·∫±ng `B` ho·∫∑c `C` (b·ªè
      A) th√¨ th∆∞·ªùng kh√¥ng t·∫≠n d·ª•ng ƒë∆∞·ª£c index t·ªët.
- [x] Vi·∫øt notes: Index selectivity - what is it? Why important?
    - **Selectivity = distinct_values / total_rows**; c√†ng g·∫ßn 1 c√†ng t·ªët.
    - High selectivity ‚Üí index filter ƒë∆∞·ª£c nhi·ªÅu rows ‚Üí query nhanh h∆°n; low selectivity (vd: gi·ªõi t√≠nh) th∆∞·ªùng kh√¥ng
      ƒë√°ng ƒë·ªÉ index m·ªôt m√¨nh.
      B·∫°n hi·ªÉu ƒë√∫ng r·ªìi üëç M√¨nh gi·∫£i th√≠ch k·ªπ h∆°n m·ªôt ch√∫t theo g√≥c nh√¨n th·ª±c t·∫ø (ƒë√∫ng ki·ªÉu ph·ªèng v·∫•n + production lu√¥n):

    ---

  ## 1Ô∏è‚É£ Selectivity l√† g√¨?

  **Selectivity = distinct_values / total_rows**

  V√≠ d·ª• b·∫£ng `users` c√≥ 1,000,000 rows:

  | Column    | Distinct values | Selectivity |
        |-----------|-----------------|-------------|
  | `user_id` | 1,000,000       | 1.0         |
  | `email`   | 1,000,000       | 1.0         |
  | `gender`  | 2               | 0.000002    |
  | `status`  | 3               | 0.000003    |
    
  ---

  ## 2Ô∏è‚É£ V√¨ sao selectivity cao th√¨ index hi·ªáu qu·∫£?

  Gi·∫£ s·ª≠:

    ```sql
    SELECT *
    FROM users
    WHERE email = 'abc@gmail.com';
    ```

    * email g·∫ßn nh∆∞ unique
    * index lookup ‚Üí tr·∫£ v·ªÅ 1 row
    * r·∫•t √≠t I/O
    * c·ª±c nhanh

  Nh∆∞ng:

    ```sql
    SELECT *
    FROM users
    WHERE gender = 'MALE';
    ```

    * c√≥ th·ªÉ 500,000 rows
    * index scan ‚Üí r·ªìi v·∫´n ph·∫£i ƒë·ªçc r·∫•t nhi·ªÅu page
    * l√∫c n√†y optimizer c√≥ th·ªÉ ch·ªçn **full table scan** c√≤n nhanh h∆°n

  üëâ V√¨ index kh√¥ng gi√∫p ‚Äúl·ªçc‚Äù ƒë·ªß m·∫°nh.
    
  ---

  ## 3Ô∏è‚É£ High selectivity vs Low selectivity

  ### üî• High selectivity (n√™n index)

    * id
    * email
    * phone
    * order_code
    * transaction_id
    * UUID

  ### ‚ùå Low selectivity (th∆∞·ªùng kh√¥ng n√™n index ri√™ng l·∫ª)

    * gender
    * is_active (true/false)
    * status (PENDING, SUCCESS, FAILED)
    * country (n·∫øu ch·ªâ v√†i n∆∞·ªõc)

    ---

  ## 4Ô∏è‚É£ Nh∆∞ng low selectivity c√≥ th·∫≠t s·ª± v√¥ d·ª•ng?

  Kh√¥ng h·∫≥n ‚ùó

  N√≥ h·ªØu √≠ch khi:

  ### ‚úÖ L√†m composite index

    ```sql
    INDEX
    (status, created_at)
    ```

  Query:

    ```sql
    WHERE status = 'PENDING'
    AND created_at >= '2026-01-01'
    ```

  ‚Üí L√∫c n√†y index r·∫•t hi·ªáu qu·∫£ v√¨:

    * status l·ªçc subset
    * created_at ti·∫øp t·ª•c l·ªçc nh·ªè h∆°n n·ªØa

    ---

  ## 5Ô∏è‚É£ Selectivity v√† Unique Index

  Unique index c√≥ selectivity g·∫ßn 1 ‚Üí r·∫•t m·∫°nh.

  Trong:

    * MySQL
    * PostgreSQL

  Unique index c√≤n gi√∫p optimizer:

    * Bi·∫øt ch·∫Øc ch·∫Øn ch·ªâ tr·∫£ v·ªÅ t·ªëi ƒëa 1 row
    * C√≥ th·ªÉ ch·ªçn plan t·ªët h∆°n

    ---

  ## 6Ô∏è‚É£ Th·ª±c t·∫ø production (r·∫•t quan tr·ªçng)

  Trong h·ªá th·ªëng l·ªõn (nh∆∞ h·ªá affiliate b·∫°n t·ª´ng n√≥i c√≥ d·ªØ li·ªáu c·ª±c l·ªõn):

    * Index sai ‚Üí write ch·∫≠m
    * Index d∆∞ ‚Üí t·ªën RAM
    * Index low selectivity ‚Üí kh√¥ng ƒë∆∞·ª£c d√πng nh∆∞ng v·∫´n ph·∫£i maintain

  N√™n khi design index:

    1. Li·ªát k√™ query quan tr·ªçng tr∆∞·ªõc (access pattern)
    2. Ki·ªÉm tra cardinality
    3. D√πng `EXPLAIN`
    4. ƒêo th·ª±c t·∫ø

    ---

  ## 7Ô∏è‚É£ M·ªôt insight n√¢ng cao (interview th√≠ch h·ªèi)

  Selectivity ch·ªâ l√† 1 y·∫øu t·ªë.

  Optimizer c√≤n xem:

    * Distribution skew
        * Histogram statistics
        * Correlation gi·ªØa columns
        * Cost model (I/O vs CPU)

  V√≠ d·ª•:

    * `status = 'PENDING'` chi·∫øm 1% th√¥i ‚Üí d√π distinct = 3 nh∆∞ng v·∫´n r·∫•t selective.
      ƒêo·∫°n n√†y l√† ph·∫ßn ‚Äún√¢ng cao‚Äù c·ªßa selectivity ‚Äî v√† r·∫•t hay b·ªã h·ªèi trong interview senior üòÑ
      M√¨nh gi·∫£i th√≠ch t·ª´ng √Ω theo h∆∞·ªõng th·ª±c t·∫ø DB engine (MySQL / PostgreSQL).

    ---

  # 1Ô∏è‚É£ V·∫•n ƒë·ªÅ c·ªßa c√¥ng th·ª©c selectivity c∆° b·∫£n

  C√¥ng th·ª©c b·∫°n ƒë·ªçc:

    ```
    selectivity = distinct_values / total_rows
    ```

  C√¥ng th·ª©c n√†y **gi·∫£ ƒë·ªãnh d·ªØ li·ªáu ph√¢n b·ªë ƒë·ªÅu (uniform distribution)**.

  Nh∆∞ng ngo√†i ƒë·ªùi g·∫ßn nh∆∞ KH√îNG BAO GI·ªú ƒë·ªÅu.
    
  ---

  # 2Ô∏è‚É£ Distribution Skew (Ph√¢n b·ªë l·ªách)

  V√≠ d·ª• b·∫£ng 1,000,000 rows:

  | status  | count   |
        | ------- | ------- |
  | SUCCESS | 980,000 |
  | FAILED  | 10,000  |
  | PENDING | 10,000  |

  Distinct = 3
  Selectivity theo c√¥ng th·ª©c = 3 / 1,000,000 = r·∫•t th·∫•p ‚ùå

  Nh∆∞ng query:

    ```sql
    WHERE status = 'PENDING'
    ```

  ‚Üí ch·ªâ tr·∫£ 1% rows
  ‚Üí th·ª±c t·∫ø r·∫•t selective
  ‚Üí index c√≥ gi√° tr·ªã

  üí° ƒê√¢y g·ªçi l√† **skewed distribution**.
    
  ---

  # 3Ô∏è‚É£ Histogram Statistics l√† g√¨?

  DB hi·ªán ƒë·∫°i (MySQL 8, PostgreSQL) kh√¥ng ch·ªâ l∆∞u:

    * number of distinct
        * total rows

  M√† c√≤n l∆∞u **histogram**:

  ‚Üí Ph√¢n b·ªë t·∫ßn su·∫•t gi√° tr·ªã

  V√≠ d·ª• histogram s·∫Ω bi·∫øt:

    * SUCCESS = 98%
        * FAILED = 1%
        * PENDING = 1%

  N√™n optimizer t√≠nh ƒë∆∞·ª£c:

    ```
    selectivity(status = 'PENDING') ‚âà 0.01
    ```

  Ch·ª© kh√¥ng d√πng 1/3.
    
  ---

  # 4Ô∏è‚É£ Correlation gi·ªØa columns

  Gi·∫£ s·ª≠:

    ```sql
    WHERE country = 'VN'
    AND city = 'HCM'
    ```

  N·∫øu optimizer nghƒ©:

    * country selectivity = 10%
        * city selectivity = 5%

  N√≥ c√≥ th·ªÉ t√≠nh sai:

    ```
    0.1 √ó 0.05 = 0.005 (0.5%)
    ```

  Nh∆∞ng th·ª±c t·∫ø:

    * HCM g·∫ßn nh∆∞ lu√¥n thu·ªôc VN

  ‚Üí 2 ƒëi·ªÅu ki·ªán c√≥ correlation cao
  ‚Üí kh√¥ng ƒë·ªôc l·∫≠p

  N·∫øu DB kh√¥ng bi·∫øt correlation ‚Üí estimate sai ‚Üí ch·ªçn plan sai.

  PostgreSQL h·ªó tr·ª£ extended statistics ƒë·ªÉ x·ª≠ l√Ω correlation t·ªët h∆°n.
    
  ---

  # 5Ô∏è‚É£ Cost Model (I/O vs CPU)

  Optimizer kh√¥ng h·ªèi:

  > Index c√≥ selective kh√¥ng?

  M√† h·ªèi:

  > D√πng index c√≥ r·∫ª h∆°n full scan kh√¥ng?

  N√≥ t√≠nh:

    ```
    Total cost = I/O cost + CPU cost
    ```

  V√≠ d·ª•:

    * status = SUCCESS (98%)
      ‚Üí index scan ph·∫£i ƒë·ªçc 980k rows
      ‚Üí random I/O nhi·ªÅu
      ‚Üí full table scan c√≥ th·ªÉ r·∫ª h∆°n

  ‚Üí optimizer b·ªè index
    
  ---

  # 6Ô∏è‚É£ V√¨ sao `distinct=3` nh∆∞ng v·∫´n selective?

  Quay l·∫°i v√≠ d·ª•:

  status c√≥ 3 gi√° tr·ªã
  distinct th·∫•p
  ‚Üí theo c√¥ng th·ª©c basic ‚Üí low selectivity

  Nh∆∞ng n·∫øu ph√¢n b·ªë l·ªách:

    ```
    PENDING = 1%
    ```

  Th√¨:

    ```
    selectivity(status='PENDING') = 0.01
    ```

  Kh√¥ng c√≤n l√† 1/3 n·ªØa.

  üí° Selectivity th·ª±c s·ª± l√† theo VALUE c·ª• th·ªÉ, kh√¥ng ph·∫£i theo column chung chung.
    
  ---

  # 7Ô∏è‚É£ T·ªïng h·ª£p l·∫°i

  Optimizer hi·ªán ƒë·∫°i xem:

    1. Table row count
    2. Distinct values
    3. Histogram (frequency distribution)
    4. Correlation gi·ªØa columns
    5. Cost model (I/O vs CPU)
    6. Index structure (B-tree depth, clustering‚Ä¶)

  Ch·ª© kh√¥ng ch·ªâ m·ªói distinct/rows.
    
  ---

  # 8Ô∏è‚É£ Th·ª±c t·∫ø production (quan tr·ªçng)

  Trong h·ªá th·ªëng d·ªØ li·ªáu l·ªõn nh∆∞ affiliate/reporting:

    * Data skew r·∫•t ph·ªï bi·∫øn
    * 1 v√†i status chi·∫øm g·∫ßn h·∫øt
    * 1 v√†i status hi·∫øm

  N·∫øu statistics outdated:

    * Optimizer estimate sai
    * Query plan t·ªá
    * Query ƒë·ªôt nhi√™n ch·∫≠m

  N√™n ph·∫£i:
    
    ```
    ANALYZE TABLE
    ```

  ho·∫∑c auto-vacuum / auto-analyze (Postgres).
    
  ---


- [x] ƒê·ªçc v·ªÅ "covering index" - index-only scans
    - Index ch·ª©a **t·∫•t c·∫£ columns** m√† query c·∫ßn ‚Üí engine ch·ªâ ƒë·ªçc index, kh√¥ng ph·∫£i quay l·∫°i table (**index-only scan
      **), gi·∫£m I/O v√† latency.
- [x] ƒê·ªçc v·ªÅ "partial index" - conditional indexes
    - Index ch·ªâ t·∫°o tr√™n subset rows v·ªõi `WHERE` (vd: `status = 'PENDING'`) ‚Üí index nh·ªè, t·∫≠p trung cho hot subset, gi·∫£m
      overhead write.
- [x] ƒê·ªçc v·ªÅ "unique index" vs "non-unique index" - performance difference
    - Unique index enforce uniqueness v√† cho ph√©p optimizer gi·∫£ ƒë·ªãnh t·ªëi ƒëa 1 row match, ƒë√¥i khi cho plan t·ªët h∆°n; nh∆∞ng
      m·ªçi write ph·∫£i check unique constraint ‚Üí th√™m ch√∫t overhead.
- [x] ƒê·ªçc v·ªÅ "index maintenance" - INSERT/UPDATE/DELETE overhead
    - M·ªói thay ƒë·ªïi d·ªØ li·ªáu ph·∫£i update **t·∫•t c·∫£ indexes li√™n quan**; nhi·ªÅu index ‚Üí write cost tƒÉng (CPU + I/O), ƒë·∫∑c bi·ªát
      tr√™n b·∫£ng l·ªõn.
- [x] Research: How many indexes is too many? (general rule)
    - Rule of thumb: small table: 3‚Äì5 index; medium: 5‚Äì7; large: 5‚Äì10 l√† ƒë√£ ph·∫£i r·∫•t c√¢n nh·∫Øc; lu√¥n d·ª±a v√†o **read/write
      profile + index usage stats** ƒë·ªÉ quy·∫øt.
- [x] ƒê·ªçc v·ªÅ "index fragmentation" - when v√† how to rebuild
    - Nhi·ªÅu INSERT/DELETE/UPDATE g√¢y pages r·ªóng/kh√¥ng li√™n t·ª•c ‚Üí fragmentation, l√†m scan ch·∫≠m.
    - Rebuild/reorganize index khi fragmentation cao (vd > ~30%) ho·∫∑c sau bulk operations l·ªõn.
- [x] ƒê·ªçc v·ªÅ "clustered index" vs "non-clustered index" (SQL Server) ho·∫∑c "primary key" vs "secondary index" (MySQL)
    - **Clustered/primary**: data physically s·∫Øp theo key, t·ªët cho range scan; ch·ªâ c√≥ 1.
    - **Non-clustered/secondary**: c·∫•u tr√∫c ri√™ng ch·ª©a key + pointer t·ªõi row/PK; c√≥ th·ªÉ c√≥ nhi·ªÅu.
- [x] ƒê·ªçc v·ªÅ "full-text index" - when to use
    - D√πng cho **search text** (title/content), support tokenization, ranking; kh√¥ng thay th·∫ø ƒë∆∞·ª£c search engine chuy√™n
      d·ª•ng nh∆∞ng t·ªët cho full-text search ƒë∆°n gi·∫£n trong DB.

### Query Optimization

- [x] ƒê·ªçc v·ªÅ "EXPLAIN" / "EXPLAIN PLAN" - how to read output
    - T·∫≠p trung v√†o: **lo·∫°i scan/join**, index n√†o d√πng, rows ∆∞·ªõc t√≠nh/actual, v√† flags Extra (vd: `Using where`,
      `Using filesort`, `Using temporary`) ƒë·ªÉ t√¨m ch·ªó full scan ho·∫∑c sort t·ªën k√©m.
- [x] ƒê·ªçc v·ªÅ "query execution plan" - steps database takes
    - Plan cho bi·∫øt th·ª© t·ª± ƒë·ªçc b·∫£ng, c√°ch JOIN, c√°ch apply WHERE/GROUP BY/ORDER BY; hi·ªÉu plan gi√∫p bi·∫øt n√™n th√™m/s·ª≠a
      index, ƒë·ªïi query th·∫ø n√†o.
- [x] ƒê·ªçc v·ªÅ "table scan" vs "index scan" vs "index seek"
    - **Table scan**: ƒë·ªçc h·∫øt b·∫£ng ‚Üí O(n), t·ªá cho b·∫£ng l·ªõn.
    - **Index scan**: scan to√†n index (th∆∞·ªùng cho range).
    - **Index seek**: nh·∫£y th·∫≥ng v√†o ƒëo·∫°n c·∫ßn trong index ‚Üí nhanh nh·∫•t.
- [x] ƒê·ªçc v·ªÅ "cost-based optimizer" - how it works
    - Optimizer sinh nhi·ªÅu plan, estimate cost d·ª±a tr√™n **statistics**, r·ªìi ch·ªçn plan r·∫ª nh·∫•t; stats x·∫•u/outdated ‚Üí ch·ªçn
      plan t·ªá.
- [x] ƒê·ªçc v·ªÅ "query hints" - when to use (rarely)
    - Hints √©p engine d√πng index/plan c·ª• th·ªÉ; ch·ªâ n√™n d√πng khi ƒë√£ hi·ªÉu r√µ v√† kh√¥ng th·ªÉ fix b·∫±ng schema/index/stats, v√¨
      hints c√≥ th·ªÉ l·ªói th·ªùi khi data thay ƒë·ªïi.
- [x] ƒê·ªçc v·ªÅ "statistics" - why database needs them
    - Stats (row count, distribution, distinct values) l√† input cho optimizer ƒë·ªÉ estimate **cardinality** v√† cost; c·∫ßn
      ƒë∆∞·ª£c update ƒë·ªãnh k·ª≥.
- [x] ƒê·ªçc v·ªÅ "cardinality estimation" - why it matters
    - ∆Ø·ªõc l∆∞·ª£ng sai s·ªë rows ‚Üí ch·ªçn sai join order/algorithm, c√≥ th·ªÉ d·∫´n t·ªõi plan c·ª±c ch·∫≠m (hash join thay v√¨ nested
      loop, ho·∫∑c ng∆∞·ª£c l·∫°i).
- [x] ƒê·ªçc v·ªÅ "JOIN algorithms" - nested loop, hash join, merge join
    - **Nested loop**: t·ªët khi 1 b·∫£ng nh·ªè + index tr√™n b·∫£ng kia.
    - **Hash join**: build hash tr√™n b·∫£ng nh·ªè, t·ªët cho large scans kh√¥ng index.
    - **Merge join**: hi·ªáu qu·∫£ khi c·∫£ 2 input ƒë√£ sort theo join key.
- [x] ƒê·ªçc v·ªÅ "subquery" vs "JOIN" - performance comparison
    - Nhi·ªÅu subquery c√≥ th·ªÉ ƒë∆∞·ª£c rewrite th√†nh JOIN, th∆∞·ªùng d·ªÖ optimize v√† r√µ r√†ng h∆°n; ƒëa s·ªë engine c≈©ng transform
      internally, nh∆∞ng vi·∫øt JOIN r√µ r√†ng th∆∞·ªùng an to√†n.
- [x] ƒê·ªçc v·ªÅ "EXISTS" vs "IN" vs "JOIN" - when to use which
    - **EXISTS**: check t·ªìn t·∫°i, d·ª´ng s·ªõm; t·ªët cho existence check.
    - **IN**: t·ªët v·ªõi list nh·ªè; subquery l·ªõn c√≥ th·ªÉ k√©m.
    - **JOIN**: khi c·∫ßn d·ªØ li·ªáu t·ª´ nhi·ªÅu b·∫£ng; th∆∞·ªùng nhanh nh·∫•t cho large sets.
- [x] ƒê·ªçc v·ªÅ "LIMIT/OFFSET" performance issues
    - `LIMIT ... OFFSET big` bu·ªôc DB **skip** r·∫•t nhi·ªÅu rows ‚Üí ch·∫≠m d·∫ßn theo page; t·ªá cho deep pagination.
- [x] ƒê·ªçc v·ªÅ "cursor-based pagination" - better alternative
    - D√πng **key c·ªßa row cu·ªëi** l√†m cursor (`WHERE id > last_id`) thay v√¨ OFFSET, t·∫≠n d·ª•ng index t·ªët h∆°n v√† kh√¥ng b·ªã
      skip/l·∫∑p khi c√≥ d·ªØ li·ªáu m·ªõi.

### Connection Pooling

- [x] ƒê·ªçc v·ªÅ "connection pooling" - why needed?
    - T·∫°o/ƒë√≥ng DB connection r·∫•t ƒë·∫Øt (network handshake, auth); pool reuse connections, gi·ªõi h·∫°n max concurrent
      connections, c·∫£i thi·ªán latency v√† stability.
- [x] ƒê·ªçc v·ªÅ "HikariCP" - default Spring Boot pool
    - HikariCP l√† default pool trong Spring Boot, t·ªëi ∆∞u performance, √≠t config nh∆∞ng ƒë·ªß hooks cho tuning, support
      metrics t·ªët.
- [x] ƒê·ªçc v·ªÅ pool size calculation: connections = ((core_count * 2) + effective_spindle_count)
    - C√¥ng th·ª©c n√†y cho **starting point**; sau ƒë√≥ ph·∫£i d·ª±a tr√™n metrics (active vs idle, wait time) v√† capacity DB th·ª±c
      t·∫ø ƒë·ªÉ tune.
- [x] ƒê·ªçc v·ªÅ "connection pool tuning" - min, max, idle timeout
    - `minimumIdle`, `maximumPoolSize`, `idleTimeout`, `maxLifetime`, `connectionTimeout` c·∫ßn align v·ªõi pattern traffic;
      tr√°nh max qu√° l·ªõn g√¢y overload DB, c≈©ng tr√°nh qu√° nh·ªè g√¢y wait nhi·ªÅu.
- [x] ƒê·ªçc v·ªÅ "connection leak detection"
    - Leak x·∫£y ra khi m∆∞·ª£n connection m√† kh√¥ng tr·∫£; HikariCP c√≥ `leakDetectionThreshold` ƒë·ªÉ log c·∫£nh b√°o khi 1
      connection b·ªã gi·ªØ qu√° l√¢u ‚Üí gi√∫p b·∫Øt bug.
- [x] ƒê·ªçc v·ªÅ "connection timeout" vs "query timeout"
    - **Connection timeout**: th·ªùi gian ch·ªù l·∫•y connection t·ª´ pool.
    - **Query timeout**: th·ªùi gian t·ªëi ƒëa cho m·ªôt query ch·∫°y; b·∫£o v·ªá kh·ªèi query treo/h·ªèng plan.
- [x] Research: HikariCP configuration best practices
    - Gi·ªØ pool size **v·ª´a ƒë·ªß**, b·∫≠t metrics, set `maxLifetime` < lifetime th·ª±c c·ªßa DB connections, v√† test d∆∞·ªõi load
      th·∫≠t ƒë·ªÉ tune; kh√¥ng set timeout qu√° cao khi·∫øn request treo l√¢u.
- [x] ƒê·ªçc v·ªÅ "prepared statements" - performance v√† security
    - Prepared statements t√°ch query template v√† params ‚Üí tr√°nh SQL injection v√† reuse plan, gi·∫£m chi ph√≠ parse/optimize
      l·∫∑p l·∫°i.
- [x] ƒê·ªçc v·ªÅ "statement caching" - reduce parsing overhead
    - Cache prepared statements (client side ho·∫∑c server side) gi√∫p tr√°nh parse/plan l·∫°i; ƒë·∫∑c bi·ªát hi·ªáu qu·∫£ v·ªõi query
      l·∫∑p nhi·ªÅu.

### Read Replicas & Replication

- [x] ƒê·ªçc v·ªÅ "master-slave replication" - how it works
    - Master ghi data, log l·∫°i (binlog/WAL); slaves ƒë·ªçc log v√† apply theo th·ª© t·ª± ‚Üí d·ªØ li·ªáu tr√™n slave **tr·ªÖ** so v·ªõi
      master.
- [x] ƒê·ªçc v·ªÅ "replication lag" - what causes it?
    - Network latency, load cao tr√™n slave, disk ch·∫≠m, ho·∫∑c burst write l·ªõn tr√™n master khi·∫øn slave apply kh√¥ng k·ªãp.
- [x] ƒê·ªçc v·ªÅ "eventual consistency" trong read replicas
    - Slave ch·ªâ ƒë·∫£m b·∫£o **eventual** sync; t·∫°i m·ªôt th·ªùi ƒëi·ªÉm c√≥ th·ªÉ outdated v√†i gi√¢y (ho·∫∑c h∆°n) so v·ªõi master.
- [x] ƒê·ªçc v·ªÅ "read-after-write consistency" problem
    - Sau khi user ghi (update balance) v√†o master, n·∫øu ngay l·∫≠p t·ª©c ƒë·ªçc t·ª´ slave c√≥ th·ªÉ kh√¥ng th·∫•y update ‚Üí c·∫ßn route
      c√°c read-critical v·ªÅ master ho·∫∑c c√≥ strategy ƒë·∫∑c bi·ªát.
- [x] ƒê·ªçc v·ªÅ "read scaling" - when read replicas help
    - ƒê·ªçc nhi·ªÅu h∆°n ghi, query ch·ªß y·∫øu l√† read-only/analytics ‚Üí c√≥ th·ªÉ offload sang nhi·ªÅu slaves ƒë·ªÉ scale read.
- [x] ƒê·ªçc v·ªÅ "write scaling" - read replicas DON'T help
    - Vi·ªác ghi v·∫´n bottleneck ·ªü master; replicas ch·ªâ gi√∫p ƒë·ªçc, kh√¥ng tƒÉng write throughput (tr·ª´ khi sharding).
- [x] Research: MySQL replication setup
    - MySQL d√πng binlog, slave `CHANGE MASTER TO ...` ƒë·ªÉ subscribe; c√≥ nhi·ªÅu mode (async, semi-sync) v·ªõi trade-off
      latency vs durability.
- [x] Research: PostgreSQL replication setup
    - PostgreSQL d√πng WAL shipping/streaming replication; slaves th∆∞·ªùng l√† hot-standby c√≥ th·ªÉ ph·ª•c v·ª• read-only.
- [x] ƒê·ªçc v·ªÅ "replication topologies" - chain, star, etc.
    - Chain (master ‚Üí slave1 ‚Üí slave2...), fan-out/star t·ª´ master, multi-tier; m·ªói ki·ªÉu c√≥ trade-off v·ªÅ **lag**, ƒë·ªô ph·ª©c
      t·∫°p v√† single points of failure.
- [x] ƒê·ªçc v·ªÅ "failover" trong master-slave setup
    - C·∫ßn c∆° ch·∫ø promote slave l√™n master + re-point c√°c node kh√°c; ph·∫£i x·ª≠ l√Ω split-brain, m·∫•t d·ªØ li·ªáu ch∆∞a replicate,
      v√† ƒë·∫£m b·∫£o app bi·∫øt master m·ªõi.

### Partitioning Basics

- [x] ƒê·ªçc v·ªÅ "horizontal partitioning" (sharding)
    - Chia rows theo key (vd: user_id) ra nhi·ªÅu shard/partition; m·ªói partition ch·ª©a subset c·ªßa rows nh∆∞ng full columns.
- [x] ƒê·ªçc v·ªÅ "vertical partitioning" (column splitting)
    - Chia columns c·ªßa c√πng 1 logical entity ra nhi·ªÅu b·∫£ng (hot columns vs cold/large columns) ƒë·ªÉ t·ªëi ∆∞u I/O v√† width
      c·ªßa row.
- [x] ƒê·ªçc v·ªÅ "range partitioning" - partition by date range
    - M·ªói partition l√† 1 kho·∫£ng (vd: theo th√°ng/nƒÉm); c·ª±c h·ª£p cho time-series v√† queries theo date range.
- [x] ƒê·ªçc v·ªÅ "hash partitioning" - partition by hash
    - Hash(key) mod N ‚Üí chia ƒë·ªÅu data, gi√∫p balance load; nh∆∞ng cross-key range scan k√©m t·ª± nhi√™n h∆°n range partition.
- [x] ƒê·ªçc v·ªÅ "list partitioning" - partition by category
    - Ph√¢n theo set gi√° tr·ªã c·ª• th·ªÉ (region = US/EU/APAC); h·ªØu √≠ch khi workload kh√°c nhau theo nh√≥m gi√° tr·ªã.
- [x] ƒê·ªçc v·ªÅ "partition pruning" - query optimization
    - Optimizer ch·ªâ scan partitions c√≥ li√™n quan d·ª±a tr√™n ƒëi·ªÅu ki·ªán WHERE (v√≠ d·ª• theo date) ‚Üí gi·∫£m I/O r·∫•t nhi·ªÅu n·∫øu
      partition design ƒë√∫ng.
- [x] ƒê·ªçc v·ªÅ "cross-partition queries" - performance impact
    - Query ph·∫£i ch·∫°m nhi·ªÅu partition/shard s·∫Ω t·ªën chi ph√≠ t·ªïng h·ª£p/merge, c√≥ th·ªÉ m·∫•t l·ª£i th·∫ø partition; c·∫ßn design
      access pattern ƒë·ªÉ ƒëa s·ªë query ch·ªâ ch·∫°m √≠t partition.
- [x] Research: MySQL partitioning
    - MySQL h·ªó tr·ª£ range/list/hash partition ·ªü m·ª©c table; c·∫ßn c·∫©n th·∫≠n v·ªõi constraints v√† index (index th∆∞·ªùng
      per-partition).
- [x] Research: PostgreSQL partitioning
    - PostgreSQL c√≥ declarative partitioning (range/list/hash); query planner l√†m pruning kh√° t·ªët n·∫øu WHERE align v·ªõi
      partition key.

### Transaction Isolation Levels

- [x] ƒê·ªçc v·ªÅ "ACID properties" - Atomicity, Consistency, Isolation, Durability
    - **Atomicity**: all-or-nothing; **Consistency**: kh√¥ng ph√° v·ª° invariants; **Isolation**: transaction nh∆∞ ch·∫°y tu·∫ßn
      t·ª±; **Durability**: ƒë√£ commit th√¨ kh√¥ng m·∫•t (d√π crash).
- [x] ƒê·ªçc v·ªÅ "transaction isolation levels" - READ UNCOMMITTED, READ COMMITTED, REPEATABLE READ, SERIALIZABLE
    - M·ªói level c·∫•m th√™m m·ªôt s·ªë anomaly, ƒë·ªïi l·∫°i cost concurrency/performance cao h∆°n.
- [x] ƒê·ªçc v·ªÅ "dirty read" - what is it?
    - ƒê·ªçc d·ªØ li·ªáu t·ª´ transaction kh√°c **ch∆∞a commit**; n·∫øu b·ªã rollback th√¨ read ƒë√≥ l√† ‚Äúb·∫©n‚Äù.
- [x] ƒê·ªçc v·ªÅ "non-repeatable read" - what is it?
    - C√πng 1 query trong 1 transaction nh∆∞ng ch·∫°y 2 l·∫ßn cho ra **gi√° tr·ªã kh√°c nhau** v√¨ transaction kh√°c ƒë√£ commit
      update.
- [x] ƒê·ªçc v·ªÅ "phantom read" - what is it?
    - L·∫ßn sau xu·∫•t hi·ªán **th√™m/h·∫øt rows** th·ªèa ƒëi·ªÅu ki·ªán, kh√¥ng ch·ªâ ƒë·ªïi gi√° tr·ªã, do transaction kh√°c insert/delete gi·ªØa
      ch·ª´ng.
- [x] Vi·∫øt table: Isolation level ‚Üí Prevents which anomalies?
    - READ UNCOMMITTED: kh√¥ng ngƒÉn g√¨.
    - READ COMMITTED: ngƒÉn **dirty read**.
    - REPEATABLE READ: ngƒÉn **dirty + non-repeatable read** (phantom t√πy engine).
    - SERIALIZABLE: ngƒÉn c·∫£ **phantom** (g·∫ßn nh∆∞ serialize).
- [x] ƒê·ªçc v·ªÅ "MVCC" (Multi-Version Concurrency Control) - how it works
    - L∆∞u nhi·ªÅu version row, m·ªói transaction ƒë·ªçc snapshot ph√π h·ª£p v·ªõi timestamp c·ªßa n√≥; gi·∫£m c·∫ßn lock read, cho ph√©p
      read kh√¥ng block write (v√† ng∆∞·ª£c l·∫°i) trong ƒëa s·ªë case.
- [x] ƒê·ªçc v·ªÅ "locking" - shared locks, exclusive locks
    - **Shared (read)**: nhi·ªÅu reader c√πng n·∫Øm ƒë∆∞·ª£c, block writer.
    - **Exclusive (write)**: 1 writer, block reader kh√°c; lock scope c√≥ th·ªÉ l√† row/page/table t√πy engine v√† query.
- [x] ƒê·ªçc v·ªÅ "deadlock" - what causes it? How to prevent?
    - X·∫£y ra khi 2+ transactions gi·ªØ lock A, ch·ªù lock B c·ªßa nhau; prevention: th·ª© t·ª± truy c·∫≠p t√†i nguy√™n nh·∫•t qu√°n, gi·ªØ
      transaction ng·∫Øn, index t·ªët ƒë·ªÉ lock √≠t rows h∆°n.
- [x] ƒê·ªçc v·ªÅ "optimistic locking" vs "pessimistic locking"
    - **Optimistic**: ƒë·ªçc version, khi update check version kh√¥ng ƒë·ªïi; t·ªët cho conflict √≠t.
    - **Pessimistic**: lock row ngay khi ƒë·ªçc ƒë·ªÉ ch·∫∑n concurrent writers; t·ªët khi conflict cao nh∆∞ng gi·∫£m concurrency.
- [x] Research: Default isolation level trong MySQL vs PostgreSQL
    - MySQL InnoDB: m·∫∑c ƒë·ªãnh **REPEATABLE READ**; PostgreSQL: m·∫∑c ƒë·ªãnh **READ COMMITTED**.

### Data Consistency vs Performance

- [x] ƒê·ªçc v·ªÅ "strong consistency" - trade-offs
    - M·ªçi read sau write ƒë·ªÅu th·∫•y d·ªØ li·ªáu m·ªõi (theo 1 model r√µ r√†ng); th∆∞·ªùng c·∫ßn coordination m·∫°nh, lock nhi·ªÅu h∆°n,
      latency cao h∆°n, kh√≥ scale.
- [x] ƒê·ªçc v·ªÅ "eventual consistency" - trade-offs
    - Cho ph√©p node/replica kh√°c nhau t·∫°m th·ªùi th·∫•y state kh√°c nhau, mi·ªÖn l√† r·ªìi s·∫Ω converge; d·ªÖ scale, latency th·∫•p
      h∆°n, nh∆∞ng app ph·∫£i ch·∫•p nh·∫≠n v√† x·ª≠ l√Ω **stale reads**.
- [x] ƒê·ªçc v·ªÅ "read consistency" - snapshot isolation
    - Snapshot isolation d√πng MVCC ƒë·ªÉ m·ªói transaction ƒë·ªçc 1 snapshot nh·∫•t qu√°n c·ªßa DB, kh√¥ng th·∫•y half-committed state,
      gi·∫£m lock gi·ªØa readers v√† writers.
- [x] ƒê·ªçc v·ªÅ "write consistency" - how to ensure
    - D√πng transaction ƒë√∫ng ch·ªó, constraints ·ªü DB (FK, UNIQUE, CHECK), idempotent operations, v√† n·∫øu distributed th√¨ c·∫ßn
      protocol ƒë·∫£m b·∫£o commit ƒë·ªìng b·ªô.
- [x] Analyze: When to sacrifice consistency for performance?
    - Khi d·ªØ li·ªáu **kh√¥ng critical** (likes, views, feed ordering), ch·∫•p nh·∫≠n ƒë·ªçc h∆°i c≈© nh∆∞ng ƒë·ªïi l·∫°i
      throughput/latency t·ªët h∆°n, ho·∫∑c trong h·ªá th·ªëng ph√¢n t√°n multi-region.
- [x] Analyze: When MUST have strong consistency?
    - S·ªë d∆∞ wallet, chuy·ªÉn ti·ªÅn, ƒë∆°n h√†ng thanh to√°n, quy·ªÅn truy c·∫≠p/security, ho·∫∑c b·∫•t k·ª≥ th·ª© g√¨ m√† state sai 1 l·∫ßn l√†
      g√¢y m·∫•t ti·ªÅn/t·ªïn h·∫°i l·ªõn.
- [x] ƒê·ªçc v·ªÅ "distributed transactions" - 2PC, performance impact
    - **2-phase commit** ƒë·∫£m b·∫£o atomic commit gi·ªØa nhi·ªÅu resource managers, nh∆∞ng th√™m coordinator, nhi·ªÅu round-trip,
      d·ªÖ th√†nh bottleneck v√† c√≥ risk blocking n·∫øu coordinator ch·∫øt; th∆∞·ªùng tr√°nh cho high-throughput path, ∆∞u ti√™n
      design **saga/eventual consistency** n·∫øu ph√π h·ª£p.

---

## Schema & Modeling TODOs

### Schema Design Exercise 1: Wallet System

- [ ] Design: Complete database schema cho Wallet System
- [ ] Requirement: 10M users, 100M transactions, balance queries < 10ms
- [ ] Design: Users table (columns, data types, constraints)
- [ ] Design: Wallets table (columns, data types, constraints)
- [ ] Design: Transactions table (columns, data types, constraints)
- [ ] Design: Transaction types (enum ho·∫∑c lookup table)
- [ ] Design: Indexes cho m·ªói table (list all indexes v·ªõi rationale)
- [ ] Design: Foreign keys (which ones? why?)
- [ ] Verify: Normalization level (1NF, 2NF, 3NF?)
- [ ] Consider: Denormalization opportunities (n·∫øu c√≥)
- [ ] Create: ERD diagram (draw.io ho·∫∑c tool)
- [ ] Document: Schema design decisions (500 words)

### Schema Design Exercise 2: Payment Gateway

- [ ] Design: Database schema cho Payment Gateway
- [ ] Requirement: 1M transactions/day, complex reporting queries
- [ ] Design: Merchants table
- [ ] Design: Payments table (with all required fields)
- [ ] Design: Payment status tracking (state machine)
- [ ] Design: Refunds table
- [ ] Design: Payment methods table
- [ ] Design: Indexes strategy (consider query patterns)
- [ ] Consider: Partitioning strategy (by date? by merchant?)
- [ ] Design: Archive strategy (old transactions)
- [ ] Create: Complete schema v·ªõi all tables
- [ ] Document: Design decisions v√† trade-offs

### Schema Design Exercise 3: Betting Platform

- [ ] Design: Database schema cho Betting Platform
- [ ] Requirement: Real-time odds updates, bet history, settlement
- [ ] Design: Matches table
- [ ] Design: Odds table (frequently updated)
- [ ] Design: Bets table
- [ ] Design: Bet outcomes table
- [ ] Design: User accounts table
- [ ] Design: Indexes (consider update frequency)
- [ ] Consider: How to handle high-frequency odds updates?
- [ ] Consider: Denormalization cho read-heavy queries
- [ ] Design: Data retention policy
- [ ] Create: Schema diagram
- [ ] Document: Design rationale

### Schema Review & Optimization

- [ ] Review: Wallet System schema
- [ ] Check: All indexes c√≥ necessary kh√¥ng?
- [ ] Check: Missing indexes? (identify potential)
- [ ] Check: Over-indexing? (too many indexes)
- [ ] Check: Data types optimal? (VARCHAR size, INT vs BIGINT)
- [ ] Check: Constraints appropriate? (NOT NULL, UNIQUE, CHECK)
- [ ] Optimize: Schema based on review
- [ ] Document: Schema review findings

---

## SQL Optimization TODOs

### Query Optimization Exercise 1: Slow Query Identification

- [ ] Setup: Database v·ªõi 1M+ records (use sample data generator)
- [ ] Create: Users table v·ªõi 1M records
- [ ] Create: Orders table v·ªõi 10M records
- [ ] Create: OrderItems table v·ªõi 50M records
- [ ] Write: Query to find user orders (JOIN Users v√† Orders)
- [ ] Run: EXPLAIN PLAN cho query
- [ ] Identify: Table scan? Index scan? Index seek?
- [ ] Measure: Query execution time
- [ ] Document: Baseline performance

### Query Optimization Exercise 2: Index Optimization

- [ ] Query: SELECT * FROM orders WHERE user_id = ? AND status = 'PENDING'
- [ ] Run: EXPLAIN PLAN (before optimization)
- [ ] Measure: Execution time (before)
- [ ] Analyze: Missing index? Wrong index?
- [ ] Create: Appropriate index (single ho·∫∑c composite)
- [ ] Run: EXPLAIN PLAN (after optimization)
- [ ] Measure: Execution time (after)
- [ ] Calculate: Performance improvement (%)
- [ ] Verify: Index ƒë∆∞·ª£c s·ª≠ d·ª•ng (check EXPLAIN output)
- [ ] Document: Optimization results

### Query Optimization Exercise 3: JOIN Optimization

- [ ] Write: Complex query v·ªõi 3-table JOIN
- [ ] Query: Users JOIN Orders JOIN OrderItems
- [ ] Run: EXPLAIN PLAN
- [ ] Identify: JOIN order (does it matter?)
- [ ] Identify: JOIN algorithm used (nested loop? hash join?)
- [ ] Optimize: JOIN order (if needed)
- [ ] Add: Indexes to support JOINs
- [ ] Measure: Performance before v√† after
- [ ] Document: JOIN optimization

### Query Optimization Exercise 4: Aggregation Optimization

- [ ] Write: Query v·ªõi GROUP BY v√† aggregate functions
- [ ] Query: SELECT user_id, COUNT(*), SUM(amount) FROM orders GROUP BY user_id
- [ ] Run: EXPLAIN PLAN
- [ ] Measure: Execution time
- [ ] Analyze: Can index help GROUP BY?
- [ ] Create: Index to optimize GROUP BY
- [ ] Measure: Performance improvement
- [ ] Consider: Materialized view? (if applicable)
- [ ] Document: Aggregation optimization

### Query Optimization Exercise 5: Subquery vs JOIN

- [ ] Write: Query using subquery
- [ ] Example: SELECT * FROM users WHERE id IN (SELECT user_id FROM orders WHERE amount > 1000)
- [ ] Run: EXPLAIN PLAN
- [ ] Measure: Execution time
- [ ] Rewrite: Same query using JOIN
- [ ] Run: EXPLAIN PLAN
- [ ] Measure: Execution time
- [ ] Compare: Subquery vs JOIN performance
- [ ] Document: Which is better? Why?

### Query Optimization Exercise 6: EXISTS vs IN vs JOIN

- [ ] Write: Query using IN clause
- [ ] Example: SELECT * FROM users WHERE id IN (SELECT user_id FROM orders)
- [ ] Measure: Execution time
- [ ] Rewrite: Using EXISTS
- [ ] Measure: Execution time
- [ ] Rewrite: Using JOIN
- [ ] Measure: Execution time
- [ ] Compare: IN vs EXISTS vs JOIN
- [ ] Analyze: Which performs best? Why?
- [ ] Document: Best practice recommendation

### Query Optimization Exercise 7: Pagination Optimization

- [ ] Write: Query v·ªõi LIMIT v√† OFFSET
- [ ] Example: SELECT * FROM orders ORDER BY created_at LIMIT 10 OFFSET 1000000
- [ ] Measure: Execution time (slow v·ªõi large OFFSET)
- [ ] Analyze: Why is it slow?
- [ ] Rewrite: Using cursor-based pagination
- [ ] Example: SELECT * FROM orders WHERE id > ? ORDER BY id LIMIT 10
- [ ] Measure: Execution time
- [ ] Compare: OFFSET vs cursor-based
- [ ] Document: Pagination best practices

### Query Optimization Exercise 8: Full Table Scan Prevention

- [ ] Write: Query that causes full table scan
- [ ] Run: EXPLAIN PLAN - verify table scan
- [ ] Identify: Missing index
- [ ] Create: Index to prevent table scan
- [ ] Run: EXPLAIN PLAN - verify index used
- [ ] Measure: Performance improvement
- [ ] Document: Table scan elimination

### Query Performance Testing

- [ ] Create: Test suite v·ªõi 10 different queries
- [ ] Run: All queries v√† measure execution time
- [ ] Identify: 3 slowest queries
- [ ] Optimize: 3 slowest queries
- [ ] Measure: Performance improvement cho m·ªói query
- [ ] Set: Performance targets (p95 < 100ms)
- [ ] Verify: All queries meet targets
- [ ] Document: Performance test results

---

## Spring Boot + DB TODOs

### Task 1: HikariCP Configuration

- [ ] Create: Spring Boot project v·ªõi database
- [ ] Add: HikariCP dependency (default trong Spring Boot)
- [ ] Configure: Connection pool size (calculate based on formula)
- [ ] Configure: Minimum idle connections
- [ ] Configure: Maximum pool size
- [ ] Configure: Connection timeout
- [ ] Configure: Idle timeout
- [ ] Configure: Max lifetime
- [ ] Add: Connection pool monitoring (metrics)
- [ ] Test: Under load, verify pool kh√¥ng exhausted
- [ ] Document: HikariCP configuration

### Task 2: JPA/Hibernate Optimization

- [ ] Setup: Spring Data JPA v·ªõi Hibernate
- [ ] Configure: HikariCP connection pool
- [ ] Configure: Hibernate batch size
- [ ] Configure: Hibernate fetch size
- [ ] Configure: Hibernate second-level cache (optional)
- [ ] Write: Entity classes v·ªõi proper annotations
- [ ] Write: Repository v·ªõi custom queries
- [ ] Test: Query performance
- [ ] Monitor: Hibernate SQL logs (verify no N+1 queries)
- [ ] Optimize: N+1 queries (if found)
- [ ] Document: JPA optimization

### Task 3: Query Performance Monitoring

- [ ] Add: Micrometer metrics
- [ ] Expose: Database query metrics
- [ ] Monitor: Query execution time
- [ ] Monitor: Connection pool usage
- [ ] Monitor: Slow queries (log queries > 1 second)
- [ ] Setup: Alert cho slow queries
- [ ] Create: Dashboard v·ªõi key metrics
- [ ] Document: Monitoring setup

### Task 4: Prepared Statements

- [ ] Verify: Spring JPA uses prepared statements (check logs)
- [ ] Write: Native query v·ªõi prepared statement
- [ ] Test: SQL injection prevention
- [ ] Measure: Performance vs regular statements
- [ ] Document: Prepared statement usage

### Task 5: Transaction Management

- [ ] Implement: Service method v·ªõi @Transactional
- [ ] Test: Transaction rollback on exception
- [ ] Configure: Transaction isolation level
- [ ] Test: Different isolation levels (READ COMMITTED, REPEATABLE READ)
- [ ] Measure: Performance impact c·ªßa isolation levels
- [ ] Document: Transaction configuration

### Task 6: Database Migration

- [ ] Setup: Flyway ho·∫∑c Liquibase
- [ ] Create: Initial schema migration
- [ ] Create: Index migration
- [ ] Create: Data migration (if needed)
- [ ] Test: Migration rollback
- [ ] Document: Migration strategy

### Task 7: Connection Leak Detection

- [ ] Configure: HikariCP leak detection
- [ ] Set: Leak detection threshold (10 seconds)
- [ ] Test: Simulate connection leak (don't close connection)
- [ ] Verify: Leak detection logs warning
- [ ] Fix: Connection leak
- [ ] Document: Leak detection setup

### Task 8: Read-Write Splitting (Optional)

- [ ] Setup: MySQL master-slave replication
- [ ] Configure: Spring Boot v·ªõi multiple data sources
- [ ] Implement: Read queries go to slave
- [ ] Implement: Write queries go to master
- [ ] Test: Read t·ª´ slave
- [ ] Test: Write to master
- [ ] Handle: Replication lag (read-after-write consistency)
- [ ] Document: Read-write splitting implementation

---

## Scaling & Replication TODOs

### Replication Setup Exercise

- [ ] Research: MySQL master-slave replication setup
- [ ] Setup: MySQL master server
- [ ] Setup: MySQL slave server
- [ ] Configure: Replication
- [ ] Test: Write to master, verify replication to slave
- [ ] Measure: Replication lag
- [ ] Test: Read from slave
- [ ] Document: Replication setup

### Read Replica Design

- [ ] Design: Read replica architecture cho Payment System
- [ ] Calculate: Number of read replicas needed (based on read load)
- [ ] Design: Read routing strategy (round-robin? least lag?)
- [ ] Design: Failover strategy (if replica fails)
- [ ] Design: Read-after-write consistency handling
- [ ] Document: Read replica design

### Partitioning Design

- [ ] Design: Partitioning strategy cho Transactions table
- [ ] Requirement: 100M transactions, query by date range
- [ ] Choose: Range partitioning by date
- [ ] Design: Partition key (created_at)
- [ ] Design: Partition pruning strategy
- [ ] Consider: Cross-partition queries impact
- [ ] Document: Partitioning design

### Database Sharding Design (Basic)

- [ ] Read: Database sharding concepts
- [ ] Design: Sharding strategy cho Users table (10M users)
- [ ] Choose: Shard key (user_id)
- [ ] Choose: Sharding algorithm (hash-based)
- [ ] Design: Shard routing logic
- [ ] Design: Cross-shard query handling
- [ ] Document: Sharding design (high-level)

---

## Consistency & Transaction TODOs

### Transaction Isolation Analysis

- [ ] Test: READ UNCOMMITTED isolation level
- [ ] Simulate: Dirty read scenario
- [ ] Verify: Dirty read occurs
- [ ] Test: READ COMMITTED isolation level
- [ ] Simulate: Non-repeatable read scenario
- [ ] Verify: Non-repeatable read occurs
- [ ] Test: REPEATABLE READ isolation level
- [ ] Simulate: Phantom read scenario
- [ ] Verify: Phantom read occurs (or not?)
- [ ] Test: SERIALIZABLE isolation level
- [ ] Measure: Performance impact c·ªßa each level
- [ ] Document: Isolation level analysis

### Deadlock Analysis

- [ ] Simulate: Deadlock scenario
- [ ] Create: Two transactions that deadlock
- [ ] Verify: Deadlock occurs
- [ ] Configure: Deadlock detection
- [ ] Test: Deadlock resolution
- [ ] Analyze: How to prevent deadlocks?
- [ ] Document: Deadlock prevention strategies

### Optimistic vs Pessimistic Locking

- [ ] Implement: Optimistic locking (version field)
- [ ] Test: Concurrent updates v·ªõi optimistic locking
- [ ] Verify: OptimisticLockException on conflict
- [ ] Implement: Pessimistic locking (@Lock)
- [ ] Test: Concurrent updates v·ªõi pessimistic locking
- [ ] Verify: Second transaction waits
- [ ] Compare: Performance c·ªßa optimistic vs pessimistic
- [ ] Document: When to use which?

### Data Consistency Scenarios

- [ ] Scenario: Update balance - deduct v√† add
- [ ] Implement: Transaction ƒë·ªÉ ensure atomicity
- [ ] Test: Rollback on failure
- [ ] Scenario: Read balance while updating
- [ ] Test: Consistency v·ªõi different isolation levels
- [ ] Document: Consistency guarantees

### ACID Properties Verification

- [ ] Test: Atomicity - transaction rollback
- [ ] Test: Consistency - constraints enforcement
- [ ] Test: Isolation - concurrent transactions
- [ ] Test: Durability - data persistence after commit
- [ ] Document: ACID verification results

---

## Review TODOs

### Self-Evaluation

- [ ] Review: T·∫•t c·∫£ Study TODOs ho√†n th√†nh?
- [ ] Review: T·∫•t c·∫£ Schema design exercises ho√†n th√†nh?
- [ ] Review: T·∫•t c·∫£ SQL optimization exercises ho√†n th√†nh?
- [ ] Review: T·∫•t c·∫£ Spring Boot tasks ho√†n th√†nh?
- [ ] Review: T·∫•t c·∫£ Scaling tasks ho√†n th√†nh?
- [ ] Rate: Database schema design skills (1-10)
- [ ] Rate: SQL optimization skills (1-10)
- [ ] Rate: Query performance tuning (1-10)
- [ ] Rate: Understanding c·ªßa transactions (1-10)
- [ ] Identify: 3 database concepts b·∫°n master
- [ ] Identify: 3 concepts c·∫ßn improve
- [ ] Plan: How to improve weak areas

### Schema Review

- [ ] Review: Wallet System schema
- [ ] Check: Normalization appropriate?
- [ ] Check: Indexes optimal?
- [ ] Check: Data types correct?
- [ ] Identify: 3 potential improvements
- [ ] Propose: Schema optimizations
- [ ] Compare: Schema vs industry best practices
- [ ] Document: Schema review findings

### Query Performance Review

- [ ] Review: All optimized queries
- [ ] Verify: All queries use indexes
- [ ] Verify: No full table scans
- [ ] Verify: Performance targets met
- [ ] Identify: 3 queries that could be improved further
- [ ] Document: Query performance review

### Code Review

- [ ] Review: Spring Boot database code
- [ ] Check: Connection pool configuration optimal?
- [ ] Check: No N+1 queries?
- [ ] Check: Transaction boundaries correct?
- [ ] Check: Error handling appropriate?
- [ ] Identify: 3 code improvements
- [ ] Refactor: At least 1 piece of code
- [ ] Document: Code review findings

### Knowledge Check

- [x] Explain: B-tree index - how it works (vi·∫øt 1 paragraph, kh√¥ng xem notes)  
  ‚Üí B-tree index l√† m·ªôt c√¢y c√¢n b·∫±ng, m·ªói node ch·ª©a nhi·ªÅu key ƒë√£ ƒë∆∞·ª£c s·∫Øp x·∫øp v√† pointer t·ªõi child nodes; khi t√¨m ki·∫øm,
  database b·∫Øt ƒë·∫ßu t·ª´ root, so s√°nh key r·ªìi ƒëi xu·ªëng nh√°nh ph√π h·ª£p cho t·ªõi leaf node, n√™n c√°c thao t√°c t√¨m
  ki·∫øm/insert/delete ƒë·ªÅu ~O(log n) v√† tree lu√¥n ƒë∆∞·ª£c t·ª± c√¢n b·∫±ng ƒë·ªÉ gi·ªØ chi·ªÅu cao th·∫•p, gi√∫p truy v·∫•n ·ªïn ƒë·ªãnh tr√™n t·∫≠p
  d·ªØ li·ªáu l·ªõn.
- [x] Explain: Composite index - column order matters (vi·∫øt explanation, kh√¥ng xem notes)  
  ‚Üí Composite index ƒë∆∞·ª£c s·∫Øp x·∫øp theo th·ª© t·ª± c·ªôt (A, B, C), n√™n ch·ªâ ƒë∆∞·ª£c d√πng hi·ªáu qu·∫£ n·∫øu ƒëi·ªÅu ki·ªán WHERE match t·ª´ tr√°i
  sang ph·∫£i (A, A+B, A+B+C); n·∫øu query ch·ªâ filter theo B ho·∫∑c C m√† b·ªè A th√¨ engine kh√≥ t·∫≠n d·ª•ng index, do ƒë√≥ ph·∫£i ch·ªçn
  order sao cho c·ªôt c√≥ selectivity cao v√† hay xu·∫•t hi·ªán trong equality conditions ƒë·ª©ng tr∆∞·ªõc.
- [x] Explain: Query execution plan - how to read (vi·∫øt guide, kh√¥ng xem notes)  
  ‚Üí Khi ƒë·ªçc execution plan, t·∫≠p trung v√†o: lo·∫°i scan/join (table scan, index scan/seek, nested loop, hash/merge join),
  index n√†o ƒëang ƒë∆∞·ª£c d√πng (`key`), s·ªë rows ∆∞·ªõc t√≠nh ph·∫£i ƒë·ªçc (`rows`), v√† ph·∫ßn `Extra/Notes` (vd: `Using where`,
  `Using filesort`, `Using temporary`); m·ª•c ti√™u l√† tr√°nh full table scan tr√™n b·∫£ng l·ªõn, gi·∫£m rows ph·∫£i scan v√† ƒë·∫£m b·∫£o
  c√°c JOIN/WHERE ƒëang hit ƒë√∫ng index.
- [x] Explain: Transaction isolation levels - differences (vi·∫øt comparison, kh√¥ng xem notes)  
  ‚Üí READ UNCOMMITTED cho ph√©p dirty read; READ COMMITTED c·∫•m dirty read nh∆∞ng v·∫´n c√≥ non-repeatable read; REPEATABLE
  READ c·∫•m dirty read v√† non-repeatable read nh∆∞ng c√≥ th·ªÉ c√≤n phantom read (t√πy engine/MVCC); SERIALIZABLE ch·∫∑t nh·∫•t,
  lo·∫°i b·ªè c·∫£ phantom read b·∫±ng c√°ch g·∫ßn nh∆∞ serialize c√°c transaction, ƒë·ªïi l·∫°i throughput gi·∫£m v√† lock/conflict tƒÉng
  m·∫°nh.
- [x] Explain: Read replica - consistency trade-offs (vi·∫øt analysis, kh√¥ng xem notes)  
  ‚Üí Read replica gi√∫p scale ƒë·ªçc v√† gi·∫£m t·∫£i master nh∆∞ng lu√¥n c√≥ replication lag ‚Üí eventual consistency; sau khi ghi v√†o
  master, n·∫øu ƒë·ªçc ngay t·ª´ replica c√≥ th·ªÉ kh√¥ng th·∫•y d·ªØ li·ªáu m·ªõi, n√™n c√°c read critical (balance, payment) th∆∞·ªùng ph·∫£i
  ƒë·ªçc t·ª´ master ho·∫∑c d√πng chi·∫øn l∆∞·ª£c sticky session/route theo lag, ch·∫•p nh·∫≠n trade-off gi·ªØa performance, availability
  v√† consistency.
- [x] Solve: Query SELECT * FROM orders WHERE user_id = ? AND status = ? - design index  
  ‚Üí Index h·ª£p l√Ω: `CREATE INDEX idx_orders_user_status ON orders(user_id, status);` v·ªõi `user_id` (th∆∞·ªùng selective h∆°n)
  ƒë·∫∑t tr∆∞·ªõc v√† `status` sau, cho ph√©p index seek theo c·∫£ hai ƒëi·ªÅu ki·ªán WHERE v√† c√≥ th·ªÉ th√†nh covering index n·∫øu query
  ch·ªâ ƒë·ªçc m·ªôt v√†i c·ªôt.
- [x] Solve: Calculate connection pool size for 4-core server, 1 database  
  ‚Üí D√πng c√¥ng th·ª©c: `connections = (core_count * 2) + effective_spindle_count` ‚Üí v·ªõi 4 core v√† 1 spindle:
  `connections = (4 * 2) + 1 = 9`; th·ª±c t·∫ø c√≥ th·ªÉ c·∫•u h√¨nh kho·∫£ng 10‚Äì15 connections r·ªìi d·ª±a v√†o metrics (active/idle,
  wait time) ƒë·ªÉ tune th√™m.
- [x] Verify: Answers c√≥ ƒë√∫ng kh√¥ng?
- [x] Document: Knowledge gaps

### Reflection

- [ ] Write: 3 ƒëi·ªÅu h·ªçc ƒë∆∞·ª£c quan tr·ªçng nh·∫•t tu·∫ßn n√†y
- [ ] Write: 2 database concepts c√≤n confuse
- [ ] Write: 1 mistake ƒë√£ l√†m v√† lesson learned
- [ ] Write: Confidence level cho Week 4 (1-10)
- [ ] Compare: Week 2 vs Week 3 progress
- [ ] Plan: Preparation cho Week 4 (Database Sharding)
- [ ] Set: Goals cho Week 4
- [ ] Document: Week 3 reflection (500 words)

### Mentor Questions (Answer these - be critical)

- [x] Q1: B·∫°n c√≥ 1 query ch·∫°y 5 gi√¢y. L√†m sao b·∫°n optimize? (vi·∫øt step-by-step process)  
  ‚Üí B1: D√πng `EXPLAIN/EXPLAIN ANALYZE` xem execution plan (full table scan? index n√†o ƒëang d√πng?).  
  ‚Üí B2: ƒêo th·ªùi gian th·ª±c thi ƒë·ªÉ c√≥ baseline.  
  ‚Üí B3: Ph√¢n t√≠ch WHERE/JOIN/ORDER BY ƒë·ªÉ t√¨m thi·∫øu index, JOIN order k√©m, LIMIT/OFFSET l·ªõn, subquery kh√¥ng c·∫ßn thi·∫øt.  
  ‚Üí B4: Thi·∫øt k·∫ø/t·ªëi ∆∞u index (∆∞u ti√™n c·ªôt trong WHERE/JOIN, composite index v·ªõi order ƒë√∫ng, covering index n·∫øu ph√π
  h·ª£p).  
  ‚Üí B5: Ch·∫°y l·∫°i EXPLAIN + benchmark, verify rows scan gi·∫£m v√† index ƒë∆∞·ª£c d√πng.  
  ‚Üí B6: N·∫øu v·∫´n ch·∫≠m, c√¢n nh·∫Øc rewrite (subquery ‚Üí JOIN, cursor-based pagination, materialized view, archive b·ªõt d·ªØ li·ªáu
  c≈©).  
  ‚Üí B7: B·∫≠t slow query log, monitor trong production v√† ti·∫øp t·ª•c t·ªëi ∆∞u d·ª±a tr√™n s·ªë li·ªáu th·ª±c.
- [x] Q2: Composite index (user_id, status, created_at) - query WHERE status = ? AND created_at > ? (kh√¥ng c√≥ user_id) -
  index c√≥ ƒë∆∞·ª£c d√πng kh√¥ng? T·∫°i sao? (vi·∫øt analysis)  
  ‚Üí Index `(user_id, status, created_at)` ƒë∆∞·ª£c sort theo `user_id` tr∆∞·ªõc n√™n query kh√¥ng c√≥ ƒëi·ªÅu ki·ªán tr√™n `user_id` s·∫Ω
  kh√¥ng t·∫≠n d·ª•ng t·ªët index n√†y (b·ªã skip c·ªôt ƒë·∫ßu), ƒëa s·ªë engine s·∫Ω ph·∫£i scan ph·∫ßn l·ªõn index ho·∫∑c b·ªè qua; n·∫øu query th∆∞·ªùng
  ch·ªâ filter theo `status` + `created_at` th√¨ n√™n t·∫°o th√™m index `(status, created_at)` chuy√™n cho pattern ƒë√≥.
- [x] Q3: Read replica c√≥ replication lag 2 gi√¢y. User v·ª´a update balance, ngay l·∫≠p t·ª©c query balance t·ª´ replica - c√≥
  th·∫•y update kh√¥ng? L√†m sao fix? (vi·∫øt solution)  
  ‚Üí V·ªõi lag 2s th√¨ g·∫ßn nh∆∞ ch·∫Øc ch·∫Øn **kh√¥ng** th·∫•y balance m·ªõi tr√™n replica ngay sau khi update; ƒë·ªÉ fix: (1) c√°c read
  critical (balance, payment) ƒë·ªçc t·ª´ master, (2) d√πng sticky session/flag sau khi write ƒë·ªÉ route m·ªôt s·ªë request ti·∫øp
  theo sang master, (3) route theo lag (n·∫øu lag > threshold th√¨ ƒë·ªçc master), ho·∫∑c (4) d√πng version/timestamp ƒë·ªÉ detect
  stale read v√† fallback sang master.
- [x] Q4: Connection pool size = 100, nh∆∞ng c√≥ 200 concurrent requests. Chuy·ªán g√¨ x·∫£y ra? L√†m sao fix? (vi·∫øt analysis)  
  ‚Üí 100 request ƒë·∫ßu m∆∞·ª£n ƒë∆∞·ª£c connection, 100 request c√≤n l·∫°i s·∫Ω block ch·ªù; n·∫øu th·ªùi gian ch·ªù v∆∞·ª£t `connection-timeout`
  th√¨ n√©m exception (timeout), g√¢y l·ªói h√†ng lo·∫°t v√† c√≥ th·ªÉ l√†m server overload th√™m. C√°ch x·ª≠ l√Ω: t·ªëi ∆∞u query ƒë·ªÉ gi·ªØ
  connection ng·∫Øn h∆°n, ƒëi·ªÅu ch·ªânh pool size (n·∫øu DB ch·ªãu ƒë∆∞·ª£c), gi·ªõi h·∫°n concurrency ·ªü app layer (queue, rate limit), v√†
  monitor active/idle connections ƒë·ªÉ tune thay v√¨ ch·ªâ tƒÉng m√π qu√°ng.
- [x] Q5: Transaction isolation level = SERIALIZABLE - c√≥ ph·∫£i lu√¥n t·ªët nh·∫•t kh√¥ng? T·∫°i sao kh√¥ng? (vi·∫øt trade-off
  analysis)  
  ‚Üí SERIALIZABLE cho isolation cao nh·∫•t (lo·∫°i b·ªè dirty/non‚Äërepeatable/phantom read) nh∆∞ng ƒë√°nh ƒë·ªïi b·∫±ng vi·ªác tƒÉng lock,
  d·ªÖ deadlock, throughput gi·∫£m m·∫°nh v√† latency cao, n√™n kh√¥ng ph√π h·ª£p cho h·ªá th·ªëng high-concurrency; th∆∞·ªùng ch·ªâ d√πng cho
  m·ªôt s·ªë lu·ªìng c·ª±c k·ª≥ critical, c√≤n l·∫°i d√πng READ COMMITTED/REPEATABLE READ + logic ·ªü application s·∫Ω c√¢n b·∫±ng h∆°n gi·ªØa
  correctness v√† performance.
- [x] Q6: B·∫°n c√≥ b·∫£ng 100M records, query WHERE created_at > ? - l√†m sao optimize? (vi·∫øt optimization strategy)  
  ‚Üí Chi·∫øn l∆∞·ª£c: (1) t·∫°o index tr√™n `created_at` (ho·∫∑c composite index n·∫øu query c√≤n filter th√™m), (2) partition b·∫£ng
  theo range th·ªùi gian ƒë·ªÉ DB ch·ªâ scan ƒë√∫ng partition (partition pruning), (3) archive d·ªØ li·ªáu qu√° c≈© sang b·∫£ng kh√°c ƒë·ªÉ
  b·∫£ng ch√≠nh nh·ªè l·∫°i, (4) d√πng covering index n·∫øu ch·ªâ c·∫ßn v√†i c·ªôt, (5) n·∫øu l√† analytics n·∫∑ng th√¨ c√¢n nh·∫Øc materialized
  view/OLAP store; lu√¥n ƒëo l·∫°i time sau m·ªói b∆∞·ªõc.
- [x] Review: Answers c√≥ ƒë·ªß depth v√† practical kh√¥ng?
- [x] Improve: Answers n·∫øu c·∫ßn

---

## Final Checklist

- [ ] T·∫•t c·∫£ Study TODOs: ‚úÖ Complete
- [ ] T·∫•t c·∫£ Schema & Modeling TODOs: ‚úÖ Complete v·ªõi diagrams
- [ ] T·∫•t c·∫£ SQL Optimization TODOs: ‚úÖ Complete v·ªõi performance measurements
- [ ] T·∫•t c·∫£ Spring Boot + DB TODOs: ‚úÖ Complete, tested, v√† documented
- [ ] T·∫•t c·∫£ Scaling & Replication TODOs: ‚úÖ Complete
- [ ] T·∫•t c·∫£ Consistency & Transaction TODOs: ‚úÖ Complete v·ªõi test results
- [ ] T·∫•t c·∫£ Review TODOs: ‚úÖ Complete
- [ ] Reflection document: ‚úÖ Written
- [ ] Code committed: ‚úÖ Yes
- [ ] Schema diagrams saved: ‚úÖ Yes
- [ ] Query performance benchmarks saved: ‚úÖ Yes
- [ ] Ready for Week 4: ‚úÖ Yes

---

> **Mentor Final Check**: Database performance l√† foundation. N·∫øu b·∫°n kh√¥ng th·ªÉ optimize queries, design schemas, v√†
> tune databases, b·∫°n kh√¥ng th·ªÉ build scalable systems. H√£y honest: B·∫°n c√≥ th·ªÉ identify v√† fix slow queries ch∆∞a? B·∫°n c√≥
> th·ªÉ design database schema cho 100M+ records ch∆∞a? N·∫øu ch∆∞a, l√†m l·∫°i. Production systems kh√¥ng ch·∫•p nh·∫≠n "query ch·∫°y
> ƒë∆∞·ª£c l√† OK".
